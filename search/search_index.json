{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Direktiv Docs","text":"<p>Direktiv is a cloud-agnostic, serverless flow engine that capitalizes on microservices, containers and custom code to create efficient processes. Using Kubernetes and Knative under the hood, this platform empowers you with the scalability of modern cloud computing. Direktiv provides a set of YAML definitions to define how the data should be processed, allowing developers to quickly and efficiently write their own business logic. </p> <p>Integrate</p> <p>Direktiv's event-driven system and container approach make it simple to link different systems. As a broker for multiple backends, Direktiv provides error handling, retries, logging and tracing capabilities to ensure seamless integration as well as greater visibility into the processes.</p> <p>Orchestrate</p> <p>Direktiv simplifies the orchestration of APIs to create higher-level services that can be used by any organization, either externally or internally. This is made possible through a YAML-based flow description system which makes it easy and fast to customize flows as well as expand capabilities.</p> <p>Automate</p> <p>Streamline repetitive duties within your team or organization by e.g. moving scripts and playbooks into an easily accessible platform. Whether you need to automate Continuous Integration, Infrastructure Management, Onboarding tasks or something else that is currently done manually - automating these processes can be a major advantage. Use a single platform which multiple users in your team have access to.</p>"},{"location":"#see-also","title":"See Also","text":"<ul> <li>The Getting Started Guide.</li> <li>The direktiv.io website.</li> <li>The direktiv.io repository.</li> <li>The Godoc library documentation.</li> </ul>"},{"location":"api/","title":"Direktiv API","text":"<p>Direktiv Open API Specification Direktiv Documentation can be found at https://docs.direktiv.io/</p>"},{"location":"api/#informations","title":"Informations","text":""},{"location":"api/#version","title":"Version","text":"<p>1.0.0</p>"},{"location":"api/#contact","title":"Contact","text":"<p>info@direktiv.io </p>"},{"location":"api/#content-negotiation","title":"Content negotiation","text":""},{"location":"api/#uri-schemes","title":"URI Schemes","text":"<ul> <li>http</li> <li>https</li> </ul>"},{"location":"api/#consumes","title":"Consumes","text":"<ul> <li>application/json</li> <li>text/plain</li> </ul>"},{"location":"api/#produces","title":"Produces","text":"<ul> <li>application/json</li> <li>text/event-stream</li> </ul>"},{"location":"api/#access-control","title":"Access control","text":""},{"location":"api/#security-schemes","title":"Security Schemes","text":""},{"location":"api/#api_key-header-key","title":"api_key (header: KEY)","text":"<p>Type: apikey</p>"},{"location":"api/#security-requirements","title":"Security Requirements","text":"<ul> <li>api_key</li> </ul>"},{"location":"api/#all-endpoints","title":"All endpoints","text":""},{"location":"api/#cloud_event_filter","title":"cloud_event_filter","text":"Method URI Name Summary POST /api/namespaces/{namespace}/eventfilter/{filtername} create cloudevent filter Creates new cloudEventFilter DELETE /api/namespaces/{namespace}/eventfilter/{filtername} delete cloudevent filter Delete existing cloudEventFilter GET /api/namespaces/{namespace}/eventfilter/{filtername} get cloud event filter Get specific cloudEventFilter GET /api/namespaces/{namespace}/eventfilter list cloudevent filter List existing cloudEventFilters PATCH /api/namespaces/{namespace}/eventfilter/{filtername} update cloudevent filter Update existing cloudEventFilter"},{"location":"api/#directory","title":"directory","text":"Method URI Name Summary PUT /api/namespaces/{namespace}/tree/{directory}?op=create-directory create directory Create a Directory"},{"location":"api/#events","title":"events","text":"Method URI Name Summary GET /api/namespaces/{namespace}/events get event history Get events history. GET /api/namespaces/{namespace}/event-listeners get event listeners Get current event listeners."},{"location":"api/#instances","title":"instances","text":"Method URI Name Summary POST /api/namespaces/{namespace}/instances/{instance}/cancel cancel instance Cancel a Pending Instance GET /api/namespaces/{namespace}/instances/{instance} get instance Get a Instance GET /api/namespaces/{namespace}/instances/{instance}/input get instance input Get a Instance Input GET /api/namespaces/{namespace}/instances get instance list Get List Instances GET /api/namespaces/{namespace}/instances/{instance}/metadata get instance metadata Get a Instance Metadata GET /api/namespaces/{namespace}/instances/{instance}/output get instance output Get a Instance Output"},{"location":"api/#logs","title":"logs","text":"Method URI Name Summary GET /api/namespaces/{namespace}/tree/{workflow}?op=logs get workflow logs Get Workflow Level Logs GET /api/namespaces/{namespace}/instances/{instance}/logs instance logs Gets Instance Logs GET /api/namespaces/{namespace}/logs namespace logs Gets Namespace Level Logs GET /api/logs server logs Get Direktiv Server Logs"},{"location":"api/#metrics","title":"metrics","text":"Method URI Name Summary GET /api/namespaces/{namespace}/metrics/failed namespace metrics failed Gets Namespace Failed Workflow Instances Metrics GET /api/namespaces/{namespace}/metrics/invoked namespace metrics invoked Gets Namespace Invoked Workflow Metrics GET /api/namespaces/{namespace}/metrics/milliseconds namespace metrics milliseconds Gets Namespace Workflow Timing Metrics GET /api/namespaces/{namespace}/metrics/successful namespace metrics successful Gets Namespace Successful Workflow Instances Metrics GET /api/namespaces/{namespace}/tree/{workflow}?op=metrics-invoked workflow metrics invoked Gets Invoked Workflow Metrics GET /api/namespaces/{namespace}/tree/{workflow}?op=metrics-failed workflow metrics milliseconds Gets Workflow Time Metrics GET /api/namespaces/{namespace}/tree/{workflow}?op=metrics-sankey workflow metrics sankey Get Sankey metrics of a workflow revision. GET /api/namespaces/{namespace}/tree/{workflow}?op=metrics-state-milliseconds workflow metrics state milliseconds Gets a Workflow State Time Metrics GET /api/namespaces/{namespace}/tree/{workflow}?op=metrics-successful workflow metrics successful Gets Successful Workflow Metrics"},{"location":"api/#namespace_services","title":"namespace_services","text":"Method URI Name Summary POST /api/functions/namespaces/{namespace} create namespace service Create Namespace Service DELETE /api/functions/namespaces/{namespace}/function/{serviceName}/revisions/{revisionGeneration} delete namespace revision Delete Namespace Service Revision DELETE /api/functions/namespaces/{namespace}/function/{serviceName} delete namespace service Delete Namespace Service GET /api/functions/namespaces/{namespace}/function/{serviceName} get namespace service Get Namespace Service Details GET /api/functions/namespaces/{namespace} get namespace service list Get Namespace Services List GET /api/functions/namespaces/{namespace}/function/{serviceName}/revisions/{revisionGeneration}/pods list namespace service revision pods Get Namespace Service Revision Pods List POST /api/functions/namespaces/{namespace}/function/{serviceName} update namespace service Create Namespace Service Revision GET /api/functions/namespaces/{namespace}/function/{serviceName}/revisions/{revisionGeneration} watch namespace service revision Watch Namespace Service Revision GET /api/functions/namespaces/{namespace}/function/{serviceName}/revisions watch namespace service revision list Watch Namespace Service Revision List"},{"location":"api/#namespaces","title":"namespaces","text":"Method URI Name Summary PUT /api/namespaces/{namespace} create namespace Creates a namespace DELETE /api/namespaces/{namespace} delete namespace Delete a namespace GET /api/namespaces/{namespace}/config get namespace config Gets a namespace config GET /api/namespaces get namespaces Gets the list of namespaces PATCH /api/namespaces/{namespace}/config set namespace config Sets a namespace config"},{"location":"api/#node","title":"node","text":"Method URI Name Summary DELETE /api/namespaces/{namespace}/tree/{node}?op=delete-node delete node Delete a node GET /api/namespaces/{namespace}/tree/{nodePath} get nodes Get List of Namespace Nodes"},{"location":"api/#operations","title":"operations","text":"Method URI Name Summary POST /api/functions/registries/test test registry Test a registry to make sure the connection is okay"},{"location":"api/#other","title":"other","text":"Method URI Name Summary POST /api/namespaces/{namespace}/broadcast broadcast cloudevent Broadcast Cloud Event POST /api/namespaces/{namespace}/broadcast/{filtername} broadcast cloudevent filter Filter given cloud event and broadcast it POST /api/jq jq playground JQ Playground api to test jq queries POST /api/namespaces/{namespace}/events/{event}/replay replay cloudevent Replay Cloud Event GET /api/version version Returns version information for servers in the cluster."},{"location":"api/#pod","title":"pod","text":"Method URI Name Summary GET /api/logs/{pod} pod logs Watch Pod Logs"},{"location":"api/#registries","title":"registries","text":"Method URI Name Summary POST /api/functions/registries/namespaces/{namespace} create registry Create a Namespace Container Registry DELETE /api/functions/registries/namespaces/{namespace} delete registry Delete a Namespace Container Registry GET /api/functions/registries/namespaces/{namespace} get registries Get List of Namespace Registries"},{"location":"api/#secrets","title":"secrets","text":"Method URI Name Summary PUT /api/namespaces/{namespace}/secrets/{folder} create folder Create a Namespace Folder PUT /api/namespaces/{namespace}/secrets/{secret} create secret Create a Namespace Secret DELETE /api/namespaces/{namespace}/secrets/{folder} delete folder Delete a Namespace Folder DELETE /api/namespaces/{namespace}/secrets/{secret} delete secret Delete a Namespace Secret GET /api/namespaces/{namespace}/secrets get secrets Get List of Namespace Secrets or Search for Namespace Secrets by given name GET /api/namespaces/{namespace}/secrets/{folder} get secrets inside folder Get List of Namespace nodes inside Folder PATCH /api/namespaces/{namespace}/secrets/{secret} overwrite and search secret Overwrite a Namespace Secret"},{"location":"api/#variables","title":"variables","text":"Method URI Name Summary DELETE /api/namespaces/{namespace}/instances/{instance}/vars/{variable} delete instance variable Delete a Instance Variable DELETE /api/namespaces/{namespace}/vars/{variable} delete namespace variable Delete a Namespace Variable DELETE /api/namespaces/{namespace}/tree/{workflow}?op=delete-var delete workflow variable Delete a Workflow Variable GET /api/namespaces/{namespace}/instances/{instance}/vars/{variable} get instance variable Get a Instance Variable GET /api/namespaces/{namespace}/instances/{instance}/vars get instance variables Get List of Instance Variable GET /api/namespaces/{namespace}/vars/{variable} get namespace variable Get a Namespace Variable GET /api/namespaces/{namespace}/vars get namespace variables Get Namespace Variable List GET /api/namespaces/{namespace}/tree/{workflow}?op=var get workflow variable Get a Workflow Variable GET /api/namespaces/{namespace}/tree/{workflow}?op=vars get workflow variables Get List of Workflow Variables PUT /api/namespaces/{namespace}/instances/{instance}/vars/{variable} set instance variable Set a Instance Variable PUT /api/namespaces/{namespace}/vars/{variable} set namespace variable Set a Namespace Variable PUT /api/namespaces/{namespace}/tree/{workflow}?op=set-var set workflow variable Set a Workflow Variable"},{"location":"api/#workflow_services","title":"workflow_services","text":"Method URI Name Summary DELETE /api/functions/namespaces/{namespace}/tree/{workflow}?op=delete-service delete workflow service Delete Namespace Service GET /api/functions/namespaces/{namespace}/tree/{workflow}?op=function get workflow service Get Workflow Service Details GET /api/functions/namespaces/{namespace}/tree/{workflow}?op=function-revision get workflow service revision Get Workflow Service Revision GET /api/functions/namespaces/{namespace}/tree/{workflow}?op=function-revisions get workflow service revision list Get Workflow Service Revision List GET /api/functions/namespaces/{namespace}/tree/{workflow}?op=pods list workflow service revision pods Get Workflow Service Revision Pods List GET /api/functions/namespaces/{namespace}/tree/{workflow}?op=services list workflow services Get Workflow Services List"},{"location":"api/#workflows","title":"workflows","text":"Method URI Name Summary GET /api/namespaces/{namespace}/tree/{workflow}?op=wait await execute workflow Await Execute a Workflow POST /api/namespaces/{namespace}/tree/{workflow}?op=wait await execute workflow body Await Execute a Workflow With Body PUT /api/namespaces/{namespace}/tree/{workflow}?op=create-workflow create workflow Create a Workflow POST /api/namespaces/{namespace}/tree/{workflow}?op=execute execute workflow Execute a Workflow POST /api/namespaces/{namespace}/tree/{workflow}?op=set-workflow-event-logging set workflow cloud event logs Set Cloud Event for Workflow to Log to POST /api/namespaces/{namespace}/tree/{workflow}?op=toggle toggle workflow Set Cloud Event for Workflow to Log to POST /api/namespaces/{namespace}/tree/{workflow}?op=update-workflow update workflow Update a Workflow"},{"location":"api/#paths","title":"Paths","text":""},{"location":"api/#await-execute-a-workflow-awaitexecuteworkflow","title":"Await Execute a Workflow (awaitExecuteWorkflow)","text":"<pre><code>GET /api/namespaces/{namespace}/tree/{workflow}?op=wait\n</code></pre> <p>Executes a workflow. This path will wait until the workflow execution has completed and return the instance output. NOTE: Input can also be provided with the <code>input.X</code> query parameters; Where <code>X</code> is the json key. Only top level json keys are supported when providing input with query parameters.</p>"},{"location":"api/#parameters","title":"Parameters","text":"Name Source Type Go type Separator Required Default Description namespace <code>path</code> string <code>string</code> \u2713 target namespace workflow <code>path</code> string <code>string</code> \u2713 path to target workflow ctype <code>query</code> string <code>string</code> Manually set the Content-Type response header instead of auto-detected. This doesn't change the body of the response in any way. field <code>query</code> string <code>string</code> If provided, instead of returning the entire output json the response body will contain the single top-level json field raw-output <code>query</code> boolean <code>bool</code> If set to true, will return an empty output as null, encoded base64 data as decoded binary data, and quoted json strings as a escaped string."},{"location":"api/#all-responses","title":"All responses","text":"Code Status Description Has headers Schema 200 OK successfully executed workflow schema"},{"location":"api/#responses","title":"Responses","text":""},{"location":"api/#200-successfully-executed-workflow","title":"200 - successfully executed workflow","text":"<p>Status: OK</p>"},{"location":"api/#schema","title":"Schema","text":""},{"location":"api/#await-execute-a-workflow-with-body-awaitexecuteworkflowbody","title":"Await Execute a Workflow With Body (awaitExecuteWorkflowBody)","text":"<pre><code>POST /api/namespaces/{namespace}/tree/{workflow}?op=wait\n</code></pre> <p>Executes a workflow with optionally some input provided in the request body as json. This path will wait until the workflow execution has completed and return the instance output. NOTE: Input can also be provided with the <code>input.X</code> query parameters; Where <code>X</code> is the json key. Only top level json keys are supported when providing input with query parameters. Input query parameters are only read if the request has no body.</p>"},{"location":"api/#parameters_1","title":"Parameters","text":"Name Source Type Go type Separator Required Default Description namespace <code>path</code> string <code>string</code> \u2713 target namespace workflow <code>path</code> string <code>string</code> \u2713 path to target workflow ctype <code>query</code> string <code>string</code> Manually set the Content-Type response header instead of auto-detected. This doesn't change the body of the response in any way. field <code>query</code> string <code>string</code> If provided, instead of returning the entire output json the response body will contain the single top-level json field raw-output <code>query</code> boolean <code>bool</code> If set to true, will return an empty output as null, encoded base64 data as decoded binary data, and quoted json strings as a escaped string. Workflow Input <code>body</code> interface{} <code>interface{}</code> \u2713 The input of this workflow instance"},{"location":"api/#all-responses_1","title":"All responses","text":"Code Status Description Has headers Schema 200 OK successfully executed workflow schema"},{"location":"api/#responses_1","title":"Responses","text":""},{"location":"api/#200-successfully-executed-workflow_1","title":"200 - successfully executed workflow","text":"<p>Status: OK</p>"},{"location":"api/#schema_1","title":"Schema","text":""},{"location":"api/#broadcast-cloud-event-broadcastcloudevent","title":"Broadcast Cloud Event (broadcastCloudevent)","text":"<pre><code>POST /api/namespaces/{namespace}/broadcast\n</code></pre> <p>Broadcast a cloud event to a namespace. Cloud events posted to this api will be picked up by any workflows listening to the same event type on the namescape. The body of this request should follow the cloud event core specification defined at https://github.com/cloudevents/spec .</p>"},{"location":"api/#parameters_2","title":"Parameters","text":"Name Source Type Go type Separator Required Default Description namespace <code>path</code> string <code>string</code> \u2713 target namespace cloudevent <code>body</code> interface{} <code>interface{}</code> \u2713 Cloud Event request to be sent."},{"location":"api/#all-responses_2","title":"All responses","text":"Code Status Description Has headers Schema 200 OK successfully sent cloud event schema"},{"location":"api/#responses_2","title":"Responses","text":""},{"location":"api/#200-successfully-sent-cloud-event","title":"200 - successfully sent cloud event","text":"<p>Status: OK</p>"},{"location":"api/#schema_2","title":"Schema","text":""},{"location":"api/#filter-given-cloud-event-and-broadcast-it-broadcastcloudeventfilter","title":"Filter given cloud event and broadcast it (broadcastCloudeventFilter)","text":"<pre><code>POST /api/namespaces/{namespace}/broadcast/{filtername}\n</code></pre> <p>Filter cloud event by given filtername and broadcast to a namespace. Cloud events posted to this api will filter cloud event by given filtername and be picked up by any workflows listening to the same event type on the namescape. The body of this request should follow the cloud event core specification defined at https://github.com/cloudevents/spec .</p>"},{"location":"api/#parameters_3","title":"Parameters","text":"Name Source Type Go type Separator Required Default Description filtername <code>path</code> string <code>string</code> \u2713 target filtername namespace <code>path</code> string <code>string</code> \u2713 target namespace cloudevent <code>body</code> interface{} <code>interface{}</code> \u2713 Cloud Event request to be sent."},{"location":"api/#all-responses_3","title":"All responses","text":"Code Status Description Has headers Schema 200 OK schema"},{"location":"api/#responses_3","title":"Responses","text":""},{"location":"api/#200","title":"200","text":"<p>Status: OK</p>"},{"location":"api/#schema_3","title":"Schema","text":""},{"location":"api/#cancel-a-pending-instance-cancelinstance","title":"Cancel a Pending Instance (cancelInstance)","text":"<pre><code>POST /api/namespaces/{namespace}/instances/{instance}/cancel\n</code></pre> <p>Cancel a currently pending instance.</p>"},{"location":"api/#parameters_4","title":"Parameters","text":"Name Source Type Go type Separator Required Default Description instance <code>path</code> string <code>string</code> \u2713 target instance namespace <code>path</code> string <code>string</code> \u2713 target namespace"},{"location":"api/#all-responses_4","title":"All responses","text":"Code Status Description Has headers Schema 200 OK successfully cancelled instance schema"},{"location":"api/#responses_4","title":"Responses","text":""},{"location":"api/#200-successfully-cancelled-instance","title":"200 - successfully cancelled instance","text":"<p>Status: OK</p>"},{"location":"api/#schema_4","title":"Schema","text":""},{"location":"api/#creates-new-cloudeventfilter-createcloudeventfilter","title":"Creates new cloudEventFilter (createCloudeventFilter)","text":"<pre><code>POST /api/namespaces/{namespace}/eventfilter/{filtername}\n</code></pre> <p>Creates new cloud event filter in target namespace The body of this request should be a compilable javascript code without function header.</p>"},{"location":"api/#parameters_5","title":"Parameters","text":"Name Source Type Go type Separator Required Default Description filtername <code>path</code> string <code>string</code> \u2713 new filtername namespace <code>path</code> string <code>string</code> \u2713 target namespace script <code>body</code> interface{} <code>interface{}</code> \u2713 compilable javascript code."},{"location":"api/#all-responses_5","title":"All responses","text":"Code Status Description Has headers Schema 200 OK schema"},{"location":"api/#responses_5","title":"Responses","text":""},{"location":"api/#200_1","title":"200","text":"<p>Status: OK</p>"},{"location":"api/#schema_5","title":"Schema","text":""},{"location":"api/#create-a-directory-createdirectory","title":"Create a Directory (createDirectory)","text":"<pre><code>PUT /api/namespaces/{namespace}/tree/{directory}?op=create-directory\n</code></pre> <p>Creates a directory at the target path.</p>"},{"location":"api/#parameters_6","title":"Parameters","text":"Name Source Type Go type Separator Required Default Description directory <code>path</code> string <code>string</code> \u2713 path to target directory namespace <code>path</code> string <code>string</code> \u2713 target namespace op <code>query</code> string <code>string</code> \u2713 <code>\"create-directory\"</code> the operation for the api"},{"location":"api/#all-responses_6","title":"All responses","text":"Code Status Description Has headers Schema 200 OK directory has been created schema default an error has occurred schema"},{"location":"api/#responses_6","title":"Responses","text":""},{"location":"api/#200-directory-has-been-created","title":"200 - directory has been created","text":"<p>Status: OK</p>"},{"location":"api/#schema_6","title":"Schema","text":"<p>OkBody</p>"},{"location":"api/#default-response","title":"Default Response","text":"<p>an error has occurred</p>"},{"location":"api/#schema_7","title":"Schema","text":"<p>ErrorResponse</p>"},{"location":"api/#create-a-namespace-folder-createfolder","title":"Create a Namespace Folder (createFolder)","text":"<pre><code>PUT /api/namespaces/{namespace}/secrets/{folder}\n</code></pre> <p>Create a namespace folder.</p>"},{"location":"api/#parameters_7","title":"Parameters","text":"Name Source Type Go type Separator Required Default Description folder <code>path</code> string <code>string</code> \u2713 target secret namespace <code>path</code> string <code>string</code> \u2713 target namespace"},{"location":"api/#all-responses_7","title":"All responses","text":"Code Status Description Has headers Schema 200 OK namespace folder has been successfully created schema default an error has occurred schema"},{"location":"api/#responses_7","title":"Responses","text":""},{"location":"api/#200-namespace-folder-has-been-successfully-created","title":"200 - namespace folder has been successfully created","text":"<p>Status: OK</p>"},{"location":"api/#schema_8","title":"Schema","text":"<p>OkBody</p>"},{"location":"api/#default-response_1","title":"Default Response","text":"<p>an error has occurred</p>"},{"location":"api/#schema_9","title":"Schema","text":"<p>ErrorResponse</p>"},{"location":"api/#creates-a-namespace-createnamespace","title":"Creates a namespace (createNamespace)","text":"<pre><code>PUT /api/namespaces/{namespace}\n</code></pre> <p>Creates a new namespace.</p>"},{"location":"api/#parameters_8","title":"Parameters","text":"Name Source Type Go type Separator Required Default Description namespace <code>path</code> string <code>string</code> \u2713 target namespace to create"},{"location":"api/#all-responses_8","title":"All responses","text":"Code Status Description Has headers Schema 200 OK namespace has been successfully created schema default an error has occurred schema"},{"location":"api/#responses_8","title":"Responses","text":""},{"location":"api/#200-namespace-has-been-successfully-created","title":"200 - namespace has been successfully created","text":"<p>Status: OK</p>"},{"location":"api/#schema_10","title":"Schema","text":"<p>OkBody</p>"},{"location":"api/#default-response_2","title":"Default Response","text":"<p>an error has occurred</p>"},{"location":"api/#schema_11","title":"Schema","text":"<p>ErrorResponse</p>"},{"location":"api/#create-namespace-service-createnamespaceservice","title":"Create Namespace Service (createNamespaceService)","text":"<pre><code>POST /api/functions/namespaces/{namespace}\n</code></pre> <p>Creates namespace scoped knative service. Service Names are unique on a scope level. These services can be used as functions in workflows, more about this can be read here: https://docs.direktiv.io/docs/walkthrough/using-functions.html</p>"},{"location":"api/#parameters_9","title":"Parameters","text":"Name Source Type Go type Separator Required Default Description namespace <code>path</code> string <code>string</code> \u2713 target namespace Service <code>body</code> CreateNamespaceServiceBody <code>CreateNamespaceServiceBody</code> \u2713 Payload that contains information on new service"},{"location":"api/#all-responses_9","title":"All responses","text":"Code Status Description Has headers Schema 200 OK successfully created service schema"},{"location":"api/#responses_9","title":"Responses","text":""},{"location":"api/#200-successfully-created-service","title":"200 - successfully created service","text":"<p>Status: OK</p>"},{"location":"api/#schema_12","title":"Schema","text":""},{"location":"api/#inlined-models","title":"Inlined models","text":"<p> CreateNamespaceServiceBody</p> <p>Properties</p> Name Type Go type Required Default Description Example cmd string <code>string</code> \u2713 envs map of string <code>map[string]string</code> image string <code>string</code> \u2713 Target image a service will use minScale integer <code>int64</code> \u2713 Minimum amount of service pods to be live name string <code>string</code> \u2713 Name of new service size integer <code>int64</code> \u2713 Size of created service pods, 0 = small, 1 = medium, 2 = large"},{"location":"api/#create-a-namespace-container-registry-createregistry","title":"Create a Namespace Container Registry (createRegistry)","text":"<pre><code>POST /api/functions/registries/namespaces/{namespace}\n</code></pre> <p>Create a namespace container registry. This can be used to connect your workflows to private container registries that require tokens. The data property in the body is made up from the registry user and token. It follows the pattern : data=USER:TOKEN</p>"},{"location":"api/#parameters_10","title":"Parameters","text":"Name Source Type Go type Separator Required Default Description namespace <code>path</code> string <code>string</code> \u2713 target namespace Registry Payload <code>body</code> CreateRegistryBody <code>CreateRegistryBody</code> \u2713 Payload that contains registry data"},{"location":"api/#all-responses_10","title":"All responses","text":"Code Status Description Has headers Schema 200 OK successfully created namespace registry schema"},{"location":"api/#responses_10","title":"Responses","text":""},{"location":"api/#200-successfully-created-namespace-registry","title":"200 - successfully created namespace registry","text":"<p>Status: OK</p>"},{"location":"api/#schema_13","title":"Schema","text":""},{"location":"api/#inlined-models_1","title":"Inlined models","text":"<p> CreateRegistryBody</p> <p>Properties</p> Name Type Go type Required Default Description Example data string <code>string</code> \u2713 Target registry connection data containing the user and token. reg string <code>string</code> \u2713 Target registry URL"},{"location":"api/#create-a-namespace-secret-createsecret","title":"Create a Namespace Secret (createSecret)","text":"<pre><code>PUT /api/namespaces/{namespace}/secrets/{secret}\n</code></pre> <p>Create a namespace secret.</p>"},{"location":"api/#consumes_1","title":"Consumes","text":"<ul> <li>text/plain</li> </ul>"},{"location":"api/#parameters_11","title":"Parameters","text":"Name Source Type Go type Separator Required Default Description namespace <code>path</code> string <code>string</code> \u2713 target namespace secret <code>path</code> string <code>string</code> \u2713 target secret Secret Payload <code>body</code> string <code>string</code> \u2713 Payload that contains secret data."},{"location":"api/#all-responses_11","title":"All responses","text":"Code Status Description Has headers Schema 200 OK namespace secret has been successfully created schema default an error has occurred schema"},{"location":"api/#responses_11","title":"Responses","text":""},{"location":"api/#200-namespace-secret-has-been-successfully-created","title":"200 - namespace secret has been successfully created","text":"<p>Status: OK</p>"},{"location":"api/#schema_14","title":"Schema","text":"<p>OkBody</p>"},{"location":"api/#default-response_3","title":"Default Response","text":"<p>an error has occurred</p>"},{"location":"api/#schema_15","title":"Schema","text":"<p>ErrorResponse</p>"},{"location":"api/#create-a-workflow-createworkflow","title":"Create a Workflow (createWorkflow)","text":"<pre><code>PUT /api/namespaces/{namespace}/tree/{workflow}?op=create-workflow\n</code></pre> <p>Creates a workflow at the target path. The body of this request should contain the workflow yaml.</p>"},{"location":"api/#consumes_2","title":"Consumes","text":"<ul> <li>text/plain</li> </ul>"},{"location":"api/#parameters_12","title":"Parameters","text":"Name Source Type Go type Separator Required Default Description namespace <code>path</code> string <code>string</code> \u2713 target namespace workflow <code>path</code> string <code>string</code> \u2713 path to target workflow op <code>query</code> string <code>string</code> \u2713 <code>\"create-workflow\"</code> the operation for the api workflow data <code>body</code> string <code>string</code> Payload that contains the direktiv workflow yaml to create."},{"location":"api/#all-responses_12","title":"All responses","text":"Code Status Description Has headers Schema 200 OK successfully created workflow schema default an error has occurred schema"},{"location":"api/#responses_12","title":"Responses","text":""},{"location":"api/#200-successfully-created-workflow","title":"200 - successfully created workflow","text":"<p>Status: OK</p>"},{"location":"api/#schema_16","title":"Schema","text":"<p>OkBody</p>"},{"location":"api/#default-response_4","title":"Default Response","text":"<p>an error has occurred</p>"},{"location":"api/#schema_17","title":"Schema","text":"<p>ErrorResponse</p>"},{"location":"api/#delete-existing-cloudeventfilter-deletecloudeventfilter","title":"Delete existing cloudEventFilter (deleteCloudeventFilter)","text":"<pre><code>DELETE /api/namespaces/{namespace}/eventfilter/{filtername}\n</code></pre> <p>Delete existing cloud event filter in target namespace</p>"},{"location":"api/#parameters_13","title":"Parameters","text":"Name Source Type Go type Separator Required Default Description filtername <code>path</code> string <code>string</code> \u2713 target filtername namespace <code>path</code> string <code>string</code> \u2713 target namespace"},{"location":"api/#all-responses_13","title":"All responses","text":"Code Status Description Has headers Schema 200 OK schema"},{"location":"api/#responses_13","title":"Responses","text":""},{"location":"api/#200_2","title":"200","text":"<p>Status: OK</p>"},{"location":"api/#schema_18","title":"Schema","text":""},{"location":"api/#delete-a-namespace-folder-deletefolder","title":"Delete a Namespace Folder (deleteFolder)","text":"<pre><code>DELETE /api/namespaces/{namespace}/secrets/{folder}\n</code></pre> <p>Delete a namespace folder.</p>"},{"location":"api/#parameters_14","title":"Parameters","text":"Name Source Type Go type Separator Required Default Description folder <code>path</code> string <code>string</code> \u2713 target folder namespace <code>path</code> string <code>string</code> \u2713 target namespace"},{"location":"api/#all-responses_14","title":"All responses","text":"Code Status Description Has headers Schema 200 OK namespace folder has been successfully deleted schema default folder not found schema"},{"location":"api/#responses_14","title":"Responses","text":""},{"location":"api/#200-namespace-folder-has-been-successfully-deleted","title":"200 - namespace folder has been successfully deleted","text":"<p>Status: OK</p>"},{"location":"api/#schema_19","title":"Schema","text":"<p>OkBody</p>"},{"location":"api/#default-response_5","title":"Default Response","text":"<p>folder not found</p>"},{"location":"api/#schema_20","title":"Schema","text":"<p>ErrorResponse</p>"},{"location":"api/#delete-a-instance-variable-deleteinstancevariable","title":"Delete a Instance Variable (deleteInstanceVariable)","text":"<pre><code>DELETE /api/namespaces/{namespace}/instances/{instance}/vars/{variable}\n</code></pre> <p>Delete a instance variable.</p>"},{"location":"api/#parameters_15","title":"Parameters","text":"Name Source Type Go type Separator Required Default Description instance <code>path</code> string <code>string</code> \u2713 target instance namespace <code>path</code> string <code>string</code> \u2713 target namespace variable <code>path</code> string <code>string</code> \u2713 target variable"},{"location":"api/#all-responses_15","title":"All responses","text":"Code Status Description Has headers Schema 200 OK successfully deleted instance variable schema"},{"location":"api/#responses_15","title":"Responses","text":""},{"location":"api/#200-successfully-deleted-instance-variable","title":"200 - successfully deleted instance variable","text":"<p>Status: OK</p>"},{"location":"api/#schema_21","title":"Schema","text":""},{"location":"api/#delete-a-namespace-deletenamespace","title":"Delete a namespace (deleteNamespace)","text":"<pre><code>DELETE /api/namespaces/{namespace}\n</code></pre> <p>Delete a namespace. A namespace will not delete by default if it has any child resources (workflows, etc...). Deleting the namespace with all its children can be done using the <code>recursive</code> query parameter.</p>"},{"location":"api/#parameters_16","title":"Parameters","text":"Name Source Type Go type Separator Required Default Description namespace <code>path</code> string <code>string</code> \u2713 target namespace to delete recursive <code>query</code> boolean <code>bool</code> recursively deletes all child resources"},{"location":"api/#all-responses_16","title":"All responses","text":"Code Status Description Has headers Schema 200 OK namespace has been successfully deleted schema default an error has occurred schema"},{"location":"api/#responses_16","title":"Responses","text":""},{"location":"api/#200-namespace-has-been-successfully-deleted","title":"200 - namespace has been successfully deleted","text":"<p>Status: OK</p>"},{"location":"api/#schema_22","title":"Schema","text":"<p>OkBody</p>"},{"location":"api/#default-response_6","title":"Default Response","text":"<p>an error has occurred</p>"},{"location":"api/#schema_23","title":"Schema","text":"<p>ErrorResponse</p>"},{"location":"api/#delete-namespace-service-revision-deletenamespacerevision","title":"Delete Namespace Service Revision (deleteNamespaceRevision)","text":"<pre><code>DELETE /api/functions/namespaces/{namespace}/function/{serviceName}/revisions/{revisionGeneration}\n</code></pre> <p>Delete a namespace scoped knative service revision. The target revision generation is the number suffix on a revision. Example: A revision named 'namespace-direktiv-fast-request-00003' would have the revisionGeneration '00003'.</p>"},{"location":"api/#parameters_17","title":"Parameters","text":"Name Source Type Go type Separator Required Default Description namespace <code>path</code> string <code>string</code> \u2713 target namespace revisionGeneration <code>path</code> string <code>string</code> \u2713 target revision generation serviceName <code>path</code> string <code>string</code> \u2713 target service name"},{"location":"api/#all-responses_17","title":"All responses","text":"Code Status Description Has headers Schema 200 OK successfully deleted service revision schema"},{"location":"api/#responses_17","title":"Responses","text":""},{"location":"api/#200-successfully-deleted-service-revision","title":"200 - successfully deleted service revision","text":"<p>Status: OK</p>"},{"location":"api/#schema_24","title":"Schema","text":""},{"location":"api/#delete-namespace-service-deletenamespaceservice","title":"Delete Namespace Service (deleteNamespaceService)","text":"<pre><code>DELETE /api/functions/namespaces/{namespace}/function/{serviceName}\n</code></pre> <p>Deletes namespace scoped knative service and all its revisions.</p>"},{"location":"api/#parameters_18","title":"Parameters","text":"Name Source Type Go type Separator Required Default Description namespace <code>path</code> string <code>string</code> \u2713 target namespace serviceName <code>path</code> string <code>string</code> \u2713 target service name"},{"location":"api/#all-responses_18","title":"All responses","text":"Code Status Description Has headers Schema 200 OK successfully deleted service schema"},{"location":"api/#responses_18","title":"Responses","text":""},{"location":"api/#200-successfully-deleted-service","title":"200 - successfully deleted service","text":"<p>Status: OK</p>"},{"location":"api/#schema_25","title":"Schema","text":""},{"location":"api/#delete-a-namespace-variable-deletenamespacevariable","title":"Delete a Namespace Variable (deleteNamespaceVariable)","text":"<pre><code>DELETE /api/namespaces/{namespace}/vars/{variable}\n</code></pre> <p>Delete a namespace variable.</p>"},{"location":"api/#parameters_19","title":"Parameters","text":"Name Source Type Go type Separator Required Default Description namespace <code>path</code> string <code>string</code> \u2713 target namespace variable <code>path</code> string <code>string</code> \u2713 target variable"},{"location":"api/#all-responses_19","title":"All responses","text":"Code Status Description Has headers Schema 200 OK successfully deleted namespace variable schema"},{"location":"api/#responses_19","title":"Responses","text":""},{"location":"api/#200-successfully-deleted-namespace-variable","title":"200 - successfully deleted namespace variable","text":"<p>Status: OK</p>"},{"location":"api/#schema_26","title":"Schema","text":""},{"location":"api/#delete-a-node-deletenode","title":"Delete a node (deleteNode)","text":"<pre><code>DELETE /api/namespaces/{namespace}/tree/{node}?op=delete-node\n</code></pre> <p>Creates a directory at the target path.</p>"},{"location":"api/#parameters_20","title":"Parameters","text":"Name Source Type Go type Separator Required Default Description namespace <code>path</code> string <code>string</code> \u2713 target namespace node <code>path</code> string <code>string</code> \u2713 path to target node op <code>query</code> string <code>string</code> \u2713 <code>\"delete-node\"</code> the operation for the api recursive <code>query</code> boolean <code>bool</code> whether to recursively delete child nodes"},{"location":"api/#all-responses_20","title":"All responses","text":"Code Status Description Has headers Schema 200 OK node has been deleted schema default an error has occurred schema"},{"location":"api/#responses_20","title":"Responses","text":""},{"location":"api/#200-node-has-been-deleted","title":"200 - node has been deleted","text":"<p>Status: OK</p>"},{"location":"api/#schema_27","title":"Schema","text":"<p>OkBody</p>"},{"location":"api/#default-response_7","title":"Default Response","text":"<p>an error has occurred</p>"},{"location":"api/#schema_28","title":"Schema","text":"<p>ErrorResponse</p>"},{"location":"api/#delete-a-namespace-container-registry-deleteregistry","title":"Delete a Namespace Container Registry (deleteRegistry)","text":"<pre><code>DELETE /api/functions/registries/namespaces/{namespace}\n</code></pre> <p>Delete a namespace container registry</p>"},{"location":"api/#parameters_21","title":"Parameters","text":"Name Source Type Go type Separator Required Default Description namespace <code>path</code> string <code>string</code> \u2713 target namespace Registry Payload <code>body</code> DeleteRegistryBody <code>DeleteRegistryBody</code> \u2713 Payload that contains registry data"},{"location":"api/#all-responses_21","title":"All responses","text":"Code Status Description Has headers Schema 200 OK successfully delete namespace registry schema"},{"location":"api/#responses_21","title":"Responses","text":""},{"location":"api/#200-successfully-delete-namespace-registry","title":"200 - successfully delete namespace registry","text":"<p>Status: OK</p>"},{"location":"api/#schema_29","title":"Schema","text":""},{"location":"api/#inlined-models_2","title":"Inlined models","text":"<p> DeleteRegistryBody</p> <p>Properties</p> Name Type Go type Required Default Description Example reg string <code>string</code> \u2713 Target registry URL"},{"location":"api/#delete-a-namespace-secret-deletesecret","title":"Delete a Namespace Secret (deleteSecret)","text":"<pre><code>DELETE /api/namespaces/{namespace}/secrets/{secret}\n</code></pre> <p>Delete a namespace secret.</p>"},{"location":"api/#parameters_22","title":"Parameters","text":"Name Source Type Go type Separator Required Default Description namespace <code>path</code> string <code>string</code> \u2713 target namespace secret <code>path</code> string <code>string</code> \u2713 target secret"},{"location":"api/#all-responses_22","title":"All responses","text":"Code Status Description Has headers Schema 200 OK namespace secret has been successfully deleted schema default secret not found schema"},{"location":"api/#responses_22","title":"Responses","text":""},{"location":"api/#200-namespace-secret-has-been-successfully-deleted","title":"200 - namespace secret has been successfully deleted","text":"<p>Status: OK</p>"},{"location":"api/#schema_30","title":"Schema","text":"<p>OkBody</p>"},{"location":"api/#default-response_8","title":"Default Response","text":"<p>secret not found</p>"},{"location":"api/#schema_31","title":"Schema","text":"<p>ErrorResponse</p>"},{"location":"api/#delete-namespace-service-deleteworkflowservice","title":"Delete Namespace Service (deleteWorkflowService)","text":"<pre><code>DELETE /api/functions/namespaces/{namespace}/tree/{workflow}?op=delete-service\n</code></pre> <p>Deletes workflow scoped knative service.</p>"},{"location":"api/#parameters_23","title":"Parameters","text":"Name Source Type Go type Separator Required Default Description namespace <code>path</code> string <code>string</code> \u2713 target namespace workflow <code>path</code> string <code>string</code> \u2713 path to target workflow svn <code>query</code> string <code>string</code> \u2713 target service name version <code>query</code> string <code>string</code> \u2713 target service version"},{"location":"api/#all-responses_23","title":"All responses","text":"Code Status Description Has headers Schema 200 OK successfully deleted service schema"},{"location":"api/#responses_23","title":"Responses","text":""},{"location":"api/#200-successfully-deleted-service_1","title":"200 - successfully deleted service","text":"<p>Status: OK</p>"},{"location":"api/#schema_32","title":"Schema","text":""},{"location":"api/#delete-a-workflow-variable-deleteworkflowvariable","title":"Delete a Workflow Variable (deleteWorkflowVariable)","text":"<pre><code>DELETE /api/namespaces/{namespace}/tree/{workflow}?op=delete-var\n</code></pre> <p>Delete a workflow variable.</p>"},{"location":"api/#parameters_24","title":"Parameters","text":"Name Source Type Go type Separator Required Default Description namespace <code>path</code> string <code>string</code> \u2713 target namespace workflow <code>path</code> string <code>string</code> \u2713 path to target workflow var <code>query</code> string <code>string</code> \u2713 target variable"},{"location":"api/#all-responses_24","title":"All responses","text":"Code Status Description Has headers Schema 200 OK successfully deleted workflow variable schema"},{"location":"api/#responses_24","title":"Responses","text":""},{"location":"api/#200-successfully-deleted-workflow-variable","title":"200 - successfully deleted workflow variable","text":"<p>Status: OK</p>"},{"location":"api/#schema_33","title":"Schema","text":""},{"location":"api/#execute-a-workflow-executeworkflow","title":"Execute a Workflow (executeWorkflow)","text":"<pre><code>POST /api/namespaces/{namespace}/tree/{workflow}?op=execute\n</code></pre> <p>Executes a workflow with optionally some input provided in the request body as json.</p>"},{"location":"api/#parameters_25","title":"Parameters","text":"Name Source Type Go type Separator Required Default Description namespace <code>path</code> string <code>string</code> \u2713 target namespace workflow <code>path</code> string <code>string</code> \u2713 path to target workflow op <code>query</code> string <code>string</code> \u2713 <code>\"execute\"</code> the operation for the api Workflow Input <code>body</code> interface{} <code>interface{}</code> \u2713 The input of this workflow instance"},{"location":"api/#all-responses_25","title":"All responses","text":"Code Status Description Has headers Schema 200 OK node has been deleted schema default an error has occurred schema"},{"location":"api/#responses_25","title":"Responses","text":""},{"location":"api/#200-node-has-been-deleted_1","title":"200 - node has been deleted","text":"<p>Status: OK</p>"},{"location":"api/#schema_34","title":"Schema","text":"<p>OkBody</p>"},{"location":"api/#default-response_9","title":"Default Response","text":"<p>an error has occurred</p>"},{"location":"api/#schema_35","title":"Schema","text":"<p>ErrorResponse</p>"},{"location":"api/#get-specific-cloudeventfilter-getcloudeventfilter","title":"Get specific cloudEventFilter (getCloudEventFilter)","text":"<pre><code>GET /api/namespaces/{namespace}/eventfilter/{filtername}\n</code></pre> <p>Get specific cloud event filter by given name in target namespace</p>"},{"location":"api/#parameters_26","title":"Parameters","text":"Name Source Type Go type Separator Required Default Description filtername <code>path</code> string <code>string</code> \u2713 target filtername namespace <code>path</code> string <code>string</code> \u2713 target namespace"},{"location":"api/#all-responses_26","title":"All responses","text":"Code Status Description Has headers Schema 200 OK schema"},{"location":"api/#responses_26","title":"Responses","text":""},{"location":"api/#200_3","title":"200","text":"<p>Status: OK</p>"},{"location":"api/#schema_36","title":"Schema","text":""},{"location":"api/#get-events-history-geteventhistory","title":"Get events history. (getEventHistory)","text":"<pre><code>GET /api/namespaces/{namespace}/events\n</code></pre> <p>Get recent events history.</p>"},{"location":"api/#parameters_27","title":"Parameters","text":"Name Source Type Go type Separator Required Default Description namespace <code>path</code> string <code>string</code> \u2713 target namespace"},{"location":"api/#all-responses_27","title":"All responses","text":"Code Status Description Has headers Schema 200 OK successfully got events history schema"},{"location":"api/#responses_27","title":"Responses","text":""},{"location":"api/#200-successfully-got-events-history","title":"200 - successfully got events history","text":"<p>Status: OK</p>"},{"location":"api/#schema_37","title":"Schema","text":""},{"location":"api/#get-current-event-listeners-geteventlisteners","title":"Get current event listeners. (getEventListeners)","text":"<pre><code>GET /api/namespaces/{namespace}/event-listeners\n</code></pre> <p>Get current event listeners.</p>"},{"location":"api/#parameters_28","title":"Parameters","text":"Name Source Type Go type Separator Required Default Description namespace <code>path</code> string <code>string</code> \u2713 target namespace"},{"location":"api/#all-responses_28","title":"All responses","text":"Code Status Description Has headers Schema 200 OK successfully got event listeners schema"},{"location":"api/#responses_28","title":"Responses","text":""},{"location":"api/#200-successfully-got-event-listeners","title":"200 - successfully got event listeners","text":"<p>Status: OK</p>"},{"location":"api/#schema_38","title":"Schema","text":""},{"location":"api/#get-a-instance-getinstance","title":"Get a Instance (getInstance)","text":"<pre><code>GET /api/namespaces/{namespace}/instances/{instance}\n</code></pre> <p>Gets the details of a executed workflow instance in this namespace.</p>"},{"location":"api/#parameters_29","title":"Parameters","text":"Name Source Type Go type Separator Required Default Description instance <code>path</code> string <code>string</code> \u2713 target instance namespace <code>path</code> string <code>string</code> \u2713 target namespace"},{"location":"api/#all-responses_29","title":"All responses","text":"Code Status Description Has headers Schema 200 OK successfully got instance schema default an error has occurred schema"},{"location":"api/#responses_29","title":"Responses","text":""},{"location":"api/#200-successfully-got-instance","title":"200 - successfully got instance","text":"<p>Status: OK</p>"},{"location":"api/#schema_39","title":"Schema","text":"<p>OkBody</p>"},{"location":"api/#default-response_10","title":"Default Response","text":"<p>an error has occurred</p>"},{"location":"api/#schema_40","title":"Schema","text":"<p>ErrorResponse</p>"},{"location":"api/#get-a-instance-input-getinstanceinput","title":"Get a Instance Input (getInstanceInput)","text":"<pre><code>GET /api/namespaces/{namespace}/instances/{instance}/input\n</code></pre> <p>Gets the input an instance was provided when executed.</p>"},{"location":"api/#parameters_30","title":"Parameters","text":"Name Source Type Go type Separator Required Default Description instance <code>path</code> string <code>string</code> \u2713 target instance namespace <code>path</code> string <code>string</code> \u2713 target namespace"},{"location":"api/#all-responses_30","title":"All responses","text":"Code Status Description Has headers Schema 200 OK successfully got instance input schema"},{"location":"api/#responses_30","title":"Responses","text":""},{"location":"api/#200-successfully-got-instance-input","title":"200 - successfully got instance input","text":"<p>Status: OK</p>"},{"location":"api/#schema_41","title":"Schema","text":""},{"location":"api/#get-list-instances-getinstancelist","title":"Get List Instances (getInstanceList)","text":"<pre><code>GET /api/namespaces/{namespace}/instances\n</code></pre> <p>Gets a list of instances in a namespace.</p>"},{"location":"api/#parameters_31","title":"Parameters","text":"Name Source Type Go type Separator Required Default Description namespace <code>path</code> string <code>string</code> \u2713 target namespace filter.field <code>query</code> string <code>string</code> field to filter filter.type <code>query</code> string <code>string</code> filter behaviour order.direction <code>query</code> string <code>string</code> order direction order.field <code>query</code> string <code>string</code> field to order by"},{"location":"api/#all-responses_31","title":"All responses","text":"Code Status Description Has headers Schema 200 OK successfully got namespace instances schema"},{"location":"api/#responses_31","title":"Responses","text":""},{"location":"api/#200-successfully-got-namespace-instances","title":"200 - successfully got namespace instances","text":"<p>Status: OK</p>"},{"location":"api/#schema_42","title":"Schema","text":""},{"location":"api/#get-a-instance-metadata-getinstancemetadata","title":"Get a Instance Metadata (getInstanceMetadata)","text":"<pre><code>GET /api/namespaces/{namespace}/instances/{instance}/metadata\n</code></pre> <p>Gets the metadata of an instance.</p>"},{"location":"api/#parameters_32","title":"Parameters","text":"Name Source Type Go type Separator Required Default Description instance <code>path</code> string <code>string</code> \u2713 target instance namespace <code>path</code> string <code>string</code> \u2713 target namespace"},{"location":"api/#all-responses_32","title":"All responses","text":"Code Status Description Has headers Schema 200 OK successfully got instance metadata schema"},{"location":"api/#responses_32","title":"Responses","text":""},{"location":"api/#200-successfully-got-instance-metadata","title":"200 - successfully got instance metadata","text":"<p>Status: OK</p>"},{"location":"api/#schema_43","title":"Schema","text":""},{"location":"api/#get-a-instance-output-getinstanceoutput","title":"Get a Instance Output (getInstanceOutput)","text":"<pre><code>GET /api/namespaces/{namespace}/instances/{instance}/output\n</code></pre> <p>Gets the output an instance was provided when executed.</p>"},{"location":"api/#parameters_33","title":"Parameters","text":"Name Source Type Go type Separator Required Default Description instance <code>path</code> string <code>string</code> \u2713 target instance namespace <code>path</code> string <code>string</code> \u2713 target namespace"},{"location":"api/#all-responses_33","title":"All responses","text":"Code Status Description Has headers Schema 200 OK successfully got instance output schema"},{"location":"api/#responses_33","title":"Responses","text":""},{"location":"api/#200-successfully-got-instance-output","title":"200 - successfully got instance output","text":"<p>Status: OK</p>"},{"location":"api/#schema_44","title":"Schema","text":""},{"location":"api/#get-a-instance-variable-getinstancevariable","title":"Get a Instance Variable (getInstanceVariable)","text":"<pre><code>GET /api/namespaces/{namespace}/instances/{instance}/vars/{variable}\n</code></pre> <p>Get the value sorted in a instance variable.</p>"},{"location":"api/#parameters_34","title":"Parameters","text":"Name Source Type Go type Separator Required Default Description instance <code>path</code> string <code>string</code> \u2713 target instance namespace <code>path</code> string <code>string</code> \u2713 target namespace variable <code>path</code> string <code>string</code> \u2713 target variable"},{"location":"api/#all-responses_34","title":"All responses","text":"Code Status Description Has headers Schema 200 OK successfully got instance variable schema"},{"location":"api/#responses_34","title":"Responses","text":""},{"location":"api/#200-successfully-got-instance-variable","title":"200 - successfully got instance variable","text":"<p>Status: OK</p>"},{"location":"api/#schema_45","title":"Schema","text":""},{"location":"api/#get-list-of-instance-variable-getinstancevariables","title":"Get List of Instance Variable (getInstanceVariables)","text":"<pre><code>GET /api/namespaces/{namespace}/instances/{instance}/vars\n</code></pre> <p>Gets a list of variables in a instance.</p>"},{"location":"api/#parameters_35","title":"Parameters","text":"Name Source Type Go type Separator Required Default Description instance <code>path</code> string <code>string</code> \u2713 target instance namespace <code>path</code> string <code>string</code> \u2713 target namespace"},{"location":"api/#all-responses_35","title":"All responses","text":"Code Status Description Has headers Schema 200 OK successfully got instance variables schema"},{"location":"api/#responses_35","title":"Responses","text":""},{"location":"api/#200-successfully-got-instance-variables","title":"200 - successfully got instance variables","text":"<p>Status: OK</p>"},{"location":"api/#schema_46","title":"Schema","text":""},{"location":"api/#gets-a-namespace-config-getnamespaceconfig","title":"Gets a namespace config (getNamespaceConfig)","text":"<pre><code>GET /api/namespaces/{namespace}/config\n</code></pre> <p>Gets a namespace config.</p>"},{"location":"api/#parameters_36","title":"Parameters","text":"Name Source Type Go type Separator Required Default Description namespace <code>path</code> string <code>string</code> \u2713 target namespace to update"},{"location":"api/#all-responses_36","title":"All responses","text":"Code Status Description Has headers Schema 200 OK successfully got namespace config schema"},{"location":"api/#responses_36","title":"Responses","text":""},{"location":"api/#200-successfully-got-namespace-config","title":"200 - successfully got namespace config","text":"<p>Status: OK</p>"},{"location":"api/#schema_47","title":"Schema","text":""},{"location":"api/#get-namespace-service-details-getnamespaceservice","title":"Get Namespace Service Details (getNamespaceService)","text":"<pre><code>GET /api/functions/namespaces/{namespace}/function/{serviceName}\n</code></pre> <p>Get details of a namespace scoped knative service.</p>"},{"location":"api/#parameters_37","title":"Parameters","text":"Name Source Type Go type Separator Required Default Description namespace <code>path</code> string <code>string</code> \u2713 target namespace serviceName <code>path</code> string <code>string</code> \u2713 target service name"},{"location":"api/#all-responses_37","title":"All responses","text":"Code Status Description Has headers Schema 200 OK successfully got service details schema"},{"location":"api/#responses_37","title":"Responses","text":""},{"location":"api/#200-successfully-got-service-details","title":"200 - successfully got service details","text":"<p>Status: OK</p>"},{"location":"api/#schema_48","title":"Schema","text":""},{"location":"api/#get-namespace-services-list-getnamespaceservicelist","title":"Get Namespace Services List (getNamespaceServiceList)","text":"<pre><code>GET /api/functions/namespaces/{namespace}\n</code></pre> <p>Gets a list of namespace knative services.</p>"},{"location":"api/#parameters_38","title":"Parameters","text":"Name Source Type Go type Separator Required Default Description namespace <code>path</code> string <code>string</code> \u2713 target namespace"},{"location":"api/#all-responses_38","title":"All responses","text":"Code Status Description Has headers Schema 200 OK successfully got services list schema"},{"location":"api/#responses_38","title":"Responses","text":""},{"location":"api/#200-successfully-got-services-list","title":"200 - successfully got services list","text":"<p>Status: OK</p>"},{"location":"api/#schema_49","title":"Schema","text":""},{"location":"api/#get-a-namespace-variable-getnamespacevariable","title":"Get a Namespace Variable (getNamespaceVariable)","text":"<pre><code>GET /api/namespaces/{namespace}/vars/{variable}\n</code></pre> <p>Get the value sorted in a namespace variable.</p>"},{"location":"api/#parameters_39","title":"Parameters","text":"Name Source Type Go type Separator Required Default Description namespace <code>path</code> string <code>string</code> \u2713 target namespace variable <code>path</code> string <code>string</code> \u2713 target variable"},{"location":"api/#all-responses_39","title":"All responses","text":"Code Status Description Has headers Schema 200 OK successfully got namespace variable schema"},{"location":"api/#responses_39","title":"Responses","text":""},{"location":"api/#200-successfully-got-namespace-variable","title":"200 - successfully got namespace variable","text":"<p>Status: OK</p>"},{"location":"api/#schema_50","title":"Schema","text":""},{"location":"api/#get-namespace-variable-list-getnamespacevariables","title":"Get Namespace Variable List (getNamespaceVariables)","text":"<pre><code>GET /api/namespaces/{namespace}/vars\n</code></pre> <p>Gets a list of variables in a namespace.</p>"},{"location":"api/#parameters_40","title":"Parameters","text":"Name Source Type Go type Separator Required Default Description namespace <code>path</code> string <code>string</code> \u2713 target namespace"},{"location":"api/#all-responses_40","title":"All responses","text":"Code Status Description Has headers Schema 200 OK successfully got namespace variables schema"},{"location":"api/#responses_40","title":"Responses","text":""},{"location":"api/#200-successfully-got-namespace-variables","title":"200 - successfully got namespace variables","text":"<p>Status: OK</p>"},{"location":"api/#schema_51","title":"Schema","text":""},{"location":"api/#gets-the-list-of-namespaces-getnamespaces","title":"Gets the list of namespaces (getNamespaces)","text":"<pre><code>GET /api/namespaces\n</code></pre> <p>Gets the list of namespaces.</p>"},{"location":"api/#parameters_41","title":"Parameters","text":"Name Source Type Go type Separator Required Default Description filter.field <code>query</code> string <code>string</code> field to filter filter.type <code>query</code> string <code>string</code> filter behaviour order.direction <code>query</code> string <code>string</code> order direction order.field <code>query</code> string <code>string</code> field to order by"},{"location":"api/#all-responses_41","title":"All responses","text":"Code Status Description Has headers Schema 200 OK successfully got list of namespaces schema"},{"location":"api/#responses_41","title":"Responses","text":""},{"location":"api/#200-successfully-got-list-of-namespaces","title":"200 - successfully got list of namespaces","text":"<p>Status: OK</p>"},{"location":"api/#schema_52","title":"Schema","text":""},{"location":"api/#get-list-of-namespace-nodes-getnodes","title":"Get List of Namespace Nodes (getNodes)","text":"<pre><code>GET /api/namespaces/{namespace}/tree/{nodePath}\n</code></pre> <p>Gets Workflow and Directory Nodes at nodePath.</p>"},{"location":"api/#parameters_42","title":"Parameters","text":"Name Source Type Go type Separator Required Default Description namespace <code>path</code> string <code>string</code> \u2713 target namespace nodePath <code>path</code> string <code>string</code> \u2713 target path in tree"},{"location":"api/#all-responses_42","title":"All responses","text":"Code Status Description Has headers Schema 200 OK successfully got namespace nodes schema default an error has occurred schema"},{"location":"api/#responses_42","title":"Responses","text":""},{"location":"api/#200-successfully-got-namespace-nodes","title":"200 - successfully got namespace nodes","text":"<p>Status: OK</p>"},{"location":"api/#schema_53","title":"Schema","text":"<p>OkBody</p>"},{"location":"api/#default-response_11","title":"Default Response","text":"<p>an error has occurred</p>"},{"location":"api/#schema_54","title":"Schema","text":"<p>ErrorResponse</p>"},{"location":"api/#get-list-of-namespace-registries-getregistries","title":"Get List of Namespace Registries (getRegistries)","text":"<pre><code>GET /api/functions/registries/namespaces/{namespace}\n</code></pre> <p>Gets the list of namespace registries.</p>"},{"location":"api/#parameters_43","title":"Parameters","text":"Name Source Type Go type Separator Required Default Description namespace <code>path</code> string <code>string</code> \u2713 target namespace"},{"location":"api/#all-responses_43","title":"All responses","text":"Code Status Description Has headers Schema 200 OK successfully got namespace registries schema"},{"location":"api/#responses_43","title":"Responses","text":""},{"location":"api/#200-successfully-got-namespace-registries","title":"200 - successfully got namespace registries","text":"<p>Status: OK</p>"},{"location":"api/#schema_55","title":"Schema","text":""},{"location":"api/#get-list-of-namespace-secrets-or-search-for-namespace-secrets-by-given-name-getsecrets","title":"Get List of Namespace Secrets or Search for Namespace Secrets by given name (getSecrets)","text":"<pre><code>GET /api/namespaces/{namespace}/secrets\n</code></pre> <p>Gets the list of namespace secrets. Also can use for search by setting query param op=search and term="},{"location":"api/#parameters_44","title":"Parameters","text":"Name Source Type Go type Separator Required Default Description namespace <code>path</code> string <code>string</code> \u2713 target namespace"},{"location":"api/#all-responses_44","title":"All responses","text":"Code Status Description Has headers Schema 200 OK successfully got namespace nodes schema default an error has occurred schema"},{"location":"api/#responses_44","title":"Responses","text":""},{"location":"api/#200-successfully-got-namespace-nodes_1","title":"200 - successfully got namespace nodes","text":"<p>Status: OK</p>"},{"location":"api/#schema_56","title":"Schema","text":"<p>OkBody</p>"},{"location":"api/#default-response_12","title":"Default Response","text":"<p>an error has occurred</p>"},{"location":"api/#schema_57","title":"Schema","text":"<p>ErrorResponse</p>"},{"location":"api/#get-list-of-namespace-nodes-inside-folder-getsecretsinsidefolder","title":"Get List of Namespace nodes inside Folder (getSecretsInsideFolder)","text":"<pre><code>GET /api/namespaces/{namespace}/secrets/{folder}\n</code></pre> <p>Gets the list of namespace secrets and folders inside specific folder.</p>"},{"location":"api/#parameters_45","title":"Parameters","text":"Name Source Type Go type Separator Required Default Description folder <code>path</code> string <code>string</code> \u2713 target folder path namespace <code>path</code> string <code>string</code> \u2713 target namespace"},{"location":"api/#all-responses_45","title":"All responses","text":"Code Status Description Has headers Schema 200 OK successfully got namespace nodes inside sepcific folder schema default an error has occurred schema"},{"location":"api/#responses_45","title":"Responses","text":""},{"location":"api/#200-successfully-got-namespace-nodes-inside-sepcific-folder","title":"200 - successfully got namespace nodes inside sepcific folder","text":"<p>Status: OK</p>"},{"location":"api/#schema_58","title":"Schema","text":"<p>OkBody</p>"},{"location":"api/#default-response_13","title":"Default Response","text":"<p>an error has occurred</p>"},{"location":"api/#schema_59","title":"Schema","text":"<p>ErrorResponse</p>"},{"location":"api/#get-workflow-level-logs-getworkflowlogs","title":"Get Workflow Level Logs (getWorkflowLogs)","text":"<pre><code>GET /api/namespaces/{namespace}/tree/{workflow}?op=logs\n</code></pre> <p>Get workflow level logs.</p>"},{"location":"api/#parameters_46","title":"Parameters","text":"Name Source Type Go type Separator Required Default Description namespace <code>path</code> string <code>string</code> \u2713 target namespace workflow <code>path</code> string <code>string</code> \u2713 path to target workflow filter.field <code>query</code> string <code>string</code> field to filter filter.type <code>query</code> string <code>string</code> filter behaviour order.direction <code>query</code> string <code>string</code> order direction order.field <code>query</code> string <code>string</code> field to order by"},{"location":"api/#all-responses_46","title":"All responses","text":"Code Status Description Has headers Schema 200 OK successfully got workflow logs schema"},{"location":"api/#responses_46","title":"Responses","text":""},{"location":"api/#200-successfully-got-workflow-logs","title":"200 - successfully got workflow logs","text":"<p>Status: OK</p>"},{"location":"api/#schema_60","title":"Schema","text":""},{"location":"api/#get-workflow-service-details-getworkflowservice","title":"Get Workflow Service Details (getWorkflowService)","text":"<pre><code>GET /api/functions/namespaces/{namespace}/tree/{workflow}?op=function\n</code></pre> <p>Get a workflow scoped knative service details. Note: This is a Server-Sent-Event endpoint, and will not work with the default swagger client.</p>"},{"location":"api/#parameters_47","title":"Parameters","text":"Name Source Type Go type Separator Required Default Description namespace <code>path</code> string <code>string</code> \u2713 target namespace workflow <code>path</code> string <code>string</code> \u2713 path to target workflow svn <code>query</code> string <code>string</code> \u2713 target service name version <code>query</code> string <code>string</code> \u2713 target service version"},{"location":"api/#all-responses_47","title":"All responses","text":"Code Status Description Has headers Schema 200 OK successfully got service details schema"},{"location":"api/#responses_47","title":"Responses","text":""},{"location":"api/#200-successfully-got-service-details_1","title":"200 - successfully got service details","text":"<p>Status: OK</p>"},{"location":"api/#schema_61","title":"Schema","text":""},{"location":"api/#get-workflow-service-revision-getworkflowservicerevision","title":"Get Workflow Service Revision (getWorkflowServiceRevision)","text":"<pre><code>GET /api/functions/namespaces/{namespace}/tree/{workflow}?op=function-revision\n</code></pre> <p>Get a workflow scoped knative service revision. This will return details on a single revision. The target revision generation (rev query) is the number suffix on a revision. Example: A revision named 'workflow-10640097968065193909-get-00001' would have the revisionGeneration '00001'.</p>"},{"location":"api/#parameters_48","title":"Parameters","text":"Name Source Type Go type Separator Required Default Description namespace <code>path</code> string <code>string</code> \u2713 target namespace workflow <code>path</code> string <code>string</code> \u2713 path to target workflow rev <code>query</code> string <code>string</code> \u2713 target service revison svn <code>query</code> string <code>string</code> \u2713 target service name"},{"location":"api/#all-responses_48","title":"All responses","text":"Code Status Description Has headers Schema 200 OK successfully got service revision details schema"},{"location":"api/#responses_48","title":"Responses","text":""},{"location":"api/#200-successfully-got-service-revision-details","title":"200 - successfully got service revision details","text":"<p>Status: OK</p>"},{"location":"api/#schema_62","title":"Schema","text":""},{"location":"api/#get-workflow-service-revision-list-getworkflowservicerevisionlist","title":"Get Workflow Service Revision List (getWorkflowServiceRevisionList)","text":"<pre><code>GET /api/functions/namespaces/{namespace}/tree/{workflow}?op=function-revisions\n</code></pre> <p>Get the revision list of a workflow scoped knative service.</p>"},{"location":"api/#parameters_49","title":"Parameters","text":"Name Source Type Go type Separator Required Default Description namespace <code>path</code> string <code>string</code> \u2713 target namespace workflow <code>path</code> string <code>string</code> \u2713 path to target workflow svn <code>query</code> string <code>string</code> \u2713 target service name version <code>query</code> string <code>string</code> \u2713 target service version"},{"location":"api/#all-responses_49","title":"All responses","text":"Code Status Description Has headers Schema 200 OK successfully got service revisions schema"},{"location":"api/#responses_49","title":"Responses","text":""},{"location":"api/#200-successfully-got-service-revisions","title":"200 - successfully got service revisions","text":"<p>Status: OK</p>"},{"location":"api/#schema_63","title":"Schema","text":""},{"location":"api/#get-a-workflow-variable-getworkflowvariable","title":"Get a Workflow Variable (getWorkflowVariable)","text":"<pre><code>GET /api/namespaces/{namespace}/tree/{workflow}?op=var\n</code></pre> <p>Get the value sorted in a workflow variable.</p>"},{"location":"api/#parameters_50","title":"Parameters","text":"Name Source Type Go type Separator Required Default Description namespace <code>path</code> string <code>string</code> \u2713 target namespace workflow <code>path</code> string <code>string</code> \u2713 path to target workflow var <code>query</code> string <code>string</code> \u2713 target variable"},{"location":"api/#all-responses_50","title":"All responses","text":"Code Status Description Has headers Schema 200 OK successfully got workflow variable schema"},{"location":"api/#responses_50","title":"Responses","text":""},{"location":"api/#200-successfully-got-workflow-variable","title":"200 - successfully got workflow variable","text":"<p>Status: OK</p>"},{"location":"api/#schema_64","title":"Schema","text":""},{"location":"api/#get-list-of-workflow-variables-getworkflowvariables","title":"Get List of Workflow Variables (getWorkflowVariables)","text":"<pre><code>GET /api/namespaces/{namespace}/tree/{workflow}?op=vars\n</code></pre> <p>Gets a list of variables in a workflow.</p>"},{"location":"api/#parameters_51","title":"Parameters","text":"Name Source Type Go type Separator Required Default Description namespace <code>path</code> string <code>string</code> \u2713 target namespace workflow <code>path</code> string <code>string</code> \u2713 path to target workflow"},{"location":"api/#all-responses_51","title":"All responses","text":"Code Status Description Has headers Schema 200 OK successfully got workflow variables schema"},{"location":"api/#responses_51","title":"Responses","text":""},{"location":"api/#200-successfully-got-workflow-variables","title":"200 - successfully got workflow variables","text":"<p>Status: OK</p>"},{"location":"api/#schema_65","title":"Schema","text":""},{"location":"api/#gets-instance-logs-instancelogs","title":"Gets Instance Logs (instanceLogs)","text":"<pre><code>GET /api/namespaces/{namespace}/instances/{instance}/logs\n</code></pre> <p>Gets the logs of an executed instance.</p>"},{"location":"api/#parameters_52","title":"Parameters","text":"Name Source Type Go type Separator Required Default Description instance <code>path</code> string <code>string</code> \u2713 target instance id namespace <code>path</code> string <code>string</code> \u2713 target namespace filter.field <code>query</code> string <code>string</code> field to filter filter.type <code>query</code> string <code>string</code> filter behaviour order.direction <code>query</code> string <code>string</code> order direction order.field <code>query</code> string <code>string</code> field to order by"},{"location":"api/#all-responses_52","title":"All responses","text":"Code Status Description Has headers Schema 200 OK successfully got instance logs schema default an error has occurred schema"},{"location":"api/#responses_52","title":"Responses","text":""},{"location":"api/#200-successfully-got-instance-logs","title":"200 - successfully got instance logs","text":"<p>Status: OK</p>"},{"location":"api/#schema_66","title":"Schema","text":"<p>OkBody</p>"},{"location":"api/#default-response_14","title":"Default Response","text":"<p>an error has occurred</p>"},{"location":"api/#schema_67","title":"Schema","text":"<p>ErrorResponse</p>"},{"location":"api/#jq-playground-api-to-test-jq-queries-jqplayground","title":"JQ Playground api to test jq queries (jqPlayground)","text":"<pre><code>POST /api/jq\n</code></pre> <p>JQ Playground is a sandbox where you can test jq queries with custom data.</p>"},{"location":"api/#parameters_53","title":"Parameters","text":"Name Source Type Go type Separator Required Default Description JQ payload <code>body</code> JqPlaygroundBody <code>JqPlaygroundBody</code> \u2713 Payload that contains both the JSON data to manipulate and jq query."},{"location":"api/#all-responses_53","title":"All responses","text":"Code Status Description Has headers Schema 200 OK jq query was successful schema 400 Bad Request the request was invalid schema 500 Internal Server Error an unexpected internal error occurred schema"},{"location":"api/#responses_53","title":"Responses","text":""},{"location":"api/#200-jq-query-was-successful","title":"200 - jq query was successful","text":"<p>Status: OK</p>"},{"location":"api/#schema_68","title":"Schema","text":""},{"location":"api/#400-the-request-was-invalid","title":"400 - the request was invalid","text":"<p>Status: Bad Request</p>"},{"location":"api/#schema_69","title":"Schema","text":""},{"location":"api/#500-an-unexpected-internal-error-occurred","title":"500 - an unexpected internal error occurred","text":"<p>Status: Internal Server Error</p>"},{"location":"api/#schema_70","title":"Schema","text":""},{"location":"api/#inlined-models_3","title":"Inlined models","text":"<p> JqPlaygroundBody</p> <p>Properties</p> Name Type Go type Required Default Description Example data string <code>string</code> \u2713 JSON data encoded in base64 query string <code>string</code> \u2713 jq query to manipulate JSON data"},{"location":"api/#list-existing-cloudeventfilters-listcloudeventfilter","title":"List existing cloudEventFilters (listCloudeventFilter)","text":"<pre><code>GET /api/namespaces/{namespace}/eventfilter\n</code></pre> <p>list all existing cloud event filter in target namespace</p>"},{"location":"api/#parameters_54","title":"Parameters","text":"Name Source Type Go type Separator Required Default Description namespace <code>path</code> string <code>string</code> \u2713 target namespace"},{"location":"api/#all-responses_54","title":"All responses","text":"Code Status Description Has headers Schema 200 OK schema"},{"location":"api/#responses_54","title":"Responses","text":""},{"location":"api/#200_4","title":"200","text":"<p>Status: OK</p>"},{"location":"api/#schema_71","title":"Schema","text":""},{"location":"api/#get-namespace-service-revision-pods-list-listnamespaceservicerevisionpods","title":"Get Namespace Service Revision Pods List (listNamespaceServiceRevisionPods)","text":"<pre><code>GET /api/functions/namespaces/{namespace}/function/{serviceName}/revisions/{revisionGeneration}/pods\n</code></pre> <p>List a revisions pods of a namespace scoped knative service. The target revision generation is the number suffix on a revision. Example: A revision named 'namespace-direktiv-fast-request-00003' would have the revisionGeneration '00003'.</p>"},{"location":"api/#parameters_55","title":"Parameters","text":"Name Source Type Go type Separator Required Default Description namespace <code>path</code> string <code>string</code> \u2713 target namespace revisionGeneration <code>path</code> string <code>string</code> \u2713 target revision generation serviceName <code>path</code> string <code>string</code> \u2713 target service name"},{"location":"api/#all-responses_55","title":"All responses","text":"Code Status Description Has headers Schema 200 OK successfully got list of a service revision pods schema"},{"location":"api/#responses_55","title":"Responses","text":""},{"location":"api/#200-successfully-got-list-of-a-service-revision-pods","title":"200 - successfully got list of a service revision pods","text":"<p>Status: OK</p>"},{"location":"api/#schema_72","title":"Schema","text":""},{"location":"api/#get-workflow-service-revision-pods-list-listworkflowservicerevisionpods","title":"Get Workflow Service Revision Pods List (listWorkflowServiceRevisionPods)","text":"<pre><code>GET /api/functions/namespaces/{namespace}/tree/{workflow}?op=pods\n</code></pre> <p>List a revisions pods of a workflow scoped knative service. The target revision generation (rev query) is the number suffix on a revision. Example: A revision named 'workflow-10640097968065193909-get-00001' would have the revisionGeneration '00001'.</p>"},{"location":"api/#parameters_56","title":"Parameters","text":"Name Source Type Go type Separator Required Default Description namespace <code>path</code> string <code>string</code> \u2713 target namespace workflow <code>path</code> string <code>string</code> \u2713 path to target workflow rev <code>query</code> string <code>string</code> \u2713 target service revison svn <code>query</code> string <code>string</code> \u2713 target service name"},{"location":"api/#all-responses_56","title":"All responses","text":"Code Status Description Has headers Schema 200 OK successfully got list of a service revision pods schema"},{"location":"api/#responses_56","title":"Responses","text":""},{"location":"api/#200-successfully-got-list-of-a-service-revision-pods_1","title":"200 - successfully got list of a service revision pods","text":"<p>Status: OK</p>"},{"location":"api/#schema_73","title":"Schema","text":""},{"location":"api/#get-workflow-services-list-listworkflowservices","title":"Get Workflow Services List (listWorkflowServices)","text":"<pre><code>GET /api/functions/namespaces/{namespace}/tree/{workflow}?op=services\n</code></pre> <p>Gets a list of workflow knative services.</p>"},{"location":"api/#parameters_57","title":"Parameters","text":"Name Source Type Go type Separator Required Default Description namespace <code>path</code> string <code>string</code> \u2713 target namespace workflow <code>path</code> string <code>string</code> \u2713 path to target workflow"},{"location":"api/#all-responses_57","title":"All responses","text":"Code Status Description Has headers Schema 200 OK successfully got services list schema"},{"location":"api/#responses_57","title":"Responses","text":""},{"location":"api/#200-successfully-got-services-list_1","title":"200 - successfully got services list","text":"<p>Status: OK</p>"},{"location":"api/#schema_74","title":"Schema","text":""},{"location":"api/#gets-namespace-level-logs-namespacelogs","title":"Gets Namespace Level Logs (namespaceLogs)","text":"<pre><code>GET /api/namespaces/{namespace}/logs\n</code></pre> <p>Gets Namespace Level Logs.</p>"},{"location":"api/#parameters_58","title":"Parameters","text":"Name Source Type Go type Separator Required Default Description namespace <code>path</code> string <code>string</code> \u2713 target namespace filter.field <code>query</code> string <code>string</code> field to filter filter.type <code>query</code> string <code>string</code> filter behaviour order.direction <code>query</code> string <code>string</code> order direction order.field <code>query</code> string <code>string</code> field to order by"},{"location":"api/#all-responses_58","title":"All responses","text":"Code Status Description Has headers Schema 200 OK successfully got namespace logs schema"},{"location":"api/#responses_58","title":"Responses","text":""},{"location":"api/#200-successfully-got-namespace-logs","title":"200 - successfully got namespace logs","text":"<p>Status: OK</p>"},{"location":"api/#schema_75","title":"Schema","text":""},{"location":"api/#gets-namespace-failed-workflow-instances-metrics-namespacemetricsfailed","title":"Gets Namespace Failed Workflow Instances Metrics (namespaceMetricsFailed)","text":"<pre><code>GET /api/namespaces/{namespace}/metrics/failed\n</code></pre> <p>Get metrics of failed workflows in the targeted namespace.</p>"},{"location":"api/#parameters_59","title":"Parameters","text":"Name Source Type Go type Separator Required Default Description namespace <code>path</code> string <code>string</code> \u2713 target namespace"},{"location":"api/#all-responses_59","title":"All responses","text":"Code Status Description Has headers Schema 200 OK successfully got namespace metrics schema"},{"location":"api/#responses_59","title":"Responses","text":""},{"location":"api/#200-successfully-got-namespace-metrics","title":"200 - successfully got namespace metrics","text":"<p>Status: OK</p>"},{"location":"api/#schema_76","title":"Schema","text":""},{"location":"api/#gets-namespace-invoked-workflow-metrics-namespacemetricsinvoked","title":"Gets Namespace Invoked Workflow Metrics (namespaceMetricsInvoked)","text":"<pre><code>GET /api/namespaces/{namespace}/metrics/invoked\n</code></pre> <p>Get metrics of invoked workflows in the targeted namespace.</p>"},{"location":"api/#parameters_60","title":"Parameters","text":"Name Source Type Go type Separator Required Default Description namespace <code>path</code> string <code>string</code> \u2713 target namespace"},{"location":"api/#all-responses_60","title":"All responses","text":"Code Status Description Has headers Schema 200 OK successfully got namespace metrics schema"},{"location":"api/#responses_60","title":"Responses","text":""},{"location":"api/#200-successfully-got-namespace-metrics_1","title":"200 - successfully got namespace metrics","text":"<p>Status: OK</p>"},{"location":"api/#schema_77","title":"Schema","text":""},{"location":"api/#gets-namespace-workflow-timing-metrics-namespacemetricsmilliseconds","title":"Gets Namespace Workflow Timing Metrics (namespaceMetricsMilliseconds)","text":"<pre><code>GET /api/namespaces/{namespace}/metrics/milliseconds\n</code></pre> <p>Get timing metrics of workflows in the targeted namespace.</p>"},{"location":"api/#parameters_61","title":"Parameters","text":"Name Source Type Go type Separator Required Default Description namespace <code>path</code> string <code>string</code> \u2713 target namespace"},{"location":"api/#all-responses_61","title":"All responses","text":"Code Status Description Has headers Schema 200 OK successfully got namespace metrics schema"},{"location":"api/#responses_61","title":"Responses","text":""},{"location":"api/#200-successfully-got-namespace-metrics_2","title":"200 - successfully got namespace metrics","text":"<p>Status: OK</p>"},{"location":"api/#schema_78","title":"Schema","text":""},{"location":"api/#gets-namespace-successful-workflow-instances-metrics-namespacemetricssuccessful","title":"Gets Namespace Successful Workflow Instances Metrics (namespaceMetricsSuccessful)","text":"<pre><code>GET /api/namespaces/{namespace}/metrics/successful\n</code></pre> <p>Get metrics of successful workflows in the targeted namespace.</p>"},{"location":"api/#parameters_62","title":"Parameters","text":"Name Source Type Go type Separator Required Default Description namespace <code>path</code> string <code>string</code> \u2713 target namespace"},{"location":"api/#all-responses_62","title":"All responses","text":"Code Status Description Has headers Schema 200 OK successfully got namespace metrics schema"},{"location":"api/#responses_62","title":"Responses","text":""},{"location":"api/#200-successfully-got-namespace-metrics_3","title":"200 - successfully got namespace metrics","text":"<p>Status: OK</p>"},{"location":"api/#schema_79","title":"Schema","text":""},{"location":"api/#overwrite-a-namespace-secret-overwriteandsearchsecret","title":"Overwrite a Namespace Secret (overwriteAndSearchSecret)","text":"<pre><code>PATCH /api/namespaces/{namespace}/secrets/{secret}\n</code></pre> <p>Overwrite a namespace secret</p>"},{"location":"api/#consumes_3","title":"Consumes","text":"<ul> <li>text/plain</li> </ul>"},{"location":"api/#parameters_63","title":"Parameters","text":"Name Source Type Go type Separator Required Default Description namespace <code>path</code> string <code>string</code> \u2713 target namespace secret <code>path</code> string <code>string</code> \u2713 target secret Secret Payload <code>body</code> string <code>string</code> \u2713 Payload that contains secret data"},{"location":"api/#all-responses_63","title":"All responses","text":"Code Status Description Has headers Schema 200 OK namespace has been successfully overwritten schema default secret not found schema"},{"location":"api/#responses_63","title":"Responses","text":""},{"location":"api/#200-namespace-has-been-successfully-overwritten","title":"200 - namespace has been successfully overwritten","text":"<p>Status: OK</p>"},{"location":"api/#schema_80","title":"Schema","text":"<p>OkBody</p>"},{"location":"api/#default-response_15","title":"Default Response","text":"<p>secret not found</p>"},{"location":"api/#schema_81","title":"Schema","text":"<p>ErrorResponse</p>"},{"location":"api/#watch-pod-logs-podlogs","title":"Watch Pod Logs (podLogs)","text":"<pre><code>GET /api/logs/{pod}\n</code></pre> <p>Watches logs of the pods for a service. This can be a namespace service or a workflow service.</p>"},{"location":"api/#parameters_64","title":"Parameters","text":"Name Source Type Go type Separator Required Default Description pod <code>path</code> string <code>string</code> \u2713 pod name"},{"location":"api/#all-responses_64","title":"All responses","text":"Code Status Description Has headers Schema 200 OK successfully watching pod logs schema"},{"location":"api/#responses_64","title":"Responses","text":""},{"location":"api/#200-successfully-watching-pod-logs","title":"200 - successfully watching pod logs","text":"<p>Status: OK</p>"},{"location":"api/#schema_82","title":"Schema","text":""},{"location":"api/#replay-cloud-event-replaycloudevent","title":"Replay Cloud Event (replayCloudevent)","text":"<pre><code>POST /api/namespaces/{namespace}/events/{event}/replay\n</code></pre> <p>Replay a cloud event to a namespace.</p>"},{"location":"api/#parameters_65","title":"Parameters","text":"Name Source Type Go type Separator Required Default Description event <code>path</code> string <code>string</code> \u2713 target cloudevent namespace <code>path</code> string <code>string</code> \u2713 target namespace"},{"location":"api/#all-responses_65","title":"All responses","text":"Code Status Description Has headers Schema 200 OK successfully replayed cloud event schema"},{"location":"api/#responses_65","title":"Responses","text":""},{"location":"api/#200-successfully-replayed-cloud-event","title":"200 - successfully replayed cloud event","text":"<p>Status: OK</p>"},{"location":"api/#schema_83","title":"Schema","text":""},{"location":"api/#get-direktiv-server-logs-serverlogs","title":"Get Direktiv Server Logs (serverLogs)","text":"<pre><code>GET /api/logs\n</code></pre> <p>Gets Direktiv Server Logs.</p>"},{"location":"api/#parameters_66","title":"Parameters","text":"Name Source Type Go type Separator Required Default Description filter.field <code>query</code> string <code>string</code> field to filter filter.type <code>query</code> string <code>string</code> filter behaviour order.direction <code>query</code> string <code>string</code> order direction order.field <code>query</code> string <code>string</code> field to order by"},{"location":"api/#all-responses_66","title":"All responses","text":"Code Status Description Has headers Schema 200 OK successfully got server logs schema default an error has occurred schema"},{"location":"api/#responses_66","title":"Responses","text":""},{"location":"api/#200-successfully-got-server-logs","title":"200 - successfully got server logs","text":"<p>Status: OK</p>"},{"location":"api/#schema_84","title":"Schema","text":"<p>OkBody</p>"},{"location":"api/#default-response_16","title":"Default Response","text":"<p>an error has occurred</p>"},{"location":"api/#schema_85","title":"Schema","text":"<p>ErrorResponse</p>"},{"location":"api/#set-a-instance-variable-setinstancevariable","title":"Set a Instance Variable (setInstanceVariable)","text":"<pre><code>PUT /api/namespaces/{namespace}/instances/{instance}/vars/{variable}\n</code></pre> <p>Set the value sorted in a instance variable. If the target variable does not exists, it will be created. Variable data can be anything.</p>"},{"location":"api/#consumes_4","title":"Consumes","text":"<ul> <li>text/plain</li> </ul>"},{"location":"api/#parameters_67","title":"Parameters","text":"Name Source Type Go type Separator Required Default Description instance <code>path</code> string <code>string</code> \u2713 target instance namespace <code>path</code> string <code>string</code> \u2713 target namespace variable <code>path</code> string <code>string</code> \u2713 target variable data <code>body</code> string <code>string</code> \u2713 Payload that contains variable data."},{"location":"api/#all-responses_67","title":"All responses","text":"Code Status Description Has headers Schema 200 OK successfully set instance variable schema"},{"location":"api/#responses_67","title":"Responses","text":""},{"location":"api/#200-successfully-set-instance-variable","title":"200 - successfully set instance variable","text":"<p>Status: OK</p>"},{"location":"api/#schema_86","title":"Schema","text":""},{"location":"api/#sets-a-namespace-config-setnamespaceconfig","title":"Sets a namespace config (setNamespaceConfig)","text":"<pre><code>PATCH /api/namespaces/{namespace}/config\n</code></pre> <p>Sets a namespace config.</p>"},{"location":"api/#parameters_68","title":"Parameters","text":"Name Source Type Go type Separator Required Default Description namespace <code>path</code> string <code>string</code> \u2713 target namespace to update Config Payload <code>body</code> SetNamespaceConfigBody <code>SetNamespaceConfigBody</code> Payload that contains the config information to set. Note: This payload only need to contain the properities you wish to set."},{"location":"api/#all-responses_68","title":"All responses","text":"Code Status Description Has headers Schema 200 OK namespace config has been successfully been updated schema"},{"location":"api/#responses_68","title":"Responses","text":""},{"location":"api/#200-namespace-config-has-been-successfully-been-updated","title":"200 - namespace config has been successfully been updated","text":"<p>Status: OK</p>"},{"location":"api/#schema_87","title":"Schema","text":""},{"location":"api/#inlined-models_4","title":"Inlined models","text":"<p> SetNamespaceConfigBody</p> <p>Properties</p> Name Type Go type Required Default Description Example broadcast interface{} <code>interface{}</code> Configuration on which direktiv operations will trigger coud events on the namespace"},{"location":"api/#set-a-namespace-variable-setnamespacevariable","title":"Set a Namespace Variable (setNamespaceVariable)","text":"<pre><code>PUT /api/namespaces/{namespace}/vars/{variable}\n</code></pre> <p>Set the value sorted in a namespace variable. If the target variable does not exists, it will be created. Variable data can be anything.</p>"},{"location":"api/#consumes_5","title":"Consumes","text":"<ul> <li>text/plain</li> </ul>"},{"location":"api/#parameters_69","title":"Parameters","text":"Name Source Type Go type Separator Required Default Description namespace <code>path</code> string <code>string</code> \u2713 target namespace variable <code>path</code> string <code>string</code> \u2713 target variable data <code>body</code> string <code>string</code> \u2713 Payload that contains variable data."},{"location":"api/#all-responses_69","title":"All responses","text":"Code Status Description Has headers Schema 200 OK successfully set namespace variable schema"},{"location":"api/#responses_69","title":"Responses","text":""},{"location":"api/#200-successfully-set-namespace-variable","title":"200 - successfully set namespace variable","text":"<p>Status: OK</p>"},{"location":"api/#schema_88","title":"Schema","text":""},{"location":"api/#set-cloud-event-for-workflow-to-log-to-setworkflowcloudeventlogs","title":"Set Cloud Event for Workflow to Log to (setWorkflowCloudEventLogs)","text":"<pre><code>POST /api/namespaces/{namespace}/tree/{workflow}?op=set-workflow-event-logging\n</code></pre> <p>Set Cloud Event for Workflow to Log to. When configured type <code>direktiv.instanceLog</code> cloud events will be generated with the <code>logger</code> parameter set to the configured value. Workflows can be configured to generate cloud events on their namespace anything the log parameter produces data. Please find more information on this topic here: https://docs.direktiv.io/docs/examples/logging.html</p>"},{"location":"api/#parameters_70","title":"Parameters","text":"Name Source Type Go type Separator Required Default Description namespace <code>path</code> string <code>string</code> \u2713 target namespace workflow <code>path</code> string <code>string</code> \u2713 path to target workflow Cloud Event Logger <code>body</code> SetWorkflowCloudEventLogsBody <code>SetWorkflowCloudEventLogsBody</code> \u2713 Cloud event logger to target"},{"location":"api/#all-responses_70","title":"All responses","text":"Code Status Description Has headers Schema 200 OK successfully update workflow schema"},{"location":"api/#responses_70","title":"Responses","text":""},{"location":"api/#200-successfully-update-workflow","title":"200 - successfully update workflow","text":"<p>Status: OK</p>"},{"location":"api/#schema_89","title":"Schema","text":""},{"location":"api/#inlined-models_5","title":"Inlined models","text":"<p> SetWorkflowCloudEventLogsBody</p> <p>Properties</p> Name Type Go type Required Default Description Example logger string <code>string</code> \u2713 Target Cloud Event"},{"location":"api/#set-a-workflow-variable-setworkflowvariable","title":"Set a Workflow Variable (setWorkflowVariable)","text":"<pre><code>PUT /api/namespaces/{namespace}/tree/{workflow}?op=set-var\n</code></pre> <p>Set the value sorted in a workflow variable. If the target variable does not exists, it will be created. Variable data can be anything.</p>"},{"location":"api/#consumes_6","title":"Consumes","text":"<ul> <li>text/plain</li> </ul>"},{"location":"api/#parameters_71","title":"Parameters","text":"Name Source Type Go type Separator Required Default Description namespace <code>path</code> string <code>string</code> \u2713 target namespace workflow <code>path</code> string <code>string</code> \u2713 path to target workflow var <code>query</code> string <code>string</code> \u2713 target variable data <code>body</code> string <code>string</code> \u2713 Payload that contains variable data."},{"location":"api/#all-responses_71","title":"All responses","text":"Code Status Description Has headers Schema 200 OK successfully set workflow variable schema"},{"location":"api/#responses_71","title":"Responses","text":""},{"location":"api/#200-successfully-set-workflow-variable","title":"200 - successfully set workflow variable","text":"<p>Status: OK</p>"},{"location":"api/#schema_90","title":"Schema","text":""},{"location":"api/#test-a-registry-to-make-sure-the-connection-is-okay-testregistry","title":"Test a registry to make sure the connection is okay (testRegistry)","text":"<pre><code>POST /api/functions/registries/test\n</code></pre> <p>Test a registry with provided url, username and token</p>"},{"location":"api/#parameters_72","title":"Parameters","text":"Name Source Type Go type Separator Required Default Description Registry Payload <code>body</code> TestRegistryBody <code>TestRegistryBody</code> \u2713 Payload that contains registry data"},{"location":"api/#all-responses_72","title":"All responses","text":"Code Status Description Has headers Schema 200 OK registry is valid schema 401 Unauthorized unauthorized to access the registry schema"},{"location":"api/#responses_72","title":"Responses","text":""},{"location":"api/#200-registry-is-valid","title":"200 - registry is valid","text":"<p>Status: OK</p>"},{"location":"api/#schema_91","title":"Schema","text":""},{"location":"api/#401-unauthorized-to-access-the-registry","title":"401 - unauthorized to access the registry","text":"<p>Status: Unauthorized</p>"},{"location":"api/#schema_92","title":"Schema","text":""},{"location":"api/#inlined-models_6","title":"Inlined models","text":"<p> TestRegistryBody</p> <p>Properties</p> Name Type Go type Required Default Description Example password string <code>string</code> \u2713 token to authenticate with the registry url string <code>string</code> \u2713 The url to test if the registry is valid username string <code>string</code> \u2713 username to authenticate with the registry"},{"location":"api/#set-cloud-event-for-workflow-to-log-to-toggleworkflow","title":"Set Cloud Event for Workflow to Log to (toggleWorkflow)","text":"<pre><code>POST /api/namespaces/{namespace}/tree/{workflow}?op=toggle\n</code></pre> <p>Toggle's whether or not a workflow is active. Disabled workflows cannot be invoked. This includes start event and scheduled workflows.</p>"},{"location":"api/#parameters_73","title":"Parameters","text":"Name Source Type Go type Separator Required Default Description namespace <code>path</code> string <code>string</code> \u2713 target namespace workflow <code>path</code> string <code>string</code> \u2713 path to target workflow Workflow Live Status <code>body</code> ToggleWorkflowBody <code>ToggleWorkflowBody</code> \u2713 Whether or not the workflow is alive or disabled"},{"location":"api/#all-responses_73","title":"All responses","text":"Code Status Description Has headers Schema 200 OK successfully updated workflow live status schema"},{"location":"api/#responses_73","title":"Responses","text":""},{"location":"api/#200-successfully-updated-workflow-live-status","title":"200 - successfully updated workflow live status","text":"<p>Status: OK</p>"},{"location":"api/#schema_93","title":"Schema","text":""},{"location":"api/#inlined-models_7","title":"Inlined models","text":"<p> ToggleWorkflowBody</p> <p>Properties</p> Name Type Go type Required Default Description Example live boolean <code>bool</code> \u2713 Workflow live status"},{"location":"api/#update-existing-cloudeventfilter-updatecloudeventfilter","title":"Update existing cloudEventFilter (updateCloudeventFilter)","text":"<pre><code>PATCH /api/namespaces/{namespace}/eventfilter/{filtername}\n</code></pre> <p>Update existing cloud event filter in target namespace</p>"},{"location":"api/#parameters_74","title":"Parameters","text":"Name Source Type Go type Separator Required Default Description filtername <code>path</code> string <code>string</code> \u2713 target filtername namespace <code>path</code> string <code>string</code> \u2713 target namespace script <code>body</code> interface{} <code>interface{}</code> \u2713 compilable javascript code."},{"location":"api/#all-responses_74","title":"All responses","text":"Code Status Description Has headers Schema 200 OK schema"},{"location":"api/#responses_74","title":"Responses","text":""},{"location":"api/#200_5","title":"200","text":"<p>Status: OK</p>"},{"location":"api/#schema_94","title":"Schema","text":""},{"location":"api/#create-namespace-service-revision-updatenamespaceservice","title":"Create Namespace Service Revision (updateNamespaceService)","text":"<pre><code>POST /api/functions/namespaces/{namespace}/function/{serviceName}\n</code></pre> <p>Creates a new namespace scoped knative service revision.</p>"},{"location":"api/#parameters_75","title":"Parameters","text":"Name Source Type Go type Separator Required Default Description namespace <code>path</code> string <code>string</code> \u2713 target namespace serviceName <code>path</code> string <code>string</code> \u2713 target service name Service <code>body</code> UpdateNamespaceServiceBody <code>UpdateNamespaceServiceBody</code> \u2713 Payload that contains information on service revision"},{"location":"api/#all-responses_75","title":"All responses","text":"Code Status Description Has headers Schema 200 OK successfully created service revision schema"},{"location":"api/#responses_75","title":"Responses","text":""},{"location":"api/#200-successfully-created-service-revision","title":"200 - successfully created service revision","text":"<p>Status: OK</p>"},{"location":"api/#schema_95","title":"Schema","text":""},{"location":"api/#inlined-models_8","title":"Inlined models","text":"<p> UpdateNamespaceServiceBody</p> <p>Properties</p> Name Type Go type Required Default Description Example cmd string <code>string</code> \u2713 image string <code>string</code> \u2713 Target image a service will use minScale integer <code>int64</code> \u2713 Minimum amount of service pods to be live size string <code>string</code> \u2713 Size of created service pods"},{"location":"api/#update-a-workflow-updateworkflow","title":"Update a Workflow (updateWorkflow)","text":"<pre><code>POST /api/namespaces/{namespace}/tree/{workflow}?op=update-workflow\n</code></pre> <p>Updates a workflow at the target path. The body of this request should contain the workflow yaml you want to update to.</p>"},{"location":"api/#consumes_7","title":"Consumes","text":"<ul> <li>text/plain</li> </ul>"},{"location":"api/#parameters_76","title":"Parameters","text":"Name Source Type Go type Separator Required Default Description namespace <code>path</code> string <code>string</code> \u2713 target namespace workflow <code>path</code> string <code>string</code> \u2713 path to target workflow workflow data <code>body</code> string <code>string</code> Payload that contains the updated direktiv workflow yaml."},{"location":"api/#all-responses_76","title":"All responses","text":"Code Status Description Has headers Schema 200 OK successfully updated workflow schema"},{"location":"api/#responses_76","title":"Responses","text":""},{"location":"api/#200-successfully-updated-workflow","title":"200 - successfully updated workflow","text":"<p>Status: OK</p>"},{"location":"api/#schema_96","title":"Schema","text":""},{"location":"api/#returns-version-information-for-servers-in-the-cluster-version","title":"Returns version information for servers in the cluster. (version)","text":"<pre><code>GET /api/version\n</code></pre> <p>Returns version information for servers in the cluster.</p>"},{"location":"api/#all-responses_77","title":"All responses","text":"Code Status Description Has headers Schema 200 OK version query was successful schema"},{"location":"api/#responses_77","title":"Responses","text":""},{"location":"api/#200-version-query-was-successful","title":"200 - version query was successful","text":"<p>Status: OK</p>"},{"location":"api/#schema_97","title":"Schema","text":""},{"location":"api/#watch-namespace-service-revision-watchnamespaceservicerevision","title":"Watch Namespace Service Revision (watchNamespaceServiceRevision)","text":"<pre><code>GET /api/functions/namespaces/{namespace}/function/{serviceName}/revisions/{revisionGeneration}\n</code></pre> <p>Watch a namespace scoped knative service revision. The target revision generation is the number suffix on a revision. Example: A revision named 'namespace-direktiv-fast-request-00003' would have the revisionGeneration '00003'. Note: This is a Server-Sent-Event endpoint, and will not work with the default swagger client.</p>"},{"location":"api/#produces_1","title":"Produces","text":"<ul> <li>text/event-stream</li> </ul>"},{"location":"api/#parameters_77","title":"Parameters","text":"Name Source Type Go type Separator Required Default Description namespace <code>path</code> string <code>string</code> \u2713 target namespace revisionGeneration <code>path</code> string <code>string</code> \u2713 target revision generation serviceName <code>path</code> string <code>string</code> \u2713 target service name"},{"location":"api/#all-responses_78","title":"All responses","text":"Code Status Description Has headers Schema 200 OK successfully watching service revision schema"},{"location":"api/#responses_78","title":"Responses","text":""},{"location":"api/#200-successfully-watching-service-revision","title":"200 - successfully watching service revision","text":"<p>Status: OK</p>"},{"location":"api/#schema_98","title":"Schema","text":""},{"location":"api/#watch-namespace-service-revision-list-watchnamespaceservicerevisionlist","title":"Watch Namespace Service Revision List (watchNamespaceServiceRevisionList)","text":"<pre><code>GET /api/functions/namespaces/{namespace}/function/{serviceName}/revisions\n</code></pre> <p>Watch the revision list of a namespace scoped knative service. Note: This is a Server-Sent-Event endpoint, and will not work with the default swagger client.</p>"},{"location":"api/#produces_2","title":"Produces","text":"<ul> <li>text/event-stream</li> </ul>"},{"location":"api/#parameters_78","title":"Parameters","text":"Name Source Type Go type Separator Required Default Description namespace <code>path</code> string <code>string</code> \u2713 target namespace serviceName <code>path</code> string <code>string</code> \u2713 target service name"},{"location":"api/#all-responses_79","title":"All responses","text":"Code Status Description Has headers Schema 200 OK successfully watching service revisions schema"},{"location":"api/#responses_79","title":"Responses","text":""},{"location":"api/#200-successfully-watching-service-revisions","title":"200 - successfully watching service revisions","text":"<p>Status: OK</p>"},{"location":"api/#schema_99","title":"Schema","text":""},{"location":"api/#gets-invoked-workflow-metrics-workflowmetricsinvoked","title":"Gets Invoked Workflow Metrics (workflowMetricsInvoked)","text":"<pre><code>GET /api/namespaces/{namespace}/tree/{workflow}?op=metrics-invoked\n</code></pre> <p>Get metrics of invoked workflow instances.</p>"},{"location":"api/#parameters_79","title":"Parameters","text":"Name Source Type Go type Separator Required Default Description namespace <code>path</code> string <code>string</code> \u2713 target namespace workflow <code>path</code> string <code>string</code> \u2713 path to target workflow"},{"location":"api/#all-responses_80","title":"All responses","text":"Code Status Description Has headers Schema 200 OK successfully got workflow metrics schema"},{"location":"api/#responses_80","title":"Responses","text":""},{"location":"api/#200-successfully-got-workflow-metrics","title":"200 - successfully got workflow metrics","text":"<p>Status: OK</p>"},{"location":"api/#schema_100","title":"Schema","text":""},{"location":"api/#gets-workflow-time-metrics-workflowmetricsmilliseconds","title":"Gets Workflow Time Metrics (workflowMetricsMilliseconds)","text":"<pre><code>GET /api/namespaces/{namespace}/tree/{workflow}?op=metrics-failed\n</code></pre> <p>Get the timing metrics of a workflow's instance. This returns a total sum of the milliseconds a workflow has been executed for.</p>"},{"location":"api/#parameters_80","title":"Parameters","text":"Name Source Type Go type Separator Required Default Description namespace <code>path</code> string <code>string</code> \u2713 target namespace workflow <code>path</code> string <code>string</code> \u2713 path to target workflow"},{"location":"api/#all-responses_81","title":"All responses","text":"Code Status Description Has headers Schema 200 OK successfully got workflow metrics schema"},{"location":"api/#responses_81","title":"Responses","text":""},{"location":"api/#200-successfully-got-workflow-metrics_1","title":"200 - successfully got workflow metrics","text":"<p>Status: OK</p>"},{"location":"api/#schema_101","title":"Schema","text":""},{"location":"api/#get-sankey-metrics-of-a-workflow-revision-workflowmetricssankey","title":"Get Sankey metrics of a workflow revision. (workflowMetricsSankey)","text":"<pre><code>GET /api/namespaces/{namespace}/tree/{workflow}?op=metrics-sankey\n</code></pre> <p>Get Sankey metrics of a workflow revision. If ref query is not provided, metrics for the latest revision will be retrieved.</p>"},{"location":"api/#parameters_81","title":"Parameters","text":"Name Source Type Go type Separator Required Default Description namespace <code>path</code> string <code>string</code> \u2713 target namespace workflow <code>path</code> string <code>string</code> \u2713 path to target workflow ref <code>query</code> string <code>string</code> target workflow revision reference"},{"location":"api/#all-responses_82","title":"All responses","text":"Code Status Description Has headers Schema 200 OK successfully got workflow metrics schema"},{"location":"api/#responses_82","title":"Responses","text":""},{"location":"api/#200-successfully-got-workflow-metrics_2","title":"200 - successfully got workflow metrics","text":"<p>Status: OK</p>"},{"location":"api/#schema_102","title":"Schema","text":""},{"location":"api/#gets-a-workflow-state-time-metrics-workflowmetricsstatemilliseconds","title":"Gets a Workflow State Time Metrics (workflowMetricsStateMilliseconds)","text":"<pre><code>GET /api/namespaces/{namespace}/tree/{workflow}?op=metrics-state-milliseconds\n</code></pre> <p>Get the state timing metrics of a workflow's instance. This returns the timing of individual states in a workflow.</p>"},{"location":"api/#parameters_82","title":"Parameters","text":"Name Source Type Go type Separator Required Default Description namespace <code>path</code> string <code>string</code> \u2713 target namespace workflow <code>path</code> string <code>string</code> \u2713 path to target workflow"},{"location":"api/#all-responses_83","title":"All responses","text":"Code Status Description Has headers Schema 200 OK successfully got workflow metrics schema"},{"location":"api/#responses_83","title":"Responses","text":""},{"location":"api/#200-successfully-got-workflow-metrics_3","title":"200 - successfully got workflow metrics","text":"<p>Status: OK</p>"},{"location":"api/#schema_103","title":"Schema","text":""},{"location":"api/#gets-successful-workflow-metrics-workflowmetricssuccessful","title":"Gets Successful Workflow Metrics (workflowMetricsSuccessful)","text":"<pre><code>GET /api/namespaces/{namespace}/tree/{workflow}?op=metrics-successful\n</code></pre> <p>Get metrics of a workflow, where the instance was successful.</p>"},{"location":"api/#parameters_83","title":"Parameters","text":"Name Source Type Go type Separator Required Default Description namespace <code>path</code> string <code>string</code> \u2713 target namespace workflow <code>path</code> string <code>string</code> \u2713 path to target workflow"},{"location":"api/#all-responses_84","title":"All responses","text":"Code Status Description Has headers Schema 200 OK successfully got workflow metrics schema"},{"location":"api/#responses_84","title":"Responses","text":""},{"location":"api/#200-successfully-got-workflow-metrics_4","title":"200 - successfully got workflow metrics","text":"<p>Status: OK</p>"},{"location":"api/#schema_104","title":"Schema","text":""},{"location":"api/#models","title":"Models","text":""},{"location":"api/#errorresponse","title":"ErrorResponse","text":"<p>interface{}</p>"},{"location":"api/#okbody","title":"OkBody","text":"<p>OkBody is an arbitrary placeholder response that represents an ok response body</p> <p>interface{}</p>"},{"location":"api/#updateservicerequest","title":"updateServiceRequest","text":"<p>UpdateServiceRequest update service request</p> <p>interface{}</p>"},{"location":"environment/cli/","title":"direktivctl","text":"<p>Although developing flows with the web UI is easy, a command line tool can be used to make local flow development faster and more convenient. Direktiv's cli <code>direktivctl</code> is used for pushing and executing flows remotely. This enables the developer to stay in his development environment, e.g. Visual Studio Code. </p>"},{"location":"environment/cli/#installing","title":"Installing","text":"<p>The direktivctl is available for Linux, Windows, and Mac platforms and is distributed as a <code>tar.gz</code> file with every new release of Direktiv. The asset can be downloaded and unpacked to get the <code>direktiv-sync</code> binary.</p> <ul> <li>Linux</li> <li>Mac</li> <li>Mac ARM</li> <li>Windows</li> </ul> Linux Installation Example<pre><code>curl -L https://github.com/direktiv/direktiv/releases/latest/download/direktivctl_amd64.tar.gz | tar -xz &amp;&amp; \\\nsudo mv direktivctl /usr/local/bin\n</code></pre>"},{"location":"environment/cli/#setting-up-a-namespace","title":"Setting up a Namespace","text":"<p>Working with the CLI assumes that you create a directory which is mirroring a namespace in Direktiv. This directory can be empty or can be a populated from a <code>github clone</code> command. The only requirement is that the namespace already exists. The connection information (address, token and namespace) can be provided with arguments but it is easier to use a <code>.direktiv.yaml</code> with that information. Providing a token is optional but <code>addr</code> and <code>namespace</code> are required.</p> Example .direktiv.yaml<pre><code>auth: \"my-api-key-token\"\naddr: \"https://my-direktiv.server\"\nnamespace: \"direktiv\"\n</code></pre> <p>This file has to be in the root folder of that project and after creating this, that directory is mirroring the file structure in Direktiv.</p>"},{"location":"environment/cli/#pushing-and-executing","title":"Pushing and Executing","text":"<p>After setup there are two commands available. The <code>push</code> command pushes a flow to Direktiv but does not execute it. This command works recursively e.g. <code>direktivctl workflows push .</code>. The <code>exec</code> command uploads and executes the flow. During execution the logs are printed to <code>stdout</code>.</p> CLI Examples<pre><code>direktivctl workflows push myworkflow.yaml\ndirektivctl workflows push myfolder/\ndirektivctl workflows exec mywf.yaml\n</code></pre>"},{"location":"environment/cli/#workflow-attributes","title":"Workflow Attributes","text":"<p>Based on naming convetion workflow attributes can be set as well. If the file starts with the characters as the flow direktivctl will assume it is a flow attribute and create it. </p> <pre><code>mywf.yaml\nmywf.yaml.script.sh\n</code></pre> <p>The above example will create a flow variable <code>script.sh</code> for the flow <code>mywf.yaml</code>.</p>"},{"location":"environment/cli/#profiles","title":"Profiles","text":"<p>If multiple configurations are needed, e.g. for local and remote, direktivctl supports \"profiles\". A profile is a configuration in a list of configurations in the config file. A valid configuration file might look like this:</p> <pre><code>profiles:\n- id: dev\nauth: 123\naddr: http://localhost:8080\nnamespace: test\n- id: prod\nauth: 123\naddr: http://10.100.91.17\nnamespace: test\n</code></pre> <p>The tool supports both types of configuration files, but you cannot mix and match. Either it uses profiles or basic configuration.</p> <p>When using profiles, the default behaviour is to select the first profile defined in the list. To override this behaviour the <code>-P</code>/<code>--profile</code> flag can be used to select one of the other profiles according to its <code>id</code>. For the example above, to push to <code>prod</code> can be done with the flag <code>--profile=prod</code>.</p>"},{"location":"environment/cli/#other-ways-to-configure","title":"Other Ways to Configure","text":"<p>For most configuration settings, direktivctl will check for values in three places in the following order:</p> <ul> <li>Commandline flags.</li> <li>Environment variables.</li> <li>A configuration file.</li> </ul> <p>As long as direktictl finds all of the values required, it doesn't care where it got them from. This means it's not strictly necessary to have a configuration file at all, so long as the settings are defined elsewhere.</p> <p>The flags are self explanatory, and otherwise available via help information (<code>-h</code>/<code>--help</code>). For environment variables, all settings are named the same way they appear in a configuration file, except for the following adjustments:</p> <ul> <li>All characters are UPPERCASE</li> <li>All dashes are replaced with underscores.</li> <li>All named are prefixed with <code>DIREKTIV_</code>.</li> </ul> <p>For example the auth token can be defined with <code>DIREKTIV_AUTH_TOKEN=my-api-key-token</code>.</p>"},{"location":"environment/direktiv-development-environment/","title":"Standalone Environment","text":"<p>To improve function and flow development it is recommended to setup a local development environment. This section explains how to setup the development environment. Details about developing custom functions is described in this section.</p>"},{"location":"environment/direktiv-development-environment/#running-direktiv","title":"Running Direktiv","text":"<p>As mentioned in the \"Getting Started\" guide there are two ways to set up a local development environment besides setting up a full Kubernetes with Direktiv. There is a Docker image and a multipass configuration. This section describes how they can be configured and used. </p>"},{"location":"environment/direktiv-development-environment/#docker","title":"Docker","text":"<p>Setting up a development Direktiv instance on a local machine is very simple. Assuming docker is installed, run the following command:</p> Starting Direktiv<pre><code>docker run --privileged -p 8080:80 -p 31212:31212 -d --name direktiv direktiv/direktiv-kube\n</code></pre> <p>This command starts direktiv as container 'direktiv'. The initial boot-time will take a few minutes. The progress can be followed with:</p> Direktiv Docker Logs<pre><code>docker logs direktiv -f\n</code></pre> <p>Once all pods reach 'running' status, direktiv is ready and the URL <code>http://localhost:8080/api/namespaces</code> is accessible.</p> <p>The database uses a persistent volume so the data stored should survive restarts with 'docker stop/start'. The port-forward of 31212 is the included docker registry.</p> <p>If there is a requirement to execute <code>kubectl</code> commands the container can be accessed via <code>docker exec</code>. For convenience there is a <code>kubectl</code> shortcut <code>kc</code> and command completion is installed as well.</p> Accessing Shell<pre><code>docker exec -it direktiv /bin/bash\n\nkc get pods -A\n</code></pre>"},{"location":"environment/direktiv-development-environment/#enabling-proxy","title":"Enabling Proxy","text":"<p>The following settings can be passed as environmental variables to use this image in environments with a proxy. This has to be done on the first startup. </p> Proxy Settings<pre><code>docker run --privileged -p 8080:80 -p 31212:31212 --env HTTPS_PROXY=\"http://&lt;proxy-address&gt;:443\" --env NO_PROXY=\"127.0.0.0/8,10.0.0.0/8,172.16.0.0/12,172.16.0.0/12,.svc,.default,.local,.cluster.local,localhost,.direktiv-services-direktiv\" -d --name direktiv -ti direktiv/direktiv-kube\n</code></pre>"},{"location":"environment/direktiv-development-environment/#api-key","title":"API Key","text":"<p>If the instance requires an API key it can be added with an environment variable as well.</p> Enable API Key<pre><code>docker run --privileged -p 8080:80 -p 31212:31212 -e APIKEY=123 -d --name direktiv -ti direktiv/direktiv-kube\n</code></pre>"},{"location":"environment/direktiv-development-environment/#enable-eventing","title":"Enable Eventing","text":"<p>Knative Eventing is disabled by default in the Docker image but can be easily enabled during startup with <code>EVENTING=true</code> as environemtn variable.</p> Enable Eventing<pre><code>docker run --privileged -p 8080:80 -p 31212:31212 -e EVENTING=true -d --name direktiv -ti direktiv/direktiv-kube\n</code></pre>"},{"location":"environment/direktiv-development-environment/#debug","title":"Debug","text":"<p>If there are issues starting nested Kubernetes it is possible to see the K3S debug logs on startup with the variable <code>DEBUG</code>.</p> Enable Eventing<pre><code>docker run --privileged -p 8080:80 -p 31212:31212 -e DEBUG=true direktiv/direktiv-kube\n</code></pre> <p>There is always the option to use the multipass configuration if the Docker image does not work.</p>"},{"location":"environment/direktiv-development-environment/#multipass","title":"Multipass","text":"<p>Multipass creates a virtual machine with Direktiv pre-configured. The configuration is different from the Docker image but all features are available to that approach as well. The cloud-init script will do the configuration during first boot and takes a few minutes to complete. Eventing is anebled by default.</p> Start Multipass Instance<pre><code>multipass launch --cpus 4 --disk 20G --memory 6G --name direktiv --cloud-init https://raw.githubusercontent.com/direktiv/direktiv/main/build/docker/all/multipass/init.yaml\n</code></pre> <p>After startup the machine can be access with a simple command. For convenience there is a <code>kubectl</code> shortcut and code completion installed. </p> Accessing Shell<pre><code>multipass exec direktiv -- /bin/bash\n</code></pre> <p>Warning</p> <p>multipass does not work in a VPN. The VPN needs to be turned off for this example installation.</p> <p>If the installation is not successful there is a cloud-init log available on the virtual machine <code>/var/log/cloud-init-output.log</code> to check the logs.</p> <p>The instance has an accessible network configured and the IP is accessible from the host. After startup the UI can be accessed with first IP listed under <code>IPv4</code>. </p> Display IP<pre><code>multipass info direktiv\n\nName:           direktiv\nState:          Running\nIPv4:           10.100.91.90\n                10.42.0.0\n                10.42.0.1\nRelease:        Ubuntu 22.04.2 LTS\nImage hash:     345fbbb6ec82 (Ubuntu 22.04 LTS)\nCPU(s):         4\nLoad:           0.53 0.51 0.25\nDisk usage:     5.0GiB out of 9.5GiB\nMemory usage:   2.1GiB out of 3.8GiB\n</code></pre>"},{"location":"environment/direktiv-development-environment/#enabling-proxy_1","title":"Enabling Proxy","text":"<p>Enabling a proxy has to be done by changing the cloud-init file manually. The first step is to download the file from Github with e.g. curl.</p> Download Cloud-Init<pre><code>curl https://raw.githubusercontent.com/direktiv/direktiv/main/build/docker/all/multipass/init.yaml &gt; myinit.yaml\n</code></pre> <p>The proxy configuration values need to be added as a file under <code>/env</code>. The following snippet is an example for such a configuration.</p> Proxy YAML<pre><code>...\nwrite_files:\n- encoding: b64\ncontent: SCRIPT\npath: /home/install.sh\npermissions: '0755'\n- path: /env\ncontent: |\nHTTP_PROXY=http://10.100.6.16:3128\nHTTPS_PROXY=http://10.100.6.16:3128\nNO_PROXY=127.0.0.0/8,10.0.0.0/8,172.16.0.0/12,172.16.0.0/12,.svc,.default,.local,.cluster.local,localhost,.direktiv-services-direktiv\nappend: true\n</code></pre> <p>After changing the file multipass requires this file instead of the default one.</p> Custom Cloud-Init<pre><code>multipass launch --cpus 4 --disk 20G --memory 6G --name direktiv --cloud-init myinit.yaml\n</code></pre> <p>Warning</p> <p>Multipass can not read and use files in the <code>/tmp</code> directory. Do not place the custom init file in <code>/tmp</code>.</p>"},{"location":"environment/direktiv-development-environment/#enabling-api-key","title":"Enabling API Key","text":"<p>To add an API key it is also required to create a custom cloud-init configuration like the proxy does. The required variables is <code>APIKEY</code>.</p> API Key YAML<pre><code>...\nwrite_files:\n- encoding: b64\ncontent: SCRIPT\npath: /home/install.sh\npermissions: '0755'\n- path: /env\ncontent: |\nAPIKEY=123\nappend: true\n</code></pre>"},{"location":"environment/direktiv-development-environment/#deleting-multipass-intance","title":"Deleting Multipass Intance","text":"<p>To remove the instance the <code>delete</code> and <code>purge</code> command is required.</p> Delete Multipass Instance<pre><code>multipass delete direktiv\nmultipass purge\n</code></pre>"},{"location":"environment/direktiv-development-environment/#docker-registry","title":"Docker registry","text":"<p>Direktiv pulls containers from a registry and use them as functions in flows. For development purposes the direktiv docker container as well as the multipass instances come with a registry installed. It is accessible via :31212. The value for  is either the localhost for Docker or the IP of the multipass instance. <p>To test the local repository the golang example from direktiv-apps can be used:</p> <pre><code>git clone https://github.com/direktiv-apps/bash.git\n\ndocker build bash/ -t &lt;IP&gt;:31212/bash\n\ndocker push &lt;IP&gt;:31212/bash\n\n# confirm upload\ncurl http://&lt;IP&gt;:31212/v2/_catalog\n</code></pre> <p>Multipass Instances</p> <p>Docker doesn not support pushing to <code>http</code> registries. Therefore it has to be added as an insecure registry to the docker service. Add something like the following to <code>/etc/docker/daemon.json</code> and restart the Docker service.</p> <pre><code>{\n\"insecure-registries\" : [\"10.100.91.188:31212\"]\n}\n</code></pre>"},{"location":"environment/direktiv-development-environment/#testing-configuration","title":"Testing Configuration","text":"<p>To test if everything is working this example creates a namespace and a flow and executes it. The value for <code>&lt;ADDRESS&gt;</code> has to be replaced with either <code>localhost:8080</code> for Docker or the IP of the multipass instance. </p> Testing Installation<pre><code># create namespace 'test'\ncurl -X PUT http://&lt;ADDRESS&gt;/api/namespaces/test\n\n# create the workflow file\ncat &gt; helloworld.yml &lt;&lt;- EOF\nfunctions:\n- id: get\n  type: reusable\n  image: gcr.io/direktiv/functions/bash:1.0\nstates:\n- id: getter\n  type: action\n  action:\n    function: get\n    input:\n      commands:\n      - command: ehoc Hello\nEOF\n\n# upload flow\ncurl -X PUT  --data-binary @helloworld.yml \"http://&lt;ADDRESS&gt;/api/namespaces/test/tree/test?op=create-workflow\"\n\n# execute flow (initial call will be slightly slower than subsequent calls)\ncurl \"http://&lt;ADDRESS&gt;/api/namespaces/test/tree/test?op=wait\"\n</code></pre>"},{"location":"environment/git/","title":"Git Mirrors","text":"<p>Direktiv supports keeping a clone of a git repository as a source of flows and variables. </p>"},{"location":"environment/git/#setting-up-a-git-mirror","title":"Setting Up A Git Mirror","text":"<p>Git mirrors can be set up as entire Direktiv namespaces and supports submodules. The following arguments can be supplied when creating a mirror as a namespace:</p> <ul> <li><code>namespace</code></li> <li><code>url</code></li> <li><code>ref</code></li> <li>Auth:</li> <li>None</li> <li>Git access token:<ul> <li><code>access_token</code></li> </ul> </li> <li>SSH<ul> <li><code>private_key</code></li> <li><code>public_key</code></li> <li><code>passphrase</code></li> </ul> </li> </ul> <p>The following arguments are considered sensitive, and will never be returned via the API, except in a redacted form: <code>access_token</code>, <code>private_key</code>, <code>passphrase</code>. </p>"},{"location":"environment/git/#authentication-authorization","title":"Authentication &amp; Authorization","text":""},{"location":"environment/git/#none","title":"None","text":"<p>If a repository is public some providers will allow clients to access it without any form of authentication. SSH requires authentication, that's why the only way to use a zero-auth configuration is with git over HTTP. When using a zero-auth configuration very few fields are needed to set up a mirror. The following is an example:</p> <pre><code>namespace: apps-svc\nurl: https://github.com/direktiv/apps-svc.git\nref: main\n</code></pre>"},{"location":"environment/git/#access-token","title":"Access Token","text":"<p>Github allows users to create personal access tokens (link). These can be used as a form of authentication. These can only be used with git over HTTP. </p> <pre><code>namespace: apps-svc\nurl: https://github.com/direktiv/apps-svc.git\nref: main\naccess_token: my-access-token...\n</code></pre>"},{"location":"environment/git/#ssh","title":"SSH","text":"<p>If the two previous approaches aren't sufficient for your needs, the reliable way of reaching a repository under any and all circumstances is with git over SSH. For this to work, you will need to provide both a public and a private key, and optionally a passphrase used to decrypt the private key, if it is password protected. You will also need to configure the remote server to recognize your SSH key. </p> <pre><code>namespace: apps-svc\nurl: https://github.com/direktiv/apps-svc.git\nref: main\npublic_key: my-public-key...\nprivate_key: my-private-key...\npassphrase: my-passphrase...\n</code></pre>"},{"location":"environment/git/#activities","title":"Activities","text":"<p>All Direktiv mirror operations are encapsulated within an \"activity\". This serves as a way of organizing the logic and logs of an operation in a convenient way. Cloning a remote repository can take time, and it's possible that the operation will fail or produce unexpected results. Check the list of recent activities and their logs to learn more about any issues you encounter.</p>"},{"location":"environment/git/#modifying-the-configuration-of-a-local-mirror","title":"Modifying the Configuration of a Local Mirror","text":"<p>For various reasons you may need to update the settings of a mirror. Whether it's to change which branch or commit it's referencing, or to update your credentials. All of this is supported. For convenience, Direktiv will only apply changes to settings you ask it to, anything else will remain unchanged. This means for example that you can swap from branch <code>v1.0.x</code> to <code>v1.1.x</code> without resupplying your SSH keys if you want to.</p>"},{"location":"environment/git/#repository-contents","title":"Repository Contents","text":""},{"location":"environment/git/#directory","title":"Directory","text":"<p>If a directory appears within the repository it will be created within the local mirror. Except in the following circumstances:</p> <ul> <li>If the directory name begins with <code>.</code></li> <li>If the directory contains no flows (recursively).</li> </ul> <p>This means repositories can group flows logically and have that grouping preserved on Direktiv.</p>"},{"location":"environment/git/#workflow","title":"Workflow","text":"<p>If a file name ends in <code>.yml</code> or <code>.yaml</code> it will be treated as a flow unless it can instead be treated as a workflow variable. As long as the name contains only acceptable workflow name characters.</p> <p>Workflow names will have their suffix trimmed in Direktiv. So <code>hello.yaml</code> will create a workflow called <code>hello</code>. </p> <p>Files that evaluate as flows according to these rules are considered to be so even if they cannot be interpreted as valid flows. This ensures that mirrors can include up-to-date sources that perfectly mirror those found in the remote repository, even if those sources are flawed or incompatible with the version of Direktiv. </p>"},{"location":"environment/git/#workflow-variable","title":"Workflow Variable","text":"<p>If a file name contains <code>.yml.</code> or <code>.yaml.</code> it will be treated as a workflow variable. As long as the name contains only acceptable workflow name characters.</p> <p>Workflow variable names are given as a concatenation of the workflow file and the variable name. For example, if you have a workflow called <code>hello.yaml</code> you can create a workflow variable called <code>x.json</code> by naming it <code>hello.yaml.x.json</code>.</p>"},{"location":"environment/git/#namespace-variable","title":"Namespace Variable","text":"<p>If a file is named with a prefix of \"<code>var.</code>\" it will be treated as a namespace variable. Unless it evaluated to one of the other types already.</p>"},{"location":"environment/git/#archive-variables","title":"Archive Variables","text":"<p>If a directory has a name that would evaluate to a namespace variable or a workflow variable if only the directory was actually a file, Direktiv will still make a variable from it. It will automatically tar the contents of the directory and gzip them, making them easily usable within functions.</p>"},{"location":"events/","title":"Events","text":"<p>Direktiv utilizes the HTTP Protocol Binding for CloudEvents, and offers two distinct ways to produce and consume events. The easiest approach is by using Direktiv's API directly in order to route your desired events. However, if you require more flexibility, Knative can assist with a more powerful and dynamic approach when it comes to eventing. What type of integration is ideal depends on which use cases are meant to be addressed by Direktiv. Independent from this integration approach system internal events within Direktiv are always supported.</p> <p></p>"},{"location":"events/#event-api","title":"Event API","text":"<p>The event API provides direct access to Direktiv's eventing system. The general API path is <code>/api/namespaces/{namespace}/broadcast</code>. Following the cloud-event specification events can be send to Direktiv in three different formats. </p> <p>Event ID<p>The specification requires an event ID. Direktiv generates a random ID if not provided by the client.</p> </p>"},{"location":"events/#binary-content-mode","title":"Binary Content Mode","text":"<p>Th binary content mode uses headers to describe the event metadata with a \"ce-\" prefix and allows for efficient transfer and without transcoding effort. The header \"content-type\" must be set to the content-type of the body of the event.</p> <pre><code>POST /api/namespaces/{namespace}/broadcast HTTP/1.1\nHost: direktiv.io\nce-specversion: 1.0\nce-type: com.example.event\nce-id: 1234-1234-1234\nce-source: /mycontext/subcontext\nContent-Type: application/json; charset=utf-8\n\n{\n   \"hello\": \"world\"\n}\n</code></pre>"},{"location":"events/#structured-content-mode","title":"Structured Content Mode","text":"<p>In structured mode the whole cloudevent is in the payload. The content-type header needs to be set to \"application/cloudevents+json\". </p> <pre><code>{\n\"specversion\" : \"1.0\",\n\"type\" : \"com.github.pull_request.opened\",\n\"source\" : \"https://github.com/cloudevents/spec/pull\",\n\"subject\" : \"123\",\n\"id\" : \"A234-1234-1234\",\n\"datacontenttype\" : \"text/xml\",\n\"data\" : \"&lt;much wow=\\\"xml\\\"/&gt;\"\n}\n</code></pre>"},{"location":"events/#batched-content-mode","title":"Batched Content Mode","text":"<p>In batch mode multiple events can be send to direktiv. The content-type has to be \"application/cloudevents-batch+json\" and the body is a JSON array of cloud events.</p> <pre><code>[\n{\n\"specversion\" : \"1.0\",\n\"type\" : \"com.github.pull_request.opened\",\n\"source\" : \"https://github.com/cloudevents/spec/pull\",\n\"subject\" : \"123\",\n\"id\" : \"C234-1234-1234\",\n\"datacontenttype\" : \"text/xml\",\n\"data\" : \"&lt;much wow=\\\"xml\\\"/&gt;\"\n},\n{\n\"specversion\" : \"1.0\",\n\"type\" : \"com.github.pull_request.opened\",\n\"source\" : \"https://github.com/cloudevents/spec/pull\",\n\"subject\" : \"123\",\n\"id\" : \"B234-1234-1234\",\n\"datacontenttype\" : \"text/xml\",\n\"data\" : \"&lt;much wow=\\\"xml\\\"/&gt;\"\n}\n]\n</code></pre>"},{"location":"events/#other-data","title":"Other Data","text":"<p>If unknown data arrives at the API endpoint Direktiv does not drop the data but converts it into a cloud event. The value for <code>type</code> is set to <code>noncompliant</code> and <code>source</code> to <code>unknown</code>. The payload of the original requets will be base64 encoded and added as <code>data_base64</code> to the event. If the content type can be guessed or is provided in the header it will be part of the cloud event as well.</p> <pre><code>{\n\"noncompliant\": {\n\"data_base64\": \"aHR0cHM6Ly93d3cueW91dHViZS5jb20vd2F0Y2g/dj1kUXc0dzlXZ1hjUQ==\",\n\"datacontenttype\": \"text/plain\",\n\"error\": \"unknown Message encoding\",\n\"id\": \"60290f4b-3971-411a-b824-73b60eb8b72d\",\n\"source\": \"unknown\",\n\"specversion\": \"1.0\",\n\"type\": \"noncompliant\"\n}\n}\n</code></pre>"},{"location":"events/#events-in-flows","title":"Events in Flows","text":"<p>Events in a Direktiv flow can be a start condition and initiate a flow or a workflow can wait for an event during flow execution. Direktiv can wait for single events or on AND and OR combinations of events. </p>"},{"location":"events/#event-start-type-example","title":"Event Start Type Example","text":"<p>The following is an example of a simple start condition for a Direktiv flow. A start condition requires the type and additional <code>context</code> values can be provided. If context values are defined the cloud event has to match the context attribute. For matching glob values can be used. </p> <pre><code>start:\ntype: event\nstate: helloworld\nevent:\ntype: io.direktiv.myevent\ncontext:\nmyvalue: my*\nstates:\n- id: helloworld\ntype: noop\nlog: jq(.)\n</code></pre> <p>The above example flow would trigger if the following cloud event would arrive:</p> <pre><code>{\n\"specversion\" : \"1.0\",\n\"type\" : \"io.direktiv.myevent\",\n\"source\" : \"https://github.com/cloudevents/spec/pull\",\n\"subject\" : \"123\",\n\"myvalue\": \"mydata\"\n}\n</code></pre> <p>Because the defintion uses a glob pattern valid values fo <code>myvalue</code> could be everything starting with <code>my</code>. If the attribute is missing or does not start with <code>my</code> the workflow would not trigger.</p>"},{"location":"events/#events-in-flow-example","title":"Events in Flow Example","text":"<p>Waiting for events within a flow is similar to a start definition except the <code>context</code> can be used to \"link\" flows to each other via context attributes in events. Additionally it can handle timeouts if an event has not been received within a certain time. </p> <pre><code>states:\n\n- id: wait-event\ntype: consumeEvent\ntimeout: PT1M\nevent:\ntype: io.direktiv.myevent\ncontext:\ncustomer: jq(.customer)\ncatch: - error: \"direktiv.cancels.timeout.soft\"\ntransition: timedout\n\n- id: timedout\ntype: noop\nlog: this event timed out\n</code></pre>"},{"location":"events/filter/","title":"Filter","text":"<p>Although Direktiv supports Knative Eventing which supports event filtering, Direktiv adds custom event filtering as well. Direktiv's event filters can be easlily configured and added as additional event route. </p>"},{"location":"events/filter/#javascript","title":"Javascript","text":"<p>Filters are based on Javascript and the filter has access to an <code>event</code> object which can be modified or the event can be dropped based on certain requirements. Direktiv provieds one additional function <code>nslog</code> which adds log entries to the namespace logs.</p> <pre><code>if (event[\"source\"] == \"mysource\") {\nnslog(\"rename source\")\nevent[\"source\"] = \"newsource\"\n}\n\nif (event[\"source\"] == \"hello\") {\nnslog(\"drop me\")\nreturn null\n}\n\nreturn event\n</code></pre> <p>The Javascript can return <code>null</code> which means the event will be dropped andn not handled by Direktiv or it returns the modified <code>event</code> object which goes into the system and will be handled by flows if there are any configured to handle it.</p>"},{"location":"events/filter/#add-filter","title":"Add Filter","text":"<p>Assuming the above filter script is stored in <code>filter.js</code> it can be added to Direktiv with the following CLI command.</p> <pre><code>direktivctl events set-filter -n events -a http://myserver myfilter filter.js </code></pre> <p>If the command was successful the filter is configured and ready to be used. </p> <pre><code>direktivctl events list-filters -n events -a http://myserver \nmyfilter\n</code></pre> <p>To keep the event system performant each filter creates a event route where the rule will be applied. The API path for the filter is <code>/api/namespaces/{namespace}/broadcast/{filtername}</code>. The filter will be applied to every event hitting that API URL. </p> <p>For the following event the source would be renamed. </p> <pre><code>{\n\"specversion\" : \"1.0\",\n\"type\" : \"io.direktiv.myevent\",\n\"source\" : \"mysource\",\n\"subject\" : \"123\"\n}\n</code></pre> <p>This event would be dropped.</p> <pre><code>{\n\"specversion\" : \"1.0\",\n\"type\" : \"io.direktiv.myevent\",\n\"source\" : \"hello\",\n\"subject\" : \"123\"\n}\n</code></pre> <p>A filter can be removed with the following command. </p> <pre><code>direktivctl events delete-filter -n events -a http://myserver myfilter\n</code></pre>"},{"location":"events/cloud/","title":"Cloud","text":"<p>A simple introduction to using events provided from Google, Amazon and Azure to send to Direktiv.</p>"},{"location":"events/cloud/amazon/","title":"Amazon EventBridge","text":"<p>We're going to go through the process of setting up a rule for 'ec2' to send events to our Direktiv service. This explains how to create an api destination and transform the aws event input to cloud event format. </p> <p>Note: the below tutorial assumes that the user has already created the IAM role for the EventBridge API integration as described in Amazon EventBridge User Guide</p> <p>From the Role create above - keep the Role Arn details as it is needed in the final step. A screenshot is shown below:</p> <p> </p>"},{"location":"events/cloud/amazon/#create-a-rule","title":"Create a rule","text":"<pre><code>aws events put-rule --name \"direktiv-rule\" --event-pattern \"{\\\"source\\\": [\\\"aws.ec2\\\"]}\"\n</code></pre> <p>The following output should appear (make sure you hold onto the ARN as it is used further down to attach a target to the rule):</p> <pre><code>{\n\"RuleArn\": \"&lt;RULE_ARN&gt;\"\n}\n</code></pre>"},{"location":"events/cloud/amazon/#create-a-connection","title":"Create a connection","text":"<p>After creating an Authorization token from the Direktiv interface, create the connection using the token as follow:</p> <pre><code>aws events create-connection --name direktiv-connection --authorization-type API_KEY --auth-parameters \"{\\\"ApiKeyAuthParameters\\\": {\\\"ApiKeyName\\\":\\\"direktiv-token\\\", \\\"ApiKeyValue\\\":\\\"&lt;DIREKTIV_TOKEN&gt;\\\"}}\"\n</code></pre> <p>Upon creating the connection the following output from the CLI should appear.</p> <pre><code>{\n\"ConnectionArn\": \"&lt;CONNECTION_ARN&gt;\",\n\"ConnectionState\": \"AUTHORIZED\",\n\"CreationTime\": \"2021-08-04T05:28:24+00:00\",\n\"LastModifiedTime\": \"2021-08-04T05:28:24+00:00\"\n}\n</code></pre> <p>We will need to use the connection arn in the next command.</p>"},{"location":"events/cloud/amazon/#create-an-api-destination","title":"Create an Api-Destination","text":"<pre><code>aws events create-api-destination --name direktiv-api --connection-arn \"&lt;CONNECTION_ARN&gt;\" --invocation-endpoint https://&lt;DIREKTIV_URL&gt;/api/namespaces/&lt;NAMESPACE&gt;/broadcast --http-method POST\n</code></pre> <p>The output should resemble this:</p> <pre><code>{\n\"ApiDestinationArn\": \"&lt;API_ARN&gt;\",\n\"ApiDestinationState\": \"ACTIVE\",\n\"CreationTime\": \"2021-08-04T05:30:50+00:00\",\n\"LastModifiedTime\": \"2021-08-04T05:30:50+00:00\"\n}\n</code></pre>"},{"location":"events/cloud/amazon/#put-targets-to-the-aws-eventbridge-rule","title":"Put Targets to the AWS EventBridge Rule","text":"<p>Adding the targets to the EventBridge rule also requires us to define an Input Path and Input Template.</p> <pre><code>aws events put-targets --rule direktiv-rule --targets '[ { \"Id\": \"direktiv-api\", \"RoleArn\": \"&lt;ROLE_ARN&gt;\", \"Arn\": \"&lt;API_ARN&gt;\", \"InputTransformer\": { \"InputPathsMap\": { \"id\":\"$.id\", \"source\":\"$.source\", \"state\":\"$.detail.state\", \"subject\":\"$.source\", \"time\":\"$.time\", \"type\":\"$.detail-type\" }, \"InputTemplate\": \" {\\\"specversion\\\":\\\"1.0\\\", \\\"id\\\":&lt;id&gt;, \\\"source\\\":&lt;source&gt;, \\\"type\\\":&lt;type&gt;, \\\"subject\\\":&lt;subject&gt;, \\\"time\\\":&lt;time&gt;, \\\"data\\\":&lt;aws.events.event.json&gt;}\" } } ]'\n</code></pre> <p>The output (if successful) below:</p> <pre><code>{\n\"FailedEntryCount\": 0,\n\"FailedEntries\": []\n}\n</code></pre>"},{"location":"events/cloud/amazon/#input-path-map-example","title":"Input Path Map Example","text":"<p>Input Path Map captures the EventBridge event so we can easily filter into a cloud event to send to Direktiv</p> <pre><code>    {\n\"id\": \"$.id\",\n\"source\": \"$.source\",\n\"subject\": \"$.source\",\n\"time\": \"$.time\",\n\"type\": \"$.detail-type\"\n}\n</code></pre>"},{"location":"events/cloud/amazon/#input-template-example","title":"Input Template Example","text":"<p>The Input Template allows you to spec out what you want the JSON to look like parsing the values from the input path.</p> <pre><code>     {\n\"specversion\":\"1.0\", \"id\": \"&lt;id&gt;\", \"source\": \"&lt;source&gt;\", \"type\": \"&lt;type&gt;\", \"subject\": \"&lt;subject&gt;\", \"time\": \"&lt;time&gt;\",\n\"data\": &lt;aws.events.event.json&gt;\n}\n</code></pre> <p>So now when you change the state of an instance on EC2 a workflow will be triggered on Direktiv if it is listening to 'aws.ec2'. For reference, when an AWS event is generated, the default event structure (for an EC2 status change as an example) is shown below:</p> <pre><code>{\n\"version\": \"0\",\n\"id\": \"7bf73129-1428-4cd3-a780-95db273d1602\",\n\"detail-type\": \"EC2 Instance State-change Notification\",\n\"source\": \"aws.ec2\",\n\"account\": \"123456789012\",\n\"time\": \"2015-11-11T21:29:54Z\",\n\"region\": \"us-east-1\",\n\"resources\": [\"arn:aws:ec2:us-east-1:123456789012:instance/i-abcd1111\"],\n\"detail\": {\n\"instance-id\": \"i-abcd1111\",\n\"state\": \"pending\"\n}\n}\n</code></pre> <p>The CloudEvent received by Direktiv after the transformation is shown below:</p> <pre><code>{\n\"specversion\": \"1.0\",\n\"id\": \"f694954a-c307-368c-005a-d4279473e156\",\n\"source\": \"aws.ec2\",\n\"type\": \"EC2 Instance State-change Notification\",\n\"subject\": \"aws.ec2\",\n\"time\": \"2022-05-04T01:57:06Z\",\n\"data\": {\n\"version\": \"0\",\n\"id\": \"f694954a-c307-368c-005a-d4279473e156\",\n\"detail-type\": \"EC2 Instance State-change Notification\",\n\"source\": \"aws.ec2\",\n\"account\": \"338328518639\",\n\"time\": \"2022-05-04T01:57:06Z\",\n\"region\": \"ap-southeast-2\",\n\"resources\": [\n\"arn:aws:ec2:ap-southeast-2:338328518639:instance/i-0cf5a83f321fbed55\"\n],\n\"detail\": {\n\"instance-id\": \"i-0cf5a83f321fbed55\",\n\"state\": \"pending\"\n}\n}\n}\n</code></pre>"},{"location":"events/cloud/amazon/#testing","title":"Testing","text":"<p>Create this simple workflow that gets executed when it receives a cloud-event of a specific type.</p> <pre><code>id: listen-for-event\ndescription: Listen to a custom cloud event\nstart:\ntype: event\nstate: helloworld\nevent:\ntype: \"EC2 Instance State-change Notification\"\nstates:\n- id: helloworld\ntype: noop\ntransform: 'jq({ result: . })'\n</code></pre>"},{"location":"events/cloud/azure/","title":"Azure EventGrid","text":"<p>Goes through the process of setting up a storage account that listens for events on upload. Being that Azure uses native cloud events we won't need to run anything apart from the initial setup.</p>"},{"location":"events/cloud/azure/#setup","title":"Setup","text":"<p>To follow along you will need access to the resource group you wish to setup in. This example includes the creation of a storage account but an existing one can be used.</p>"},{"location":"events/cloud/azure/#create-a-storage-account-container","title":"Create a Storage Account &amp; Container","text":"<p>Create a storage account under a resource group</p> <pre><code>az storage account create --name direktivstoragetest --resource-group trentis-direktiv-apps-test\n</code></pre> <p>Create a container under that storage account. You can get the --account-key by doing the following</p> <pre><code>az storage account keys list --account-name direktivstoragetest\n</code></pre> <pre><code>az storage container create  --name direktiv-container --account-name direktivstorage100  --account-key ACCOUNT-KEY\n</code></pre>"},{"location":"events/cloud/azure/#create-an-event-subscription","title":"Create an Event Subscription","text":"<p>webhook-request-callback sends option request</p> <p>Create an event subscription attached to the storage account.</p> <pre><code>az eventgrid event-subscription create \\\n--name direktiv-event \\\n--source-resource-id=$(az storage account show --name direktivstoragetest --resource-group trentis-direktiv-apps-test --query id --output tsv) \\\n--endpoint=https://playground.direktiv.io/api/namespaces/trent/event \\\n--endpoint-type=webhook --event-delivery-schema cloudeventschemav1_0 \\\n--delivery-attribute-mapping Authorization Static \"Bearer ACCESS_TOKEN\" true\n</code></pre>"},{"location":"events/cloud/azure/#testing","title":"Testing","text":"<pre><code>id: listen-for-azure-event\ndescription: Listen to a custom cloud event\nstart:\ntype: event\nstate: helloworld\nevent:\ntype: Microsoft.Storage.BlobCreated\nstates:\n- id: helloworld\ntype: noop\ntransform: 'jq({ result: . })'\n</code></pre>"},{"location":"events/cloud/gcp/","title":"Google Cloud EventArc","text":"<p>To send Google Cloud Audit log events to EventArc you will need a container service running on Cloud Run. We provide you a container located at 'gcr.io/direktiv/event-arc-listener'. That container's job is to read the cloud event it receives and relays it back to a Direktiv service.</p>"},{"location":"events/cloud/gcp/#setup","title":"Setup","text":""},{"location":"events/cloud/gcp/#setup-audit-logs-to-be-managed","title":"Setup Audit Logs to be managed","text":"<p>Read policy file to /tmp/policy.yaml <pre><code>gcloud projects get-iam-policy PROJECT_ID &gt; /tmp/policy.yaml\n</code></pre></p> <p>Add the follow section above 'bindings:'</p> <pre><code>auditConfigs:\n- auditLogConfigs:\n- logType: ADMIN_READ\n- logType: DATA_WRITE\n- logType: DATA_READ\nservice: storage.googleapis.com\n</code></pre> <p>Set the new policy</p> <pre><code>gcloud projects set-iam-policy PROJECT_ID /tmp/policy.yaml\n</code></pre>"},{"location":"events/cloud/gcp/#setup-configs-for-gcloud-to-run-properly","title":"Setup Configs for Gcloud to run properly","text":"<pre><code>gcloud config set project PROJECT_ID\ngcloud config set run/region us-central1\ngcloud config set run/platform managed\ngcloud config set eventarc/location us-central1\n</code></pre>"},{"location":"events/cloud/gcp/#configure-the-cloud-run-service","title":"Configure the Cloud Run Service","text":""},{"location":"events/cloud/gcp/#using-authentication","title":"Using Authentication","text":"<p>Create a secret to use as the DIREKTIV_TOKEN </p> <pre><code>gcloud secrets create DIREKTIV_TOKEN \\\n--replication-policy=\"automatic\"\n</code></pre> <p>Create a file that contains the ACCESS_TOKEN generated from Direktiv that has 'namespaceEvent' privilege. I chose to create the file as '/tmp/ac'.</p> <p>Add the secret data to the secret <pre><code>gcloud secrets versions add DIREKTIV_TOKEN --data-file=/tmp/ac\n</code></pre></p>"},{"location":"events/cloud/gcp/#create-a-cloud-run-service","title":"Create a Cloud Run Service","text":"<p>Deploy the container to your environment</p> <pre><code>gcloud beta run deploy event-arc-listener --image gcr.io/direktiv/event-arc-listener \\\n--update-secrets=DIREKTIV_TOKEN=DIREKTIV_TOKEN:1 \\\n--set-env-vars \"DIREKTIV_NAMESPACE=trent\" \\\n--set-env-vars \"DIREKTIV_ENDPOINT=https://playground.direktiv.io\" \\\n--allow-unauthenticated\n</code></pre>"},{"location":"events/cloud/gcp/#create-a-trigger-for-the-cloud-run-service","title":"Create a Trigger for the Cloud Run Service","text":"<p>Create a new trigger to listen for storage events on this project. <pre><code>gcloud eventarc triggers create storage-upload-trigger \\\n--destination-run-service=event-arc-listener  \\\n--destination-run-region=us-central1 \\\n--event-filters=\"type=google.cloud.audit.log.v1.written\" \\\n--event-filters=\"serviceName=storage.googleapis.com\" \\\n--event-filters=\"methodName=storage.objects.create\" \\\n--service-account=SERVICE_ACCOUNT_ADDRESS\n</code></pre></p> <p>Note: Keep in mind this trigger will take 10 minutes to work</p>"},{"location":"events/cloud/gcp/#testing","title":"Testing","text":"<p>Create this simple workflow that gets executed when it receives a cloud-event of a specific type.</p> <pre><code>id: listen-for-event\ndescription: Listen to a custom cloud event\nstart:\ntype: event\nstate: helloworld\nevent:\ntype: google.cloud.audit.log.v1.written\nstates:\n- id: helloworld\ntype: noop\ntransform: 'jq({ result: . })'\n</code></pre>"},{"location":"events/knative/example/","title":"Kafka Example","text":"<p>This example uses Kafka as Knative event broker and event source and sink as well. After receiving a message from Kafka, Knative forwards it to Direktiv which subsequently initiates a flow and publishes an event back to Knative which will broker the event to a receive topic in Kafka. To run this example the following steps are required:</p> <ul> <li>Installing Kafka</li> <li>Installing Knative with Kafka</li> <li>Configure Kafka Source</li> <li>Configure Direktiv Source</li> <li>Configuring Kafka Sink</li> <li>Flow</li> </ul> <p>Example Versions</p> <p>The version numbers in this example might have changed over time. Please make sure to update them accordingly if required.</p> <p></p>"},{"location":"events/knative/example/#installing-kafka","title":"Installing Kafka","text":"<p>To enable Knative Eventing in a production environment, Knative requires the installation of an event broker. By setting up triggers and subscriptions, Knative brokers like RabbitMQ or Kafka can build an event mesh architecture. Here we will be using Kafka and the Strimzi Operator for the installation. This is a two-step process, installing the Kafka operator and creating the Kafka cluster itself.</p> Installing Strimzi Operator<pre><code>kubectl create namespace kafka\nkubectl create -f 'https://strimzi.io/install/latest?namespace=kafka' -n kafka\nkubectl wait --for=condition=ready pod -l name=strimzi-cluster-operator -n kafka --timeout=300s\n</code></pre> <p>Kafka Installation</p> <p>The Kafka installation instructions provided here is just an example and can not be used as-is in production environments. Please go to https://strimzi.io for full documentation. </p> <p>After the operator is running the following command enables KRaft for the operator. This allows an installation without Zookeeper and should simplify this setup.</p> Enable KRaft<pre><code>kubectl -n kafka set env deployment/strimzi-cluster-operator STRIMZI_FEATURE_GATES=+UseKRaft\nkubectl wait --for=condition=ready pod -l name=strimzi-cluster-operator -n kafka --timeout=300s\n</code></pre> <p>The following command will create the actual Kafka cluster which will be used in this example. </p> Create Kafka Instance<pre><code>cat &lt;&lt;-EOF | kubectl apply -f -\n---\napiVersion: kafka.strimzi.io/v1beta2\nkind: Kafka\nmetadata:\nname: my-cluster\nnamespace: kafka\nspec:\nkafka:\nversion: 3.4.0\nreplicas: 1\nlisteners:\n- name: plain\nport: 9092\ntype: internal\ntls: false\n- name: tls\nport: 9093\ntype: internal\ntls: true\nconfig:\noffsets.topic.replication.factor: 1\ntransaction.state.log.replication.factor: 1\ntransaction.state.log.min.isr: 1\ndefault.replication.factor: 1\nmin.insync.replicas: 1\ninter.broker.protocol.version: \"3.4\"\nstorage:\ntype: ephemeral\nzookeeper:\nreplicas: 1\nstorage:\ntype: ephemeral\nEOF\n</code></pre>"},{"location":"events/knative/example/#knative-with-kafka","title":"Knative with Kafka","text":"<p>To use Kafka as the underlying mechanism for message brokering Knative needs to be configured during installation. The YAML here will create Knative Eventing instance with the required settings.</p> Knative Eventing with Kafka<pre><code>cat &lt;&lt;-EOF | kubectl apply -f -\n---\napiVersion: v1\nkind: Namespace\nmetadata:\nname: knative-eventing\n---\napiVersion: operator.knative.dev/v1beta1\nkind: KnativeEventing\nmetadata:\nname: knative-eventing\nnamespace: knative-eventing\nspec:\nconfig:\nconfig-br-default-channel:\nchannel-template-spec: |\napiVersion: messaging.knative.dev/v1beta1\nkind: KafkaChannel\nspec:\nnumPartitions: 6\nreplicationFactor: 1\ndefault-ch-webhook:\ndefault-ch-config: |\nclusterDefault:\napiVersion: messaging.knative.dev/v1beta1\nkind: KafkaChannel\nspec:\nnumPartitions: 10\nreplicationFactor: 1\nEOF\n</code></pre> <p>This installation requires the Knative Kafka controller and data plane as well. This can be installed with two <code>kubectl</code> commands.</p> Knative Kafka Dependencies<pre><code>kubectl apply --filename https://github.com/knative-sandbox/eventing-kafka-broker/releases/download/knative-v1.9.3/eventing-kafka-controller.yaml\nsleep 3\nkubectl apply --filename https://github.com/knative-sandbox/eventing-kafka-broker/releases/download/knative-v1.9.3/eventing-kafka-broker.yaml\n</code></pre> <p>The last step is to create the actual broker. The following two commands are creating the broker configuration and the broker using the configuration.</p> Kafka Configuration<pre><code>cat &lt;&lt;-EOF | kubectl apply -f -\n---\napiVersion: v1\nkind: ConfigMap\nmetadata:\nname: kafka-broker-config\nnamespace: knative-eventing\ndata:\ndefault.topic.partitions: \"10\"\ndefault.topic.replication.factor: \"1\"\nbootstrap.servers: \"my-cluster-kafka-bootstrap.kafka:9092\"\nEOF\n</code></pre> Creating Broker<pre><code>cat &lt;&lt;-EOF | kubectl apply -f -\n---\napiVersion: eventing.knative.dev/v1\nkind: Broker\nmetadata:\nannotations:\neventing.knative.dev/broker.class: Kafka\nname: default\nnamespace: knative-eventing\nspec:\nconfig:\napiVersion: v1\nkind: ConfigMap\nname: kafka-broker-config\nnamespace: knative-eventing\nEOF\n</code></pre> <p>The Kafka broker is now up and running. The setup can be tested with <code>kubectl</code>.</p> Working Knative Eventing<pre><code>kubectl get brokers.eventing.knative.dev\nNAME      URL                                                                              AGE   READY   REASON\ndefault   http://kafka-broker-ingress.knative-eventing.svc.cluster.local/default/default   16m   True    </code></pre>"},{"location":"events/knative/example/#configuring-kafka-source","title":"Configuring Kafka Source","text":"<p>Kafka will be an event source and a sink in this example. Therefore we need two channels. One channel sending messages and a second channeld to receive the outcome of the whole message process. </p> Sender &amp; Receiver Topics<pre><code>cat &lt;&lt;-EOF | kubectl apply -f -\n---\napiVersion: kafka.strimzi.io/v1beta2\nkind: KafkaTopic\nmetadata:\nname: sender-topic\nnamespace: kafka\nlabels:\nstrimzi.io/cluster: my-cluster\nspec:\npartitions: 3\nreplicas: 1\nconfig:\nretention.ms: 7200000\nsegment.bytes: 1073741824\n---\napiVersion: kafka.strimzi.io/v1beta2\nkind: KafkaTopic\nmetadata:\nname: receiver-topic\nnamespace: kafka\nlabels:\nstrimzi.io/cluster: my-cluster\nspec:\npartitions: 3\nreplicas: 1\nconfig:\nretention.ms: 7200000\nsegment.bytes: 1073741824\nEOF\n\nkubectl get kafkatopics.kafka.strimzi.io  -n kafka\n</code></pre> <p>With that setup a Kafka source can be installed which will trigger the event flow. This YAML creates the source which sends all messages to the Kafka broker. This shows the decoupling of the events. The producer or sender is unaware of the receiver(s) of the message. </p> Install Kafka Source<pre><code>kubectl apply -f https://github.com/knative-sandbox/eventing-kafka-broker/releases/download/knative-v1.9.3/eventing-kafka-source.yaml\n\ncat &lt;&lt;-EOF | kubectl apply -f -\n---\napiVersion: sources.knative.dev/v1beta1\nkind: KafkaSource\nmetadata:\nname: direktiv-kafka-source\nnamespace: knative-eventing\nspec:\nconsumerGroup: knative-group\nbootstrapServers:\n- my-cluster-kafka-bootstrap.kafka:9092\ntopics:\n- sender-topic\nsink:\nref:\napiVersion: eventing.knative.dev/v1\nkind: Broker\nname: default\nEOF\n</code></pre> Working Kafka Source<pre><code>kubectl get kafkasources.sources.knative.dev\n\nNAME                    TOPICS                       BOOTSTRAPSERVERS                            READY   REASON   AGE\ndirektiv-kafka-source   [\"sender-topic\"]             [\"my-cluster-kafka-bootstrap.kafka:9092\"]   True             4m16s\n</code></pre> <p>With this source enabled Knative can receive events but it requires a trigger to have another system consume the event. A trigger is a simple mechnism in Knative to \"forward\" certain events to subscribers. In this YAML there is a trigger filter defined this trigger consumes all events of type <code>dev.knative.kafka.event</code> and forwards it to Direktiv's direktiv-eventing service. The <code>uri</code> value specifies the target namespace in Direktiv. For more information about eventing filters visit the Knative documentation page about filters.</p> Trigger to Direktiv<pre><code>cat &lt;&lt;-EOF | kubectl apply -f -\n---\napiVersion: eventing.knative.dev/v1\nkind: Trigger\nmetadata:\nname: direktiv-in\nnamespace: knative-eventing\nspec:\nbroker: default\nfilter:\nattributes:\ntype: dev.knative.kafka.event\nsubscriber:\nref:\napiVersion: v1\nkind: Service\nname: direktiv-eventing\nuri: /direktiv\nEOF\n</code></pre> <p>This setup can already send events to a namespace called <code>direktiv</code> if data arrives at the <code>sender-topic</code> topic in Kafka. This can be easily tested if the namespace <code>direktiv</code> already exists in Direktiv. To test it we start a pod which connects to the sender topic.</p> Kafka Client Pod<pre><code>kubectl -n kafka run kafka-producer -ti --image=quay.io/strimzi/kafka:latest-kafka-3.4.0 --rm=true --restart=Never -- bin/kafka-console-producer.sh --broker-list my-cluster-kafka-bootstrap.kafka:9092 --topic sender-topic\n</code></pre> <p>After running the pod add JSON into the command prompt, e.g. {}. This sends the JSON object to Kafka. Knative's broker will pick up the message and execute the trigger for Direktiv. The event will appear on the direktiv namespace dashboard.</p> <p></p>"},{"location":"events/knative/example/#configuring-direktiv-source","title":"Configuring Direktiv Source","text":"<p>To connect Direktiv back to Knative we need to install <code>direktiv-knative-source</code>. This source listens to events generated in Direktiv and pushes them to Knative. In this example the message is pushed back to the broker which can then use triggers to distribute the event. The required argument for this source is the direktiv URI within the cluster, e.g. <code>direktiv-flow.default:3333</code>.</p> Direktiv Source<pre><code>cat &lt;&lt;-EOF | kubectl apply -f -\n---\napiVersion: sources.knative.dev/v1\nkind: ContainerSource\nmetadata:\nname: direktiv-source\nnamespace: knative-eventing\nspec:\ntemplate:\nspec:\ncontainers:\n- image: vorteil/direktiv-knative-source\nname: direktiv-source\nargs:\n- --direktiv=direktiv-flow.default:3333\nsink:\nref:\napiVersion: eventing.knative.dev/v1\nkind: Broker\nname: default\nEOF\n</code></pre>"},{"location":"events/knative/example/#configuring-kafka-sink","title":"Configuring Kafka Sink","text":"<p>The last step is to create a Kafka sink which consumes the event coming from Direktiv. This closes the communication cycle from Kafka to Direktiv and back to Kafka again. For this to work a Kafka sink has to be installed.</p> Kafka Sink Installation<pre><code>kubectl apply -f https://github.com/knative-sandbox/eventing-kafka-broker/releases/download/knative-v1.9.3/eventing-kafka-sink.yaml\n\ncat &lt;&lt;-EOF | kubectl apply -f -\n---\napiVersion: eventing.knative.dev/v1alpha1\nkind: KafkaSink\nmetadata:\n  name: direktiv-kafka-sink\n  namespace: knative-eventing\nspec:\n  topic: receiver-topic\n  bootstrapServers:\n  - my-cluster-kafka-bootstrap.kafka:9092\nEOF\n</code></pre> <p>Sink Topic</p> <p>Send a message to the <code>receiver-topic</code> if the sink reports an error about a missing topic:  <pre><code>kubectl -n kafka run kafka-receiver -ti --image=quay.io/strimzi/kafka:latest-kafka-3.4.0 --rm=true --restart=Never -- bin/kafka-console-producer.sh --broker-list my-cluster-kafka-bootstrap.kafka:9092 --topic receiver-topic\n</code></pre></p> <p>After installing the sink a trigger is required to tie them together. A filter can applied to that trigger as well. In this case the trigger accepts events if the type of the cloudevent is <code>myevent</code>.</p> Kafka Receiver Sink<pre><code>cat &lt;&lt;-EOF | kubectl apply -f -\n---\napiVersion: eventing.knative.dev/v1\nkind: Trigger\nmetadata:\nname: direktiv-receive\nnamespace: knative-eventing\nspec:\nbroker: default\nfilter:\nattributes:\ntype: myevent\nsubscriber:\nref:\napiVersion: eventing.knative.dev/v1alpha1\nkind: KafkaSink\nname: direktiv-kafka-sink\nEOF\n</code></pre>"},{"location":"events/knative/example/#flow","title":"Flow","text":"<p>After all components are installed and connected a flow in Direktiv is required to actually transfrom the message and send it back. The example flow in the <code>direktiv</code> namespace here will listen to all <code>dev.knative.kafka.event</code> events and return the event under the new attribute <code>x</code>.</p> Simple Flow<pre><code>start:\ntype: event\nstate: tellme\nevent:\ntype: dev.knative.kafka.event\nstates:\n- id: tellme\ntype: generateEvent\nevent:\ntype: myevent\nsource: Direktiv\ndata:\nx: jq(.\"dev.knative.kafka.event\".data)\n</code></pre> <p>With that setup a new message e.g. <code>\"Hello\"</code> on the <code>sender-topic</code> queue should show as <code>{ \"x\": { \"Hello\" }}</code> in the receiver topic. Please make sure to send valid JSON because this is being used as the data playload for the event. </p> Listen to Receiver Topic<pre><code>kubectl -n kafka run kafka-consumer -ti --image=quay.io/strimzi/kafka:latest-kafka-3.4.0 --rm=true --restart=Never -- bin/kafka-console-consumer.sh --bootstrap-server my-cluster-kafka-bootstrap:9092 --topic receiver-topic --from-beginning\n</code></pre>"},{"location":"events/knative/knative/","title":"Eventing","text":"<p>Direktiv provides a sink and a source for integration into Knative Eventing. Knative uses a broker to relay events between systems and the Kafka example shows how to use Kafka as broker. This section however explains the concept via direct connections between sinks and sources. </p>"},{"location":"events/knative/knative/#preparing-direktiv","title":"Preparing Direktiv","text":"<p>Knative requires a sink to send events to Direktiv. Direktiv comes with a ready-to-use Knative sink but it has to be enabled. This can be done during installation or afterward with an <code>helm upgrade</code>. The following configuration in Direktiv's <code>value.yaml</code> adds the required sink service.</p> Enabling Eventing<pre><code>eventing:\nenabled: true\n</code></pre> Upgrade Direktiv<pre><code>helm upgrade -f direktiv.yaml -n direktiv direktiv direktiv/direktiv\n</code></pre> <p>After that change there is an additional service <code>direktiv-eventing</code> available in Direktiv's namespace. </p>"},{"location":"events/knative/knative/#knative-installation","title":"Knative Installation","text":"<p>During the default installation Knative's operator has been installed an makes installing Knative eventing an easy task with the default settings. </p> Operator Installation<pre><code>kubectl apply -f https://github.com/knative/operator/releases/download/knative-v1.9.4/operator.yaml\n</code></pre> Create Eventing Namespace<pre><code>kubectl create ns knative-eventing\n</code></pre> Install Default Knative Eventing<pre><code>kubectl apply -f - &lt;&lt;EOF\napiVersion: operator.knative.dev/v1beta1\nkind: KnativeEventing\nmetadata:\nname: knative-eventing\nnamespace: knative-eventing\nEOF\n</code></pre> <p>Default Installation</p> <p>The default installation uses an in-memory channel which is not recommended in production use because it is best-effort. </p>"},{"location":"events/knative/knative/#simple-ping-source","title":"Simple Ping Source","text":"<p>An easy way to test test the installation is to install a \"ping\" source. This is one of many sources provided by the Knative project. The examples below are almost identical except the <code>uri</code> parameter. Direktiv uses this to define the target namespaces. If the value is empty or <code>/</code> it will send the event to all namespace. If it contains a value e.g. <code>/mynamespace</code> it will send it to that namespace only. Event filters can be defined with a query parameter <code>filter</code>, e.g. <code>/mynamespace?filter=myfilter</code>.</p> Events For All Namespaces<pre><code>kubectl apply -f - &lt;&lt;EOF\napiVersion: sources.knative.dev/v1\nkind: PingSource\nmetadata:\nname: my-ping\nnamespace: default\nspec:\nschedule: \"*/1 * * * *\"\ncontentType: application/json\ndata: '{\"message\": \"Hello world!\"}'\nsink:\nref:\napiVersion: v1\nkind: Service\nname: direktiv-eventing   EOF\n</code></pre> Events For One Namespace<pre><code>kubectl apply -f - &lt;&lt;EOF\napiVersion: sources.knative.dev/v1\nkind: PingSource\nmetadata:\nname: my-ping\nnamespace: default\nspec:\nschedule: \"*/1 * * * *\"\ncontentType: application/json\ndata: '{\"message\": \"Hello world!\"}'\nsink:\nref:\napiVersion: v1\nkind: Service\nname: direktiv-eventing   uri: /hello\nEOF\n</code></pre>"},{"location":"events/knative/vmware/","title":"VMware Example","text":"<p>Connecting Direktiv and VMWare vSphere or ESXi via Knative Eventing is a very simple process because VMWare provides a Knative eventing source for their products. If Knative Eventing is configured with Direktiv there are just three simple steps required to connect these components.  </p> <p>VMWare Version</p> <p>This example has been tested with 7.x and 8.x</p>"},{"location":"events/knative/vmware/#installing-vmware-tanzu-sources","title":"Installing VMWare Tanzu Sources","text":"<p>The VMWare sources can be directly installed from the source repository with a <code>kubectl</code> command.</p> Apply Tanzu Source<pre><code>kubectl apply -f https://github.com/vmware-tanzu/sources-for-knative/releases/download/v0.36.3/release.yaml\n</code></pre> <p>VMWare Source Version</p> <p>Please check for the latest version of the VMWare sources</p> <p>After running the command there shouild be three pods available in the namespace <code>vmware-sources</code>:</p> <ul> <li>horizon-source-webhook</li> <li>vsphere-source-webhook</li> <li>horizon-source-controller</li> </ul>"},{"location":"events/knative/vmware/#creating-credentials","title":"Creating Credentials","text":"<p>To connect to vSphere or ESXi the source needs the credentials and connectivity information. It requires a kubernetes secrets which will be consumed later by the actual source.</p> VMWare Secret<pre><code>kubectl apply -f - &lt;&lt;EOF\napiVersion: v1\nkind: Secret\nmetadata:\nname: vsphere-credentials\nnamespace: vmware-sources\ntype: kubernetes.io/basic-auth\nstringData:\nusername: root\npassword: MySecretPassword\nEOF\n</code></pre> <p>The next stpe is to create the actual source. It requires the address and the reference to the crednetials used. The sink is the default Direktiv sink. The namespace of the sink might need to be adjusted to fit the installation namespace.</p> Create Source<pre><code>kubectl apply -f - &lt;&lt;EOF\napiVersion: sources.tanzu.vmware.com/v1alpha1\nkind: VSphereSource\nmetadata:\nname: source\nnamespace: vmware-sources\nspec:\n# Where to fetch the events, and how to auth.\naddress: https://192.168.220.128\nskipTLSVerify: true\nsecretRef:\nname: vsphere-credentials\n\n# Where to send the events.\nsink:\nref:\napiVersion: v1\nkind: Service\nname: direktiv-eventing\nnamespace: default\nuri: /hello?filter=test # sending to namespace vmware\n\n# Adjust checkpointing and event replay behavior\ncheckpointConfig:\nmaxAgeSeconds: 300\nperiodSeconds: 10\n\n# Set the CloudEvent data encoding scheme to JSON\npayloadEncoding: application/json\nEOF\n</code></pre>"},{"location":"events/knative/vmware/#testing-and-filtering","title":"Testing And Filtering","text":"<p>By default there should be enough events generated within VMWare to see incoming events on the monitoring page of Direktiv. These events can be e.g. of type <code>com.vmware.vsphere.VmBeingCreatedEvent.v0</code> or <code>com.vmware.vsphere.VmStartingEvent.v0</code>. Because there a many events it might be worthwhile to filter them. </p> <p>For thie filtering there are two options. Either use the native Knative trigger/filter mechanism or Direktiv's built-in event filter. </p> <p>Direktiv supports Javascript filters for events and this example will rename logout events, drop login events and pass through all other events as-is.</p> Direktiv Filter<pre><code>nslog(\"event incoming\")\n\nif (event[\"type\"] == \"com.vmware.vsphere.UserLogoutSessionEvent.v0\") {\nnslog(\"logout type\")\nevent[\"type\"] = \"vmware-logout\"\n}\n\nif (event[\"type\"] == \"com.vmware.vsphere.UserLoginSessionEvent.v0\") {\nnslog(\"drop login session\")\nreturn null\n}\n\nreturn event\n</code></pre> Applying Filter<pre><code>direktivctl events set-filter -n MYNAMESPACE -a http://DIREKTIV_SERVER filterName filter.js </code></pre>"},{"location":"examples/aws/","title":"AWS Examples","text":"<p>AWS Examples on Github</p> <p>These examples should how you can communicate with AWS using the aws images. There are two examples, one is how to run a ec2 instance and the other is how to upload a file to a s3 bucket. </p> <p>These examples require the following namespace secrets to be set:</p> <ul> <li>ACCESS_KEY</li> <li>SECRET_ACCESS_KEY</li> </ul> <p>The flow will use these secrets to configure AWS access.</p>"},{"location":"examples/aws/#run-ec2-instance-flow-example","title":"Run EC2 Instance Flow Example","text":"<p>This flow will create a new t2.small instance on ec2 ap-southeast-2 region. The flow uses the 'awsgo' action which executes the cli command passed in the command input property.</p> Start AWS Instance<pre><code>functions:\n- id: aws-cli\nimage: gcr.io/direktiv/functions/aws-cli:1.0\ntype: knative-workflow\n\nstates:\n- id: start-instance\ntype: action\naction:\nsecrets: [\"ACCESS_KEY\", \"ACCESS_SECRET\"]\nfunction: aws-cli\ninput: access-key: jq(.secrets.ACCESS_KEY)\nsecret-key: jq(.secrets.ACCESS_SECRET)\nregion: ap-southeast-2\ncommands: - command: aws ec2 run-instances --image-id ami-07620139298af599e --instance-type t2.small\n</code></pre>"},{"location":"examples/aws/#upload-file-to-s3-bucket-example","title":"Upload File to S3 Bucket Example","text":"<p>This flow will upload a file to a S3 bucket. The file name and data are set in the input. The input property <code>fileData</code> can be a url-encoded base64 string or a standard base64 string.</p> Start AWS Instance<pre><code>functions:\n- id: s3\nimage: gcr.io/direktiv/functions/aws-cli:1.0\ntype: knative-workflow\n\nstates:\n- id: validate-input\ntype: validate\ntransform: 'jq(. + {fileData: .fileData | split(\"base64,\")[-1]})'\nschema:\ntype: object\nrequired:\n- fileName\n- fileData\nproperties:\nfileName:\ntitle: Filename\ndescription: Filename to be set in S3 bucket\ntype: string\nfileData:\ntitle: File\ndescription: File to upload\ntype: string\nformat: data-url\ntransition: store\n\n# stores the uploaded file as binary\n- id: store\ntype: setter\nvariables:\n- key: data\nscope: workflow\nmimeType: application/octet-stream\nvalue: 'jq(.fileData)'\ntransition: upload-file\n\n- id: upload-file\ntype: action\naction:\nfunction: s3\nsecrets: [\"ACCESS_KEY\", \"ACCESS_SECRET\"]\nfiles: - key: data\nscope: workflow\nas: jq(.fileName)\ninput:\naccess-key: jq(.secrets.ACCESS_KEY)\nsecret-key: jq(.secrets.ACCESS_SECRET)\nregion: ap-southeast-2\ncommands: - command: aws s3 cp jq(.fileName) s3://direktiv/\n</code></pre> Input<pre><code>{\n\"fileData\": \"SGVsbG8sIHdvcmxkIQ==\",\n\"fileName\": \"message.txt\"\n}\n</code></pre>"},{"location":"examples/conditional-states/","title":"Conditional State","text":"<p>Conditional State on Github</p> <p>This example demonstrates the use of a switch state to conditional transition to different states based on a jq expression.  To show this, the example below is a flow that either approves or rejects a loan depending on the provided credit score and required minimum credit score.</p> Simple Switch Statement<pre><code>description: |\nConditionally transition to states depending if input credit score is higher\nor lower than creditMinRequired.\n\nstates:\n- id: validate-input\ntype: validate\nschema:\ntype: object\nrequired:\n- creditScore\n- creditMinRequired\nproperties:\ncreditMinRequired:\ntype: number\ntitle: Minimum credit score\ndescription: minimum credit score required for approval default: 500\ncreditScore:\ntype: number\ndescription: credit score of user\ntitle: Credit Score\ntransition: check-credit\n\n#\n# Check if the user's threshold is above minimum credit requirements.\n# If credit score meets requirements transition to approve-loan. Otherwise\n# transition to reject-loan.\n#\n- id: check-credit\ntype: switch\nconditions:\n- condition: jq(.creditScore &gt; .creditMinRequired)\ntransition: approve-loan\ndefaultTransition: reject-loan\n- id: reject-loan\ntype: noop\ntransform: 'jq({ \"msg\": \"You have been rejected for this loan\" })'\n- id: approve-loan\ntype: noop\ntransform: 'jq({ \"msg\": \"You have been approved for this loan\" })'\n</code></pre> Input<pre><code>{\n\"creditMinRequired\": 500,\n\"creditScore\": 600\n}\n</code></pre> Output<pre><code>{\n\"msg\": \"You have been approved for this loan\"\n}\n</code></pre>"},{"location":"examples/counter-persistent-data/","title":"Counter","text":"<p>Counter on Github</p> <p>A simple example that shows how to store a counter as a flow variable for persistent data. Any state data can be set to a variable to be used in later instances. If the variable does not exist it is empty but is getting created the first time it will be stored.</p> Counter Example<pre><code>description: \"Simple Counter getter and setter variable example\"\nstates:\n#\n# Get flow counter variable and increment value\n#\n- id: counter-get\ntype: getter transition: counter-set\nvariables:\n- key: counter\nscope: workflow\ntransform: 'jq(. += {\"newCounter\": (.var.counter + 1)})'\n\n#\n# Set workflow counter variable\n#\n- id: counter-set\ntype: setter\nvariables:\n- key: counter\nscope: workflow value: 'jq(.newCounter)'\n</code></pre>"},{"location":"examples/counter-persistent-data/#output","title":"Output","text":"Output<pre><code>{\n\"newCounter\": 1,\n\"var\": {\n\"counter\": 0\n}\n}\n</code></pre>"},{"location":"examples/cron/","title":"Cron","text":"<p>Cron on Github</p> <p>Direktiv flows can have different start actions. This can be a direct call or waiting for events.  Another way of executing flows is the cron start definition.</p> Cron<pre><code>start:\ntype: scheduled\ncron: '* * * * *' # Trigger a new instance every minute.\n\nstates:\n- id: run\ntype: noop\nlog: Run Cron\n</code></pre>"},{"location":"examples/foreach/","title":"Foreach","text":"<p>Foreach  on Github</p> <p>The <code>foreach</code> state requires the <code>array</code> attribute to loop over. The difference to other states is that the data in the action of the <code>foreach</code> function is not getting the state data of the flow but the values provided in the array. </p>"},{"location":"examples/foreach/#simple-foreach","title":"Simple Foreach","text":"<p>This is the most basic example. It shows that each action call in the foreach loop has it's own object during execution. In the flow scope there is a variable <code>.names</code>. But the <code>array</code> definition uses jq to iterate through <code>.names</code> and creates a list of JSON objects with the variable <code>name</code>. This means that each action only sees an object with the value <code>name</code> and has no access to <code>names</code>.</p> Simple Foreach<pre><code>functions:\n- id: echo\nimage: gcr.io/direktiv/functions/echo:1.0\ntype: knative-workflow\n\nstates:\n\n- id: data\ntype: noop\nlog: preparing foreach data\ntransform:\nnames:\n- hello\n- world\n- goodbye\ntransition: foreach\n\n- id: foreach\ntype: foreach\narray: 'jq([.names[] | { name: . }])'\naction:\nfunction: echo\ninput: 'jq(.)'\n</code></pre> <p>The output for this flow should be something like the following:</p> Output<pre><code>{\n\"names\": [\n\"hello\",\n\"world\",\n\"goodbye\"\n],\n\"return\": [\n{\n\"name\": \"hello\"\n},\n{\n\"name\": \"world\"\n},\n{\n\"name\": \"goodbye\"\n}\n]\n}\n</code></pre>"},{"location":"examples/foreach/#foreach-with-jq","title":"Foreach with JQ","text":"<p>This examples shows how to use JQ for a more complex foreach scenario. It generates an array based on <code>.data</code> in the first state. The JQ command is storing the state data <code>.otherdata</code> in the variable <code>od</code>. This result will be piped into the actual array generation with <code>.data[]</code>. In this case it is more obvious how each <code>foreach</code> action gets it's own JSON object. In this case the JQ command sets the <code>name</code> to the name in the array, <code>time</code> to the actual time with the JQ <code>time</code> function. The last attribute <code>otherdata</code> passes the original value from the flow state data into the action.</p> JQ Foreach<pre><code>functions:\n- id: echo\nimage: gcr.io/direktiv/functions/echo:1.0\ntype: knative-workflow\n\nstates:\n\n- id: data\ntype: noop\ntransform:\ndata:\n- name: key1\nvalue: value1\n- name: key2\nvalue: value2\n- name: key3\nvalue: value3\notherdata: somedata\ntransition: foreach\n\n- id: foreach\ntype: foreach\narray: 'jq(.otherdata as $od | [.data[] | { name: .name, time: now, otherdata: $od }])'\naction:\nfunction: echo\ninput: 'jq(.)'\n</code></pre> Output<pre><code>{\n\"data\": [\n{\n\"name\": \"key1\",\n\"value\": \"value1\"\n},\n{\n\"name\": \"key2\",\n\"value\": \"value2\"\n},\n{\n\"name\": \"key3\",\n\"value\": \"value3\"\n}\n],\n\"otherdata\": \"somedata\",\n\"return\": [\n{\n\"name\": \"key1\",\n\"otherdata\": \"somedata\",\n\"time\": 1680972341.2246315\n},\n{\n\"name\": \"key2\",\n\"otherdata\": \"somedata\",\n\"time\": 1680972341.224634\n},\n{\n\"name\": \"key3\",\n\"otherdata\": \"somedata\",\n\"time\": 1680972341.2246354\n}\n]\n}\n</code></pre>"},{"location":"examples/foreach/#foreach-with-js","title":"Foreach with JS","text":"<p>This example uses Javascript to achieve the same outcome. If data structures are getting too complex it might be better to use Javascript for readability. If Javascript is used Direktiv passes in an object <code>data</code> which contains the flow state. Data can be accessed in the usual way like <code>data[\"otherdata\"]</code>. In the case of a <code>foreach</code> the Javascript function needs to return an array.</p> JS Foreach<pre><code>functions:\n- id: echo\nimage: gcr.io/direktiv/functions/echo:1.0\ntype: knative-workflow\n\nstates:\n- id: data\ntype: noop\ntransform:\ndata:\n- name: key1\nvalue: value1\n- name: key2\nvalue: value2\n- name: key3\nvalue: value3\notherdata: somedata\ntransition: foreach\n- id: foreach\ntype: foreach\narray: |\njs(\n// empty array\nconst items = []\n\n// loop over \"data\" attribute created in first state of flow\nfor (let i = 0; i &lt; data[\"data\"].length; i++) { \n// create object and set attributes\nitem = new Object();  \nitem.name = data[\"data\"][i][\"name\"]\nitem.time = Date.now()\nitem.otherdata = data[\"otherdata\"]\n\n// add item\nitems[i] = item\n}\n\n// return array of items\nreturn items\n)\naction:\nfunction: echo\ninput: 'jq(.)'\n</code></pre>"},{"location":"examples/greeting-event-listener/","title":"Event-based Workflow","text":"<p>Event-based Workflow on Github</p> <p>This example demonstrates a flow that waits for a cloud event with type <code>greetingcloudevent</code>. When the event is received, a state will be triggered using the data provided by the event. Because this flow has a start of type event, directly executing this flow is not necessary. </p> <p>To trigger the listener flow, a second flow will be created to generate the cloud event. </p> <p>The <code>generate-greeting</code> flow generates the <code>greetingcloudevent</code> that the <code>eventbased-greeting</code> flow is waiting for.</p> Listener Workflow<pre><code># Example Input:\n# This input is a cloud event and was generated from the greeting-generate flow.\n# {\n#   \"greetingcloudevent\": {\n#     \"data\": {\n#       \"name\": \"Trent\"\n#     },\n#     \"datacontenttype\": \"application/json\",\n#     \"id\": \"2638e2d6-754e-409f-9038-f725e0d9d0af\",\n#     \"source\": \"Direktiv\",\n#     \"specversion\": \"1.0\",\n#     \"type\": \"greetingcloudevent\"\n#   }\n# }\n#\n# Example Output\n# {\n#     \"return\": {\n#         \"greeting\": \"Welcome to Direktiv, World!\"\n#     }\n# }\n\n\ndescription: |\nPassively listen for cloud events where the type equals \"greetingcloudevent\" and\nthen execute a action state to call the direktiv/greeting action, which 'greets' \nthe user specified in the \"name\" field of the input provided to the flow.\n\nBecause this flow has a start of type event, directly executing this flow \nis not necessary.\n\n#\n# Start of type event definition sets the flow to be executed when a event\n# is triggered with the defined type 'greetingcloudevent'\n#\nstart:\ntype: event\nstate: greeter\nevent:\ntype: greetingcloudevent\n\nfunctions:\n- id: hello-world\nimage: gcr.io/direktiv/functions/hello-world:1.0\ntype: knative-workflow\n\n\nstates:\n- id: greeter\ntype: action\nlog: jq(.greetingcloudevent.data.name)\naction: function: hello-world\ninput: name: jq(.greetingcloudevent.data.name)\ntransform: 'jq({ \"greeting\": .return.\"hello-world\" })'\n</code></pre> Output<pre><code>{\n\"return\": {\n\"greeting\": \"Welcome to Direktiv, World!\"\n}\n}\n</code></pre> Generator Workflow<pre><code>description: |\nGenerate a cloud with of type \"greetingcloudevent\" with name data as input.\n\nstates:\n# Example Generated Cloud Event:\n# {\n#   \"greetingcloudevent\": {\n#     \"data\": {\n#       \"name\": \"World\"\n#     },\n#     \"datacontenttype\": \"application/json\",\n#     \"id\": \"2638e2d6-754e-409f-9038-f725e0d9d0af\",\n#     \"source\": \"Direktiv\",\n#     \"specversion\": \"1.0\",\n#     \"type\": \"greetingcloudevent\"\n#   }\n# }\n- id: gen\ntype: generateEvent\nevent:\ntype: greetingcloudevent\nsource: Direktiv\ndata:\nname: \"World\"\n</code></pre>"},{"location":"examples/greeting/","title":"Greeting Example","text":"<p>Greeting Example on Github</p> <p>This simple example flow uses a single <code>action</code> state to call the <code>hello-world</code> action, which 'greets' the user specified in the <code>\"name\"</code> field of the input provided to the flow. The validate state ensures the input is valid.</p> Greeter Flow<pre><code># Example Input:\n# {\n#     \"name\": \"World\"\n# }\n#\n# Example Output:\n# The results of this action will contain a greeting addressed to the provided name.\n# {\n#     \"return\": {\n#         \"greeting\": \"Welcome to Direktiv, World!\"\n#     }\n# }\n\n\ndescription: |\nExecute a action state to call the direktiv/greeting action, which 'greets' \nthe user specified in the \"name\" field of the input provided to the flow.\n\nfunctions:\n- id: greeter\nimage: gcr.io/direktiv/functions/hello-world:1.0\ntype: knative-workflow\n\nstates:\n- id: validate-input\ntype: validate\nschema:\ntype: object\nrequired:\n- name\nproperties:\nname:\ntype: string\ndescription: Name to greet\ntitle: Name\ntransition: greeter\n\n#\n# Execute greeter action.\n#\n- id: greeter\ntype: action\nlog: jq(.)\naction: function: greeter\ninput: name: jq(.name)\ntransform: 'jq({ \"greeting\": .return.\"hello-world\" })'\n</code></pre> Input<pre><code>{\n\"name\": \"World\"\n}\n</code></pre> <p>The results of this action will contain a greeting addressed to the provided name.</p> Output<pre><code>{\n\"greeting\": \"Hello World\"\n}\n</code></pre>"},{"location":"examples/input-convert/","title":"Convert Input","text":"<p>Convert Input on Github</p> <p>This example show how to handle input which is not JSON. This example uses a XLSX file and converts it to JSON to be used in the workflow. </p> <p>If Direktiv gets non-JSON input, in this case a binary file, it encodes it as Base64 and starts the workflow with a an <code>input</code> variable containing the binary file. </p> Convert Flow<pre><code>functions:\n- id: csvkit\nimage: gcr.io/direktiv/functions/csvkit:1.0\ntype: knative-workflow\n\n# Fetch base64 input and store it workflow variable\nstates:\n- id: set\ntype: setter\nlog: jq(.)\nvariables:\n- key: in.xlsx\n# mark this a binary file\nmimeType: application/octet-stream\n# for non-JSON input the data ends up as base64 in .input\nvalue: 'jq(.input)'\nscope: workflow\ntransition: convert # Takes the workflow variable and converts it\n- id: convert\ntype: action\naction:\nfunction: csvkit\nfiles: - key: in.xlsx\nscope: workflow\ninput: commands:\n- command: bash -c 'in2csv in.xlsx &gt; out.csv'\n- command: csvjson out.csv\ntransform:\njson: jq(.return.csvkit[1].result[0])\n</code></pre> Push Data to Flow<pre><code>curl -XPOST --data-binary @data.xlsx http://MYSERVER/api/namespaces/examples/tree/input-convert/workflow?op=wait\n</code></pre>"},{"location":"examples/request-external-api/","title":"Request API","text":"<p>Request API on Github</p> <p>This example shows how we can write a flow to communicate with a external API service. In this flowflow we will use the Direktiv request image to make a HTTP GET request to https://fakerapi.it/ and fetch the details of a fake person. A transform is also used to clean up the returned value from the action, but it can be commented out to see the full return value.</p> API Request<pre><code># Example Output:\n# {\n#   \"person\": {\n#     \"address\": {\n#       \"buildingNumber\": \"8422\",\n#       \"city\": \"Ashleytown\",\n#       \"country\": \"Ethiopia\",\n#       \"county_code\": \"AD\",\n#       \"id\": 0,\n#       \"latitude\": -21.509297,\n#       \"longitude\": -48.162169,\n#       \"street\": \"47933 Kennedi View Apt. 395\",\n#       \"streetName\": \"Margie Stream\",\n#       \"zipcode\": \"44788\"\n#     },\n#     \"birthday\": \"1944-09-28\",\n#     \"email\": \"qmetz@gmail.com\",\n#     \"firstname\": \"Gabriella\",\n#     \"gender\": \"female\",\n#     \"id\": 1,\n#     \"image\": \"http://placeimg.com/640/480/people\",\n#     \"lastname\": \"Steuber\",\n#     \"phone\": \"+5542223225627\",\n#     \"website\": \"http://wiza.com\"\n#   }\n# }\n\ndescription: |\nExecute a HTTP request to generate a persons details from the fake data API fakerapi. \nfunctions:\n- id: http-request\nimage: gcr.io/direktiv/functions/http-request:1.0\ntype: knative-workflow\nstates:\n#\n# HTTP GET Fake person from fakerapi\n# Transform data to get data out of body\n#\n- id: get-fake-persons\ntransform: \"jq({person: .return[0].result.data[0]})\"\ntype: action\naction:\nfunction: http-request\ninput: method: \"GET\"\nurl: \"https://fakerapi.it/api/v1/persons?_quantity=1\"\n</code></pre> Output<pre><code>{\n\"person\": {\n\"address\": {\n\"buildingNumber\": \"8422\",\n\"city\": \"Ashleytown\",\n\"country\": \"Ethiopia\",\n\"county_code\": \"AD\",\n\"id\": 0,\n\"latitude\": -21.509297,\n\"longitude\": -48.162169,\n\"street\": \"47933 Kennedi View Apt. 395\",\n\"streetName\": \"Margie Stream\",\n\"zipcode\": \"44788\"\n},\n\"birthday\": \"1944-09-28\",\n\"email\": \"qmetz@gmail.com\",\n\"firstname\": \"Gabriella\",\n\"gender\": \"female\",\n\"id\": 1,\n\"image\": \"http://placeimg.com/640/480/people\",\n\"lastname\": \"Steuber\",\n\"phone\": \"+5542223225627\",\n\"website\": \"http://wiza.com\"\n}\n}\n</code></pre>"},{"location":"examples/scripting/","title":"Scripting","text":"<p>Scripting on Github</p> <p>To use scripts like Python, Javascript, Powershell etc. A script can be loaded from flow or namespace variables. These files can be provided to the actions and executed. If the namespace is synced via Git a naming convention adds variables to worklflows. If a file has a prefix of a flow it will be added as variable. This enables Direktiv to use it as script in a flow, e.g.:</p> <ul> <li>myflow.yaml</li> <li>myflow.yaml.script.sh</li> </ul> <p>In the above example there would be a <code>script.sh</code> flow variable. The following flow example uses Python but any file type can be used, even binaries.</p> Python Flow<pre><code>functions:\n- id: python\nimage: gcr.io/direktiv/functions/python:1.0\ntype: knative-workflow\nstates:\n- id: python\ntype: action\naction:\nfunction: python\n# use AWS key and secret\nsecrets: [\"AWS_ACCESS_KEY_ID\",\"AWS_SECRET_ACCESS_KEY\"]\nfiles:\n- key: python.py\nscope: workflow\ninput: commands:\n- command: pip install boto3\n- command: python3 python.py\nenvs: - name: AWS_ACCESS_KEY_ID\nvalue: jq(.secrets.AWS_ACCESS_KEY_ID)\n- name: AWS_SECRET_ACCESS_KEY\nvalue: jq(.secrets.AWS_SECRET_ACCESS_KEY)\n- command: cat out.json\ntransform:\nregions: jq(.return.python[1].result)\n</code></pre> python.py<pre><code>import boto3\nimport os\nimport json\n\nsession = boto3.session.Session()\n\nregions = {}\n\nclient = boto3.client('ec2',region_name='us-east-1')\nec2_regions = [region['RegionName'] for region in client.describe_regions()['Regions']]\nfor region in ec2_regions:\n    print(\"executing region \" + region)\n    vs = []\n    ec2_resource = session.resource('ec2', region_name=region)\n    for volume in ec2_resource.volumes.filter():\n        if volume.state == 'available':\n            vs.append(volume.id)\n\n    if len(vs) &gt; 0:\n        regions[region] = vs\n        print(\"added \" + str(len(vs)) +  \"volumes for region  \" + region)\n\n# writes json to a file\nwith open('out.json', 'w') as out_file:\n     json.dump(regions, out_file)\n\n# writes json to a workflow variable\nwith open('out/workflow/out.json', 'w') as out_file:\n     json.dump(regions, out_file)\n</code></pre>"},{"location":"examples/solving-math-expressions/","title":"Solving Math Expressions","text":"<p>Solving Math Expressions on Github</p> <p>This example shows how we can iterate over data using the ForEach state. Which executes an action that solves a math expression. The flow data input are the expressions you want to solve as a string array.</p> <p>The example demonstrates the use of an action isolate to solve a number of mathematical expressions using a <code>foreach</code> state. For each expression in the input array, the isolate will be run once. </p> Solver Flow<pre><code># Example Input:\n# {\n#  \"expressions\": [\n#    \"4+10\",\n#    \"15-14\",\n#    \"100*3\",\n#    \"200/2\"\n#  ]\n# }\n#\n# Example Output:\n# The results of this foreach loop will be a json array of strings that have the solved answers.\n# {\n#   \"solved\": [\n#     \"14\",\n#     \"1\",\n#     \"300\",\n#     \"100\"\n#   ]\n# }\n\n\ndescription: |\nExecutes an action that solves a math expression. \nThe workflow data input are the expressions you want to solve as a string array.\n\nfunctions:\n- id: solve-math-expression\nimage: gcr.io/direktiv/functions/bash:1.0\ntype: knative-workflow\n\nstates:\n- id: validate-input\ntype: validate\nschema:\ntype: object\nrequired:\n- expressions\nproperties:\nexpressions:\ntype: array\ndescription: expressions to solve\ntitle: Expressions\nitems:\ntype: string\ntransition: solve\n\n#\n# Execute solve action.\n#\n- id: solve\ntype: foreach\narray: 'jq([.expressions[] | { expression: . }])'\naction:\nfunction: solve-math-expression\ninput: commands: - command: bash -c \"echo $((jq(.expression)))\"\ntransform: 'jq({ solved: [.return[] | .bash[0].result ] })'\n</code></pre> Input<pre><code>{\n\"expressions\": [\n\"4+10\",\n\"15-14\",\n\"100*3\",\n\"200/2\"\n]\n}\n</code></pre> <p>The results of this foreach loop will be a json array of strings that have the solved answers.</p> Output<pre><code>{\n\"solved\": [\n\"14\",\n\"1\",\n\"300\",\n\"100\"\n]\n}\n</code></pre> <p>Note: The array for a foreach state must be passed as an array of objects. This is why to iterate over the <code>expressions</code> string array, we must pipe it and construct a new array of objects using <code>[.expressions[] | { expression: . }]</code>.</p>"},{"location":"examples/solving-math-expressions/#jq-expressions","title":"jq: <code>.expressions</code>","text":"<pre><code>[\n\"4+10\",\n\"15-14\",\n\"100*3\",\n\"200/2\"\n]\n</code></pre>"},{"location":"examples/solving-math-expressions/#jq-expressions-expression","title":"jq: <code>[.expressions[] | { expression: . }]</code>","text":"<pre><code>[\n{\n\"expression\": \"4+10\"\n},\n{\n\"expression\": \"15-14\"\n},\n{\n\"expression\": \"100*3\"\n},\n{\n\"expression\": \"200/2\"\n}\n]\n</code></pre>"},{"location":"examples/subflows/","title":"Subflows","text":"<p>Subflows on Github</p> <p>Direktiv can use containers as actions but can also call subflows in the same way.  It uses the same parameters and provides the same functionality.</p> Parent Flow<pre><code>functions:\n# Define subflow function\n- id: sub\nworkflow: subflow\ntype: subflow\n\n# Call subflow with input values\nstates:\n- id: call-sub type: action\naction:\nfunction: sub\ninput: key: value\n</code></pre> Subflow<pre><code>states:\n- id: print\ntype: noop\nlog: jq(.)\n</code></pre>"},{"location":"examples/variable-mime-type/","title":"Variable Mime Type Example","text":"<p>Variable Mime Type Example on Github</p> <p>All variables have an associated mime type to distinguish the content type of its value. This example will show two examples, and the special behaviour that happens when mimeType is <code>text/plain</code> or <code>application/octet-stream</code>. </p>"},{"location":"examples/variable-mime-type/#storing-a-string-as-a-raw-plaintext-variable","title":"Storing a string as a raw plaintext variable.","text":"<p>By default (mimeType=application/json) all variables are treated as JSON values. So this means even if you store a string in a variable, it's value is stored with quotes wrapped around it.</p> JSON String Data<pre><code>description: |\nStore the workflow variable 'StringVar' as a json encoded string.  \n\nstates:\n#\n# Set StringVar Value: \n# \"hello\\nworld\"\n#\n- id: set-var\ntype: setter\nvariables:\n- key: StringVar\nscope: workflow value: |\nhello\nworld\n</code></pre> JSON String Variable<pre><code>\"hello\\nworld\"\n</code></pre> <p>If the data is YAML it will be converted to JSON in the variable.</p> JSON Data<pre><code>description: |\nStore the workflow variable 'StringVar' as a json.  \n\nstates:\n#\n# Set StringVar Value: \n# \"hello\\nworld\"\n#\n- id: set-var\ntype: setter\nvariables:\n- key: StringVar\nscope: workflow value: - key: value\n</code></pre> JSON Variable<pre><code>[{\"key\":\"value\"}]\n</code></pre> <p>There are certain scenarios where you would not want to store the variable with its quotes. To do this all need to do is simply set the mimeType to <code>text/plain</code> or <code>text/plain; charset=utf-8</code>. This will store the variable as a raw string without quotes. </p> Plain Text<pre><code>description: |\nStore the workflow variable 'StringVar' as a plaintext string.  \n\nstates:\n#\n# Set StringVar Value: \n# hello\n# world\n#\n- id: set-var\ntype: setter\nvariables:\n- key: StringVar\nscope: workflow mimeType: 'text/plain'\nvalue: |\nhello\nworld\n</code></pre>"},{"location":"examples/variable-mime-type/#variable-stringvar-value","title":"Variable - StringVar Value","text":"Plain Text Variable<pre><code>hello\nworld\n</code></pre>"},{"location":"examples/variable-mime-type/#auto-decoding-base64-string","title":"Auto-Decoding Base64 string","text":"<p>Another special behaviour is that it's also possible to auto decode a base64 string by setting the <code>mimeType</code> to <code>application/octet-stream</code>. This is used for binaries like Excel files, images etc.</p> Base64 Variable<pre><code>description: |\nAuto decode base64 string and store the resulting value \nas the workflow variable 'MessageVar'.  \n\nstates:\n#\n# Set MessageVar Value: \n# hello from direktiv\n#\n- id: set-var\ntype: setter\nvariables:\n- key: MessageVar\nscope: workflow value: 'aGVsbG8gZnJvbSBkaXJla3Rpdg=='\nmimeType: 'application/octet-stream'\n</code></pre>"},{"location":"examples/variable-mime-type/#variable-messagevar-value","title":"Variable - MessageVar Value","text":"Binary Data<pre><code>hello from direktiv\n</code></pre> <p>These are the only two mime types with special behaviour. Any other <code>mimeType</code> will be treated internally by the default <code>JSON</code> behaviour. The default value for mimeType is <code>application/json</code></p>"},{"location":"examples/variables/","title":"Variable Scopes","text":"<p>Variable Scopes on Github</p> <p>Variable can be set on different scopes. Later in the flow they can be accessed within the same scope. The following scopes are available.</p> <ul> <li>instance: Only valid during the execution of the flow</li> <li>workflow: Stored as workflow variable and can be accessed from every intsance of the flow</li> <li>namespace: Namespace global scope and every workflow in the namespace can access it</li> </ul> <p>This example uses a setter state to set a variable in the <code>instance</code> scope. The second state set a workflow variable with the special output folder <code>out</code> in actions. Values can be stored in <code>out/&lt;SCOPE&gt;</code> and will be set after executing the action. The last state uses a <code>transform</code> to return the variables.</p> Set Variables<pre><code>functions:\n- id: bash\nimage: gcr.io/direktiv/functions/bash:1.0\ntype: knative-workflow\n\nstates:\n\n# Sets the variable in instance scope\n- id: set-value\ntype: setter\nvariables:\n- key: x\nscope: instance\nvalue: This is my value\ntransition: set-value-fn\n\n# Sets the variable in workflow scope with writing to the special \"out\" folder\n- id: set-value-fn\ntype: action\naction:\nfunction: bash\ninput: commands:\n- command: bash -c 'echo \\\"my fn value\\\" &gt; out/workflow/y'\ntransition: get-values\n\n# fetch values\n- id: get-values\ntype: getter\nvariables:\n- key: x\nscope: instance\n- key: y\nscope: workflow\ntransform:\nmy-x: jq(.var.x)\nmy-y: jq(.var.y)\n</code></pre>"},{"location":"getting_started/","title":"Getting Started","text":"<p>If you're beginning your journey with Direktiv, there are two easy ways to do so. You can opt for a full installation or take the simpler route and use a Docker container that is fully equipped with everything required to get started - including a nested Kubernetes instance - or by utilizing a Multipass virtual machine setup.</p>"},{"location":"getting_started/#docker-linux-only","title":"Docker (Linux only)","text":"<p>The Docker image works on Linux only and can be used foe easy development of flows on a local machine.</p> Running Docker Image<pre><code>docker run --privileged -p 8080:80 -ti direktiv/direktiv-kube\n</code></pre>"},{"location":"getting_started/#multipass-linux-mac-windows","title":"Multipass (Linux, Mac, Windows)","text":"<p>For Windows and Mac users in particular there is a Multipass cloud-init script to set up a Direktiv instance for testing and development.</p> Running Multipass<pre><code>multipass launch --cpus 4 --disk 20G --memory 6G --name direktiv --cloud-init https://raw.githubusercontent.com/direktiv/direktiv/main/build/docker/all/multipass/init.yaml\n</code></pre> <p>Warning</p> <p>multipass does not work in a VPN. The VPN needs to be turned off for this example installation.</p> <p>The development section has more details how to configure these instances and how to use them.</p>"},{"location":"getting_started/conditional-transitions/","title":"Conditional Transitions","text":"<p>Oftentimes a flow needs to be a little bit smarter than an immutable sequence of states. That's when conditional transitions are required. For these cases Direktiv provides a <code>switch</code> state which can route the flow based on conditions. Each condition can route the flow to a different state but there can be a <code>defaultTransition</code> to transition to if none of the conditions are true. </p> Loop Demo<pre><code>functions:\n- id: httprequest\nimage: gcr.io/direktiv/functions/http-request:1.0\ntype: knative-workflow\nstates:\n- id: ifelse\ntype: switch\ndefaultTransition: done\nconditions:\n- condition: jq(.names)\ntransition: poster\n- id: poster\ntype: action\naction:\nfunction: httprequest\ninput: method: POST\nurl: https://jsonplaceholder.typicode.com/posts\ncontent: name: jq(.names[0])\ntransform: jq(del(.names[0]))\ntransition: ifelse\n- id: done\ntype: noop\ntransform: done\n</code></pre> Input<pre><code>{\n\"names\": [\n\"Michael\",\n\"Thomas\",\n\"Kevin\"\n]\n}\n</code></pre> Output<pre><code>{\n\"done\": \"yes\"\n}\n</code></pre> <p>In this example the switch state will transition to <code>poster</code> until the list of names is empty, at which point the flow will transition to the default transition <code>done</code>.</p>"},{"location":"getting_started/conditional-transitions/#switch-state","title":"Switch State","text":"<p>The Switch State can make decisions about where to transition to next based on the instance data by evaluating a number of <code>jq</code> expressions and checking the results. Here's an example switch state definition:</p> <pre><code>- id: ifelse\ntype: switch\nconditions:\n- condition: 'jq(.person.age &gt; 18)'\ntransition: accept\n#transform:\n- condition: 'jq(.person.age != nil)'\ntransition: reject\n#transform:\ndefaultTransition: failure\n#defaultTransform:\n</code></pre> <p>Each of the <code>conditions</code> will be evaluated in the order it appears by running the <code>jq</code> command in <code>condition</code>. Any result other than <code>null</code>, <code>false</code>, <code>{}</code>, <code>[]</code>, <code>\"\"</code>, or <code>0</code> will cause the condition to be considered a successful match. If no conditions match the default transition will be used.</p>"},{"location":"getting_started/conditional-transitions/#other-conditional-transitions","title":"Other Conditional Transitions","text":"<p>The Switch State is not the only way to do conditional transitions. The eventsXor state also transitions conditionally based on which CloudEvent was received. All states can also define handlers for catching various types of errors.</p>"},{"location":"getting_started/conditional-transitions/#loops","title":"Loops","text":"<p>By transitioning to a state that has already happened it's possible to create loops in flow instances. In this example we have got a type of range loop, iterating over the contents of an array. Direktiv sets limits for the number of transitions an instance can make in order to protect itself from infinitely-looping flows. This is an example only and in this case a foreach is a better solution.</p>"},{"location":"getting_started/error-handling/","title":"Error Handling","text":"<p>One obvious use for loops is to retry some logic if an error occurs, but there's no need to design looping flow because Direktiv has configurable error catching &amp; retrying available on every action-based state. This will be discussed in a later article.</p> <p>Handling errors can be an important part of a flow.</p>"},{"location":"getting_started/error-handling/#demo","title":"Demo","text":"<pre><code>functions:\n- id: http-request\nimage: gcr.io/direktiv/functions/http-request:1.0\ntype: knative-workflow\nstates:\n- id: do-request\ntype: action\naction:\nfunction: http-request\ninput:\nurl: http://doesnotexist.xy\nretries:\nmax_attempts: 2\ndelay: PT5S\nmultiplier: 2.0\ncodes: [\".*\"]\n</code></pre> <p>In this example a request is being made to an URL. This URL does not exist to simulate the retry mechanism. It uses the multiplier to try within 5 seconds the first time and 10 seconds the second time.</p>"},{"location":"getting_started/error-handling/#catchable-errors","title":"Catchable Errors","text":"<p>Errors that occur during instance execution usually are considered \"catchable\". Any flow state may optionally define error catchers, and if a catchable error is raised Direktiv will check to see if any catchers can handle it.</p> <p>Errors have a \"code\", which is a string formatted in a style similar to a domain name. Error catchers can explicitly catch a single error code or they can use <code>*</code> wildcards in their error codes to catch ranges of errors. Setting the error catcher to just \"<code>*</code>\" means it will handle any error, so long as no catcher defined higher up in the list has already caught it.</p> <p>If no catcher is able to handle an error, the flow will fail immediately.</p> <pre><code>functions:\n- id: http-request\nimage: gcr.io/direktiv/functions/http-request:1.0\ntype: knative-workflow\nstates:\n- id: do-request\ntype: action\naction:\nfunction: http-request\ninput:\nurl: http://doesnotexist.xy\nretries:\nmax_attempts: 2\ndelay: PT5S\nmultiplier: 2.0\ncodes: [\".*\"]\ncatch:\n- error: \"direktiv.retries.exceeded\"\ntransition: handle-error\n- id: handle-error\ntype: noop\nlog: this did not work\n</code></pre> <p>In this case the flow catches the failed retries and transitions to <code>handle-error</code> and the flow finished successful. Every other error will mark the flow execution as failed.</p>"},{"location":"getting_started/error-handling/#uncatchable-errors","title":"Uncatchable Errors","text":"<p>Rarely, some errors are considered \"uncatchable\", but generally an uncatchable error becomes catchable if escalated to a calling flow. One example of this is the error triggered by Direktiv if a flow fails to complete within its maximum timeout.</p> <p>If a flow fails to complete within its maximum timeout it will not be given an opportunity to catch the error and continue running. But if that flow is running as a subflow its parentflow will be able to detect and handle that error.</p>"},{"location":"getting_started/error-handling/#retries","title":"Retries","text":"<p>Action definitions may optionally define a retry strategy. If a retry strategy is defined the catcher's transition won't be used and no error will be escalated for retryable errors until all retries have failed. A retry strategy might look like the following:</p> <pre><code>    retry:\nmax_attempts: 3\ndelay: PT30S\nmultiplier: 2.0\ncodes: [\".*\"]\n</code></pre> <p>In this example you can see that a maximum number of attempts is defined, alongside an initial delay between attempts and a multiplication factor to apply to the delay between subsequent attempts.</p>"},{"location":"getting_started/error-handling/#recovery","title":"Recovery","text":"<p>Flows sometimes perform actions which may need to be reverted or undone if the flow as a whole cannot complete successfully. Solving these problems requires careful use of error catchers and transitions.</p>"},{"location":"getting_started/error-handling/#cause-errors","title":"Cause Errors","text":"<p>Sometimes it is important to fail the flow with a custom error. This is possible with the <code>error</code> state. This can used e.g. in switch states.</p> <pre><code>states:\n- id: a\ntype: switch\ndefaultTransition: fail\nconditions:\n- condition: 'jq(.y == true)'\n\n- id: fail\ntype: error\nerror: badinput\nmessage: 'value y not set'\n</code></pre> <p>In this example if the payload does not contain <code>y: true</code> the flow fails. The error throwns <code>badinput</code> is thrown and the flow failed. The error <code>badinput</code> could be caught by a parent flow.</p>"},{"location":"getting_started/events/","title":"Events","text":"<p>Direktiv has built-in support for CloudEvents, which can be a great way to interact with flows. The following flow has a start condition based on events. It would only start if an event of type <code>com.github.pull.create</code> arrives with the source set to <code>https://github.com/cloudevents/spec/pull</code></p> Example Workflow<pre><code>start:\ntype: event\nevent:\ntype: com.github.pull.create\ncontext:\nsource: https://github.com/cloudevents/spec/pull\nfunctions:\n- id: httprequest\nimage: gcr.io/direktiv/functions/http-request:1.0\ntype: knative-workflow\nstates:\n- id: notify\ntype: action\naction:\nfunction: httprequest\ninput:\nmethod: \"POST\"\nurl: \"https://jsonplaceholder.typicode.com/todos/1\"\nbody: 'jq(.\"com.github.pull.create\")'\n</code></pre>"},{"location":"getting_started/events/#cloudevents","title":"CloudEvents","text":"<p>CloudEvents are specification for describing event data in a common way. They're JSON objects with a number of required fields, some optional fields, and a payload.</p> Sample Cloudevent<pre><code>{\n\"specversion\" : \"1.0\",\n\"type\" : \"com.github.pull.create\",\n\"source\" : \"https://github.com/cloudevents/spec/pull\",\n\"subject\" : \"123\",\n\"id\" : \"A234-1234-1234\",\n\"time\" : \"2018-04-05T17:31:00Z\",\n\"comexampleextension1\" : \"value\",\n\"comexampleothervalue\" : 5,\n\"datacontenttype\" : \"text/xml\",\n\"data\" : \"&lt;much wow=\\\"xml\\\"/&gt;\"\n}\n</code></pre> <p>CloudEvents can be sent via the API to a namespace or generated by flow within Direktiv, to be handled by any number of interested receivers on that namespace.</p>"},{"location":"getting_started/events/#start-types","title":"Start Types","text":"<p>The most common use for events in Direktiv is to have external services generate CloudEvents and send them to Direktiv to trigger your flows. But to make your flows trigger on an event you need to register the flow's interest in the event by adding the appropriate start type to your workflow definition:</p> <pre><code>start:\ntype: event\nevent:\ntype: com.github.pull.create\nfilters:\nsource: \"https://github.com/cloudevents/spec/pull\"\n</code></pre> <p>In this example a new instance will be created whenever a cloudevent is received that has the matching <code>type</code> and <code>source</code> values.</p> <p>Two other event-based start types exist in Direktiv: the <code>eventsXor</code>, and the <code>eventsAnd</code>.</p> <p>The <code>eventsXor</code> registers an interest in multiple events and will trigger a new instance as soon as any one of them is received. The <code>eventsAnd</code> also registers an interest in multiple events, but will only trigger once all have been received.</p>"},{"location":"getting_started/events/#event-payloads","title":"Event Payloads","text":"<p>Whenever an event is received its payload will be added to the instance data under a field with the same name as the event \"type\". This allows for a uniform approach to accepting events that supports single events, eventsXor, and eventsAnd. The payload itself consists of the full cloudevent including attributes, extension context attributes and data.</p>"},{"location":"getting_started/events/#instances-waiting-for-events","title":"Instances Waiting for Events","text":"<p>Triggering flows is not the only thing you can do with events. Flows can be constructed to run some logic and then wait for an event before proceeding. Like the event-based start types, there are three event consuming states: <code>consumeEvent</code>, <code>eventsXor</code>, and <code>eventsAnd</code>. </p> Waiting Within A Flow<pre><code>- id: wait-event\ntype: consumeEvent\nevent:\ntype: com.github.pull.create\ncontext:\nsource: \"https://github.com/cloudevents/spec/pull\"\nrepository: 'jq(.repo)'\ntimeout: PT5M\ntransform: 'jq(.\"com.github.pull.create\")'\ntransition: next-state\n</code></pre>"},{"location":"getting_started/events/#timeouts","title":"Timeouts","text":"<p>It's rarely a good idea to leave a flow waiting indefinitely. Direktiv allows you to define timeouts in ISO8601 format when waiting on an event. If the state is not ready to proceed before the timeout has elapsed an error will be thrown. It's possible to catch the error <code>direktiv.cancels.timeout.soft</code>.</p> <p>The <code>timeout</code> field is not required, but Direktiv caps the maximum timeout whether specified or not to prevent flows from living forever. The default timeout is 15 minutes.</p>"},{"location":"getting_started/events/#context","title":"Context","text":"<p>Event-consuming states have a <code>context</code> field. The context field can restrict which events are considered matches by requiring an exact match on a CloudEvent context field. This can be used to link certain events to e.g. customer ids or transaction ids.</p>"},{"location":"getting_started/events/#generateevent-state","title":"GenerateEvent State","text":"<p>Flows can generate events for their namespace. The fields for this state are fairly self-explanatory. Here's an example:</p> <pre><code>- id: gen-event\ntype: generateEvent\nevent:\ntype: \"my.custom.event\"\nsource: \"direktiv\"\ndata: 'jq(.)'\ndatacontenttype: \"application/json\"\n</code></pre> <p>If the <code>jq</code> command that populates the <code>data</code> field outputs a plain base64 encoded string and the <code>datacontenttype</code> field is set to anything other than <code>application/json</code> Direktiv will decode the string before sending the event.</p>"},{"location":"getting_started/functions-intro/","title":"Introduction to Functions","text":"<p>Flows wouldn't be very powerful if they were limited to just the predefined states. That's why Direktiv can run \"functions\" which are basically serverless containers or even a separate flow, referred to as a <code>subflow</code>. Direktiv uses the <code>action</code> state to provide this functionality.</p>"},{"location":"getting_started/functions-intro/#example","title":"Example","text":"<pre><code>functions:\n- id: http-request\nimage: gcr.io/direktiv/functions/http-request:1.0\ntype: knative-workflow\n\nstates:\n- id: getter\ntype: action\naction:\nfunction: http-request\ninput:\nurl: \"https://jsonplaceholder.typicode.com/todos/1\"\n</code></pre> <p>If the flow requires function to run they need to be defined in the <code>functions</code> section. There are different types of functions and the type is specified in the <code>type</code> attribute. The value can be one of the following:</p>"},{"location":"getting_started/functions-intro/#function-types","title":"Function Types","text":""},{"location":"getting_started/functions-intro/#knative-workflow","title":"knative-workflow","text":"<p>This function is for the flow only and will not be re-used across different flows. This type requires an image name to use. The image name should point to a valid container image in a remote registry like Docker Hub, GCR, Azure etc. Two additional attributes can be provided:</p> <p>size: Sometimes functions need a different size in terms of CPU and memory. Possible values are <code>small</code>, <code>medium</code> and <code>large</code>. The definition of those values can be configured in Direktiv's configuration files via Helm chart. </p> <p>cmd: The function can use a different command in the container if it is supported by the function container. </p>"},{"location":"getting_started/functions-intro/#knative-namespace","title":"knative-namespace","text":"<p>If a function is used frequently by different flows it can be shared across flows with this type. They can be created under <code>Services</code> in the user interface or via API. </p> <pre><code>- id: http-request\nservice: request\ntype: knative-namespace\n</code></pre> <p>For these types a <code>scale</code> attribute can be defined on creation of the service which sets the minimum instances to run in the cluster and therefore reducing or eliminating the warm-up time and the function can run immediately. </p>"},{"location":"getting_started/functions-intro/#subflow","title":"subflow","text":"<p>In Direktiv a function can be a subflows as well. The behaviour is the same as calling serverless container functions. If used the flow provides the input for the subflow and accepts the response of the subflow as result. </p> <pre><code>- id: http-request\nworkflow: my-subflow\ntype: subflow\n</code></pre>"},{"location":"getting_started/functions-intro/#input-value","title":"Input Value","text":"<p>The input value for the function is set in <code>input</code> in. This YAML object under <code>input</code> will be send as JSON to the function container and can a multi-level nested object as well. Different containers require different inputs depending on their functionality. This concept is important for custom functions. </p> <pre><code>- id: getter\ntype: action\naction:\nfunction: http-request\ninput:\nurl: \"https://jsonplaceholder.typicode.com/todos/1\"\n</code></pre>"},{"location":"getting_started/functions-intro/#return-value","title":"Return Value","text":"<p>Every time a function is called the response is stored in <code>return</code> in the state data and can be processed via e.g. <code>transform</code> or <code>switch</code>. The next function call overwrites the <code>return</code> value so if data is required from a function accross multiple states it needs to be stored with a transition. </p> <p>In the example above the state data after executing the flow would have an additional JSON object with information about the headers and the content of the HTTP request in the <code>return</code> attribute.</p> <pre><code>{\n\"return\": [\n{\n\"code\": 200,\n\"headers\": {\n\"Access-Control-Allow-Credentials\": [\n\"true\"\n],\n\"Age\": [\n\"20706\"\n]\n},\n\"result\": {\n\"completed\": false,\n\"id\": 1,\n\"title\": \"delectus aut autem\",\n\"userId\": 1\n},\n\"status\": \"200 OK\",\n\"success\": true\n}\n]\n}\n</code></pre>"},{"location":"getting_started/functions-intro/#store-value","title":"Store Value","text":"<p>As mentioned earlier, every return of a function is getting overwritten with the next function call. Therefore it is important to store the data in the state if it is needed later in the flow. This can be done with a simple transform at the end of the action state. In the example here we store only the response status.</p> <pre><code>functions:\n- id: http-request\nimage: gcr.io/direktiv/functions/http-request:1.0\ntype: knative-workflow\n\nstates:\n- id: getter\ntype: action\naction:\nfunction: http-request\ninput:\nurl: \"https://jsonplaceholder.typicode.com/todos/1\"\ntransform:\nstatus: jq(.return[0].status)\n</code></pre> <p>The http request function returns an array so the JQ command would be <code>.return[0]</code> to get the 0th item from it and the <code>.status</code> fetches the status of that item. More function can be found at apps.direktiv.io.</p>"},{"location":"getting_started/functions-intro/#foreach","title":"Foreach","text":"<p>Another way to call functions is the <code>foreach</code> function. This is useful if an array of objects need to be processed the same way, e.g. executing multiple http requests. </p> <pre><code>functions:\n- id: http-request\nimage: gcr.io/direktiv/functions/http-request:1.0\ntype: knative-workflow\n\nstates:\n- id: getter\ntype: foreach\narray: |-\njq(\n[ \n{ \"url\": \"https://jsonplaceholder.typicode.com/todos/1\"}, \n{ \"url\": \"https://www.direktiv.io\"}]\n)\naction:\nfunction: http-request\ninput:\nurl: jq(.url)\n</code></pre> <p>This <code>foreach</code> call the same function but uses an array of objects. There are a few simple requirements for <code>foreach</code> states.</p> <ul> <li>The array has to be a list of objects not e.g. an array of strings.</li> <li>The <code>input</code> attribute has only access to the object it is iterating over at that time. It does not have access to state data at all. </li> </ul>"},{"location":"getting_started/functions-intro/#parallel","title":"Parallel","text":"<p>The parallel execution can be used if the flow needs to execute functions in parallel with the same state data. An example would be quality gates during a release process where functional tests and load test can potentially be run in parallel. </p> <pre><code>functions:\n- id: http-request\nimage: gcr.io/direktiv/functions/http-request:1.0\ntype: knative-workflow\n- id: python\nimage: gcr.io/direktiv/functions/python:1.0\ntype: knative-workflow\n\nstates:\n- id: execute-both\ntype: parallel\nmode: and\nactions:\n- function: http-request\ninput: url: https://www.direktiv.io\n- function: python\ninput:\ncommands:\n- command: python3 -c 'import os;print(os.environ[\"hello\"])'\nenvs: - name: hello\nvalue: world\n</code></pre> <p>Additionally a <code>mode</code> attribute can be set to either <code>or</code> or <code>and</code> to define if all actions need to return successfully or only one. </p>"},{"location":"getting_started/namespaces/","title":"Namespaces","text":"<p>Direktiv namespaces allow you the flexibility to divide projects, teams or use-cases. These spaces are totally seperate and independent of each other in terms of e.g. flows, secrets and services. You can easily create a namespace using the user interface or through an API call.</p> <p>Namespaces come in two different types. The <code>standard</code> version only stores data in Direktiv, while the <code>mirror</code> namespaces use Git as their source of truth for configuration and flows. It is recommended to use Git-backed namespaces for projects but for this guide a <code>standard</code> namespace will suffice.</p>"},{"location":"getting_started/namespaces/#create-standard-namespace","title":"Create Standard Namespace","text":"<pre><code>curl -X PUT \"http://localhost:8080/api/namespaces/demo\"\n</code></pre> <p>Response <pre><code>{\n\"namespace\":  {\n\"createdAt\":  \"2023-02-23T08:47:05.490124153Z\",\n\"updatedAt\":  \"2023-02-23T08:47:05.490124801Z\",\n\"name\":  \"demo\",\n\"oid\":  \"\"\n}\n}\n</code></pre></p> <p>Server Name</p> <p>Please adjust the server name to your environment if you are not using the all-in-one image for this \"Getting Started\" guide.</p>"},{"location":"getting_started/namespaces/#create-mirror-git-namespace","title":"Create Mirror (Git) Namespace","text":"<p>To create a Git namespace Direktiv requires at least the two attributes <code>url</code> and <code>ref</code>. The <code>ref</code> value is the tag, branch or commit to use as the base whereas the <code>url</code> points to the Git repository to use. If there are only those two attributes provided the access to the repository needs to be <code>public</code>.  </p> <p>Public Git <pre><code>curl -X PUT http://localhost:8080/api/namespaces/demo \\\n--data-binary @- &lt;&lt; EOF\n{ \n    \"url\": \"https://github.com/direktiv/direktiv-examples.git\", \n    \"ref\": \"main\" \n}\nEOF\n</code></pre></p> <p>If it is a <code>private</code> repository Direktiv requires either <code>passphrase</code>, which can be Github or Gitlab token or a <code>publicKey</code>/<code>privateKey</code> combination where the public key is registered with the Git instance. </p> <p>Private Git with Token <pre><code>curl -X PUT http://localhost:8080/api/namespaces/demo \\\n--data-binary @- &lt;&lt; EOF\n{ \n    \"url\": \"https://github.com/direktiv/direktiv-examples.git\", \n    \"ref\": \"main\",\n    \"passphrase\": \"abhsh2763gshs\"\n}\nEOF\n</code></pre></p> <p>GitLab Passphrases</p> <p>GitLab requires a username for the token. The username needs to be prepended like <code>username:glpat-152zshj2756</code></p>"},{"location":"getting_started/namespaces/#delete-namespace","title":"Delete Namespace","text":"<p>Delting a namepsace with the API is very simple. The command requires the <code>recursive</code> attribute if there is already content in the namespace.</p> <pre><code>curl -X DELETE http://localhost:8080/api/namespaces/demo?recursive=true\n</code></pre>"},{"location":"getting_started/persistent-data/","title":"Persistent Data","text":"<p>Direktiv supports storing and retrieving data that is persisted beyond the scope of a single state or flow instance. This article shows how to store and retrieve these variables. </p>"},{"location":"getting_started/persistent-data/#demo","title":"Demo","text":"<pre><code>states:\n- id: a\ntype: getter\nvariables:\n- key: x\nscope: workflow\ntransform: 'jq(.var.x += 1)'\ntransition: b\n- id: b\ntype: setter\nvariables:\n- key: x\nscope: workflow\nvalue: 'jq(.var.x)'\n</code></pre> <p>This demo increments a counter each time the flow is executed. It gets the variable <code>x</code> from <code>workflow</code> scope and increments it vi <code>jq</code>. The secons state stores the data in the same variable on the same scope.</p>"},{"location":"getting_started/persistent-data/#scopes","title":"Scopes","text":"<p>There are three scopes for storing persistent data: <code>instance</code>, <code>workflow</code>, and <code>namespace</code>.</p> <p>Data stored in the <code>instance</code> scope only exists for the duration of the running flow instance.</p> <p>Data stored in the <code>workflow</code> scope exists until the flow definition is deleted, and is accessible to all instances of that flow.</p> <p>Data stored in the <code>namespace</code> scope exists until the namespace itself is deleted, and is accessible to all instances of all flows originating on that namespace.</p>"},{"location":"getting_started/persistent-data/#setter-state","title":"Setter State","text":"<p>The Setter State can be used to store any number of variables. Each variable must be explicitly scoped, and the value stored for a variable is generated by the output of a <code>jq</code> query.</p> <pre><code>states:\n- id: a\ntype: setter\nvariables:\n- key: MyVar\nscope: namespace\nvalue: 'Hello'\n</code></pre> <p>The only way to delete a stored value is to set it to <code>null</code>.</p> <pre><code>states:\n- id: a\ntype: setter\nvariables:\n- key: MyVar\nscope: namespace\nvalue: </code></pre>"},{"location":"getting_started/persistent-data/#getter-state","title":"Getter State","text":"<p>The Getter State is used to retrieve any number of variables in persistent storage. Each variable must be explicitly scoped, and the value retrieved will be stored under <code>.var.KEY</code> where <code>KEY</code> is the variable's name.</p> <pre><code>- id: a\ntype: getter\nvariables:\n- key: x\nscope: namespace\n</code></pre> <p>A key doesn't need to exist in storage to return successfully, but the value returned will be <code>null</code> if it doesn't exist.</p>"},{"location":"getting_started/persistent-data/#concurrency","title":"Concurrency","text":"<p>Direktiv makes no effort to guarantee any thread-safety on persistent data. Multiple instances that interact with the same variable may have inconsistent results.</p>"},{"location":"getting_started/persistent-data/#getting-setting-from-functions","title":"Getting &amp; Setting from Functions","text":""},{"location":"getting_started/persistent-data/#getting","title":"Getting","text":"<p>Accessing persistent data from within a function is a fairly straightforward process. The request that the custom function receives from Direktiv contains a header 'Direktiv-TempDir', which contains all of the variables specified in the function definition. The <code>as</code>, <code>key</code>, <code>scope</code>, and <code>type</code> fields can all play a role in the placement and naming of files within this directory:</p> <ul> <li><code>key</code></li> <li>The key used to select a variable from within the flow definition. If no <code>as</code> field is provided, the file on a custom function will correspond to the value of <code>key</code>.</li> <li><code>scope</code></li> <li>Which scope to get the variable from: <code>instance</code>, <code>workflow</code>, or <code>namespace</code>. Defaults to <code>instance</code> if omitted.</li> <li><code>as</code></li> <li>An optional field used to set the name of the file as it appears on the isolate.</li> <li><code>type</code></li> <li><code>plain</code><ul> <li>The variable data inside of the file will be written 'as-is'.</li> </ul> </li> <li><code>base64</code><ul> <li>If the variable is stored as base64-encoded data, it will be decoded before being written to the file system.</li> </ul> </li> <li><code>tar</code><ul> <li>If the variable is a valid tar archive, a directory will be created instead of a file, with the contents of the tar archive populating it.</li> </ul> </li> <li><code>tar.gz</code><ul> <li>Similar to <code>tar</code>, this will result in a populated directory being created from a valid <code>.tar.gz</code> file.</li> </ul> </li> </ul> <p>For example, given the following state definition, a directory named 'myFiles' should exist within the directory specified by the <code>Direktiv-TempDir</code> header. Assuming that this header has a value of <code>/mnt/shared/example</code>, the following structure would be expected:</p> <pre><code>  - id: get\nimage: localhost:5000/iv-getter:v1\nfiles:\n- key: \"myFiles\"\nscope: instance\ntype: tar\n</code></pre> <pre><code>/mnt/shared/example/\n\u2514\u2500\u2500 myFiles\n    \u2514\u2500\u2500 file-1\n    \u2514\u2500\u2500 file-2\n    \u2514\u2500\u2500 file-3\n</code></pre>"},{"location":"getting_started/persistent-data/#setting","title":"Setting","text":"<p>From within a function running on Direktiv, variables can be set by sending a <code>POST</code> request:</p> <pre><code>POST http://localhost:8889/var?aid=&lt;EXAMPLE&gt;&amp;scope=instance&amp;key=myFiles\n\nBody: &lt;VARIABLE DATA&gt;\n</code></pre> <ul> <li>query parameters</li> <li>aid<ul> <li>The action ID, found from the <code>Direktiv-ActionID</code> header of the request being served by the isolate.</li> </ul> </li> <li>scope<ul> <li>The scope for which the variable is set (<code>namespace</code>, <code>workflow</code>, or <code>instance</code>)</li> </ul> </li> <li>key<ul> <li>The key used by subsequent actions to access the variable.</li> </ul> </li> </ul> <p>An alternative approach is to write files into certain directories. The direktiv sidecar will store those files as variables. There are three different folders for the three different scopes. For the above example they would be:</p> <pre><code>/mnt/shared/example/out/instance\n/mnt/shared/example/out/workflow\n/mnt/shared/example/out/namespace\n</code></pre> <p>Files under these folders will be stored with their names under the scope of the folder. Diretories will be stored as tar.gz files.</p>"},{"location":"getting_started/scheduling/","title":"Scheduling","text":"<p>Sometimes a flow needs to run periodically. Direktiv supports scheduling based on \"cron\". The <code>cron</code> is one of the start definitions.</p>"},{"location":"getting_started/scheduling/#demo","title":"Demo","text":"<pre><code>start:\ntype: scheduled\ncron: \"* 0/2 * * *\"\nfunctions:\n- id: httprequest\nimage: gcr.io/direktiv/functions/http-request:1.0\ntype: reusable\nstates:\n- id: getter\ntype: action\naction:\nfunction: httprequest\ninput: method: \"GET\"\nurl: \"https://jsonplaceholder.typicode.com/todos/1\"\n</code></pre>"},{"location":"getting_started/scheduling/#start-types","title":"Start Types","text":"<p>Flow definitions can have one of many different start types. If the <code>start</code> section left out entirely, causes it to <code>default</code>, which is appropriate for a direct-invoke/subflow flow. </p> <p><pre><code>start:\ntype: scheduled\ncron: \"0 */2 * * *\"\n</code></pre> Direktiv supports valid cron expressions and prevents scheduled flows from being directly invoked or used as a subflow, which is why this example does not specify any input data. Scheduled flows can not accept any payloads. </p>"},{"location":"getting_started/scheduling/#activeinactive-flows","title":"Active/Inactive Flows","text":"<p>Every flow definition can be considered \"active\" or \"inactive\". Being \"active\" doesn't mean that there's an instance running right now, it means that Direktiv will allow instances to be created from it. This setting is part of the API, not a part of the flow definition.</p> <p>With scheduled flows this is a useful setting. It can toggle the schedule on and off without modifying the flow definition itself.</p>"},{"location":"getting_started/scheduling/#cron","title":"Cron","text":"<p>Cron is a time-based job scheduler in Unix-like operating systems. Direktiv doesn't run cron, but it does borrow their syntax and expressions for scheduling. In the example above the cron expression is \"<code>0 */2 * * *</code>\". This tells Direktiv to run the flow once every two hours. There are many great resources online to help creating custom cron expressions.</p>"},{"location":"getting_started/secrets-registries/","title":"Secrets &amp; Registries","text":"<p>Many flows require sensitive information such as passwords or authentication tokens to access third-party APIs. This article shows the best way to handle sensitive data such as this so that they don not need to be stored as plaintext in flow definitions. Additionally this article shows how to pull containers from a private repository.</p> <p>Stored secrets can be requested in a function via the <code>secrets</code> attribute and is available as <code>.secrets.SECRETNAME</code></p> Secrets<pre><code>functions:\n- id: httprequest\nimage: direktiv/request:v1\ntype: reusable\nstates:\n- id: getter\ntype: action\naction:\nsecrets: [\"secretToken\"]\nfunction: httprequest\ninput:\nmethod: \"GET\"\nurl: \"https://jsonplaceholder.typicode.com/todos/1\"\nheaders:\n\"Content-type\": \"application/json; charset=UTF-8\"\n\"Authorization\": \"bearer jq(.secrets.secretToken)\"\n</code></pre>"},{"location":"getting_started/secrets-registries/#registries","title":"Registries","text":"<p>Direktiv can store authentication information for a container repositories on a namespace-by-namespace basis. Creating secrets can be done via the Direktiv API or web interface in the settings page.</p> <p>With the relevant registry defined, functions referencing containers on that registry become accessible. For example, if a registry was created via the api with the following curl command:</p> <pre><code>curl -X 'POST' \\\n'URL/api/functions/registries/namespaces/NAMESPACE' \\\n-H 'accept: application/json' \\\n-H 'Content-Type: application/json' \\\n-d '{\n  \"data\": \"admin:8QwFLg%D$qg*\",\n  \"reg\": \"https://index.docker.io\"\n}'\n</code></pre> <p>This registry would be used automatically by Direktiv when running the flow in the demo.</p>"},{"location":"getting_started/secrets-registries/#example-google-artifact-registry","title":"Example Google Artifact Registry","text":"<p>To use the Google Artifact Registry a service account with a key is required. How to create a service account and generate a key is documented here.</p> <p>The keed needs to be in base64 format. On linux it can be converted with the following command:</p> <pre><code>base64 -w 0 mykey-da8c8b573601.json &gt; base64google.json\n</code></pre> <p>Please make sure that there are no line wraps in the base64 file. For base64 encoded files the username is <code>_json_key_base64</code>. Example details for this registry would be something like the following:</p> Key Value URL https://us-central1-docker.pkg.dev Username _json_key_base64 Password ewogICJ0eXBlIjo...WlJkMWhqK1RRRF <p>Note</p> <p>If a registry is created after a service, the service will need to be recreated to use the latest registry.</p>"},{"location":"getting_started/secrets-registries/#secrets","title":"Secrets","text":"<p>Similar to how registry tokens are stored, arbitrary secrets can also be stored. That includes passwords, API tokens, certificates, or anything else. Secrets are stored on a namespace-by-namespace basis as key-value pairs. Secreats can be defined with the Direktiv API or web interface.</p> <p>Wherever actions appear in flow definitions there's always an optional <code>secrets</code> field. For every secret named in this field, Direktiv will find and decrypt the relevant secret from your namespace and add it to the data from which the action input is generated just before running the <code>jq</code> command that generates that logic. This means your <code>jq</code> commands can reference your secret and place it wherever it needs to be.</p> <p>Direktiv discards the secret-enriched data after generating the action input, so the secrets won't naturally appear in your instance output or logs. But once Direktiv passes that data to your action it has no control over how it's used. It's up to you to ensure your action doesn't log sensitive information and doesn't send sensitive information where it shouldn't go.</p> <p>IMPORTANT: Be especially wary of subflows. Try to avoid passing secrets to subflows if you can, subflows can reference secrets the same way as their parents after all. Remember, your secret-enriched data will become the input for a subflow, which means it will be logged. It's also stored in that subflow's instance data and could be passed around automatically if you're not careful. If your subflow doesn't strip secrets out before it terminates those secrets could also end up in the caller's <code>return</code> object.</p>"},{"location":"getting_started/secrets-registries/#security","title":"Security","text":"<p>Registry tokens and secrets are stored individually encrypted within Direktiv's database. Each namespace gets its own unique encryption keys, and the decryption key is stored in a different database. For the online Direktiv, these two databases are on different machines and are firewalled apart from one another, and all internal traffic is encrypted.</p> <p>These measures minimize the risk of damaging data breaches, but we still recommend using tokens rather than passwords wherever possible.</p>"},{"location":"getting_started/states/","title":"Flows & States","text":"<p>Direktiv Flows are YAML-based definitions of states connected in a directed acyclic graph (DAG). During runtime, the flow controls how execution progresses and which states are being called. It provides different state types to allow e.g. decision making, execute functions, event triggering and subflow calls. </p> <p>During execution data will be stored as JSON which can be accessed or modified in any given state.  Direktiv takes any kind of input to start the process off and returns a result as JSON output once finished.</p> <p>Direktiv Flow </p>"},{"location":"getting_started/states/#workflow-definition","title":"Workflow definition","text":"<p>All states for a flow are listed under <code>states</code>. Every flow must have at least one state. The first state under <code>states</code> will be executed first and all subsequent states need to be connected  via transitions. If a state has no <code>transition</code> attribute the flow ends at that point of the execution. </p>"},{"location":"getting_started/states/#simple-state","title":"Simple State","text":"<pre><code>states:\n- id: hello\ntype: noop\nlog: this is the log\ntransform: hello: world\n</code></pre> <p>The above flow contains a single <code>noop</code> (\"no operation\") and shows the common attributes in all available states within Dirketiv. When the flow is getting executed Direktiv creates an <code>instance</code> of that flow definition and tracks the progress and state data of that instance. The output of that flow would be the following:</p> <pre><code>{\n\"hello\": \"world\"\n}\n</code></pre>"},{"location":"getting_started/states/#state-id","title":"State ID","text":"<pre><code>- id: hello\n</code></pre> <p>Every state has to have its own identifier. The state identifier is used in logging and to define transitions, which will come up in a later example when we define more than one state. A state identifier must be unique within the flow definition. </p>"},{"location":"getting_started/states/#state-type","title":"State Type","text":"<pre><code>  type: noop\n</code></pre> <p>There are many state types that do all sorts of different things. It is required to provide the state type. </p>"},{"location":"getting_started/states/#log","title":"Log","text":"<pre><code>  log: this is the log\n</code></pre> <p>Every state has the <code>log</code> attribute and the content of the log attribute will be stored in the logs of the instance. </p>"},{"location":"getting_started/states/#transform-command","title":"Transform Command","text":"<pre><code>  transform: hello: world\n</code></pre> <p>Any state may optionally define a \"transform\" to modify the state data. The transform can add and delete data in the state or even wipe all data in the state. </p>"},{"location":"getting_started/states/#simple-transition","title":"Simple Transition","text":"<p>A <code>transition</code> attribute in a state instructs Direktiv to move to the next state. Transitions can also be conditional or during error handling but the following is a simple sequential transition.</p> <pre><code>states:\n\n- id: hello\ntype: noop\nlog: this is the log\ntransform: hello: world\ntransition: next-step\n- id: next-step\ntype: noop\nlog: last-step\n- id: last-step\ntype: noop\nlog: second stage\n</code></pre>"},{"location":"getting_started/subflows/","title":"Subflows","text":"<p>Just like scripting or programming, with Direktiv it's possible to organize your logic into reusable modules. Anytime a flow is invoked by another we it is called subflow. A subflow can be called like actions and it uses the same parameters as functions.</p> Subflow 'checker'<pre><code>functions:\n- id: httprequest\nimage: gcr.io/direktiv/functions/http-request:1.0\ntype: knative-workflow\nstates:\n\n# validates input and protects flow from wrong input data\n- id: validate-input\ntype: validate\nschema:\ntype: object\nrequired:\n- contact\n- payload\nadditionalProperties: false\nproperties:\ncontact:\ntype: string\npayload:\ntype: string\ntransition: notify\n\n# run http request\n- id: notify\ntype: action\naction:\nfunction: httprequest\ninput:\nmethod: \"GET\"\nurl: \"https://jsonplaceholder.typicode.com/todos/1\"\ncontent: input: jq(.)\ntransition: check-results\n\n# check if http code is 200\n- id: check-results\ntype: switch\nconditions:\n- condition: 'jq(.return[0].code != 200)'\ntransition: throw\ndefaultTransform:\nresult: jq(.return[0].code)\n\n# throw an error if not 200 response code\n- id: throw\ntype: error\nerror: notification.lint\nmessage: \"not 200 response\"\n</code></pre> Parent Flow<pre><code>functions:\n- id: checker-sub\ntype: subflow\n# relative reference to subflow\nworkflow: checker\nstates:\n- id: notify\ntype: action\naction:\nfunction: checker-sub\ninput:\ncontact: hello\npayload: data\n</code></pre> Output<pre><code>{\n\"return\": {\n\"result\": 200\n}\n}\n</code></pre>"},{"location":"getting_started/transforms/","title":"Transforms &amp; JQ/JS","text":"<p>Every flow instance always has something called the \"Instance Data\", which is a JSON object that is used to pass data around. Almost everywhere a <code>transition</code> can happen in a flow definition a <code>transform</code> can also happen allowing the author to filter, enrich, or otherwise modify the instance data. Transforms can be static, as seen in previous parts of this guide, or use JQ or Javascript to dynamically change it. </p>"},{"location":"getting_started/transforms/#jq-introduction","title":"JQ introduction","text":"<p>Direktiv uses JQ, JSON query language, to dynamically change data within the system. It is used in transformations, transitions, logs or function calls. </p> <p>JQ Hints</p> <p>Setting Defaults: JQ throws an error if the value you are accessing is empty. It is easy to set a default value with JQ like the following example:  <pre><code>- id: hello\n  type: noop\n  transform:\n    hello: jq(.myvalue // \"world\")\n</code></pre></p> <p>Multi-Line: Sometimes JQ can be hard to read if it is too long. YAML provides an easy way to use multi-line input. </p> <pre><code>- id: hello\n  type: noop\n  transform:\n    hello: |-\n      jq(\nif .mydata // \"myvalue\" == \"hello\"\nthen \"it is hello\" elif . == \"world\" then \"it is world\" else \"none of the above\" end\n      )\n</code></pre> <p>The <code>transform</code> field can contain a valid <code>jq</code> command, which will be applied to the existing instance data to generate a new JSON object that will entirely replace it. Note that only a JSON object will be considered a valid output from this <code>jq</code> command: <code>jq</code> is capable of outputting primitives and arrays, but these are not acceptable output for a <code>transform</code>. </p> <p>Transforms can be wrapped in <code>'jq()'</code> or <code>jq()</code>. The difference between the two is that one instructs YAML more explicitly what's in the string. This can be important if you use <code>jq</code> commands containing braces, for example: <code>jq({a: 1})</code>. Because if this is not explicitly quoted, YAML interprets it incorrectly and throws errors. The quoted form is always valid and generally safer.</p> <p>Hint</p> <p>The UI provides a JQ playground to write andf test JQ queries. </p>"},{"location":"getting_started/transforms/#js-introduction","title":"JS introduction","text":"<p>An alternative to JQ is Javascript. Direktiv provides a <code>data</code> Javascript object which can be modified to change state data. It assumes the script runs in a function and the Javascript section needs to return data even if it is an empty string. A <code>null</code> value is not allowed. </p> <pre><code>- id: hello\ntype: noop\ntransform:\nepoch: js(return Date.now())\n</code></pre> <p>Javascript snippets have access to the state data as well. The state data in that object is accessible through regular Javascript commands.</p> <pre><code>- id: hello\ntype: noop\ntransform: |- js(\ndata[\"hello\"] = \"world\"\nreturn data\n)\n</code></pre>"},{"location":"getting_started/transforms/#first-transform","title":"First Transform","text":"<p>Although a <code>transform</code> can use <code>jq</code> or <code>js</code> to modify data plain YAML can be used to do the transform. The following example does such a static transform. This can be used to e.g. set-up defaults or a basic object to work with in that flow. </p> <pre><code>states:\n- id: transform1\ntype: noop\ntransform:\nnumber: 5\nobjects:\n- key1: value1\n- key2: value2\n</code></pre> <p>Resulting Instance Data</p> <pre><code>{\n\"number\": 5,\n\"objects\": [\n{\n\"key1\": \"value1\"\n},\n{\n\"key2\": \"value2\"\n}\n]\n}\n</code></pre>"},{"location":"getting_started/transforms/#second-transform","title":"Second Transform","text":"<p>The second transform enriches the existing instance data by adding a new field to it.</p> <p>Command</p> <pre><code>states:\n- id: transform1\ntype: noop\ntransform:\nnumber: 5\nobjects:\n- key1: value1\n- key2: value2\ntransition: transform2\n- id: transform2\ntype: noop\ntransform: 'jq(.multiplier = 10)' </code></pre> <p>Resulting Instance Data</p> <pre><code>{\n\"multiplier\": 10,\n\"number\": 5,\n\"objects\": [\n{\n\"key1\": \"value1\"\n},\n{\n\"key2\": \"value2\"\n}\n]\n}\n</code></pre>"},{"location":"getting_started/transforms/#third-transform","title":"Third Transform","text":"<p>The third transform multiplies two fields to produce a new field, then pipes the results into another command that deletes two fields.</p> <p>Command</p> <pre><code>states:\n- id: transform1\ntype: noop\ntransform:\nnumber: 5\nobjects:\n- key1: value1\n- key2: value2\ntransition: transform2\n- id: transform2\ntype: noop\ntransform: 'jq(.multiplier = 10)' transition: transform3\n- id: transform3\ntype: noop\ntransform: 'jq(.result = .multiplier * .number | del(.multiplier, .number))'\n</code></pre> <p>Resulting Instance Data</p> <pre><code>{\n\"objects\": [\n{\n\"key1\": \"value1\"\n},\n{\n\"key2\": \"value2\"\n}\n],\n\"result\": 50\n}\n</code></pre>"},{"location":"getting_started/transforms/#fourth-transform","title":"Fourth Transform","text":"<p>The fourth transform selects a child object nested within the instance data and makes that into the new instance data.</p> <p>Command</p> <pre><code>states:\n- id: transform1\ntype: noop\ntransform:\nnumber: 5\nobjects:\n- key1: value1\n- key2: value2\ntransition: transform2\n- id: transform2\ntype: noop\ntransform: 'jq(.multiplier = 10)' transition: transform3\n- id: transform3\ntype: noop\ntransform: 'jq(.result = .multiplier * .number | del(.multiplier, .number))'\ntransition: transform4\n- id: transform4\ntype: noop\ntransform: 'jq(.objects[0])'\n</code></pre> <p>Resulting Instance Data</p> <pre><code>{\n\"key1\": \"value1\"\n}\n</code></pre>"},{"location":"getting_started/transitions/","title":"Input & Transitions","text":"<p>Input data and transitions, in particular conditional transitions, are an important part in Direktiv. As previously shown a state can define a transition as the next state in the flow. If there is no transition defined the flow ends at that point in the execution. So far the examples have only shown sequential transition but here there will be a conditional transition based on input data of the flow. </p>"},{"location":"getting_started/transitions/#conditional-transition","title":"Conditional Transition","text":"<p>To execute conditional transitions Direktiv provides a <code>switch</code> which makes decisions about where to transition to next based on the instance data by evaluating a number of <code>jq</code> or <code>js</code> expressions and checking the results. </p> <pre><code>states:\n- id: ifelse\ntype: switch\nconditions:\n- condition: 'jq(.age &gt; 17)'\ntransition: accepted\n- condition: 'jq(.age != null)'\ntransition: rejected\ndefaultTransition: failure\n\n- id: accepted\ntype: noop\ntransform:\nmessage: request accepted\n\n- id: rejected\ntype: noop\ntransform:\nmessage: rejected based on age\n\n- id: failure\ntype: error\nerror: age.error\nmessage: no age provided\n</code></pre> <p>Each of the <code>conditions</code> will be evaluated in the order it appears by running the <code>jq</code> command in <code>condition</code>. Any result other than <code>null</code>, <code>false</code>, <code>{}</code>, <code>[]</code>, <code>\"\"</code>, or <code>0</code> will cause the condition to be considered a successful match. If no conditions match the default transition will be used. </p> <p>Transform</p> <p>Each condition has a <code>transform</code> attribute and there is a <code>defaultTransform</code> so every condition can modfiy the state data if there is a successful match. </p> <p>Running the above example will always go to the <code>failure</code> state because no input data has been provided for this flow. In this case the <code>failure</code> state is an <code>error</code> state which marks the flow as failed. More about errors can be found in the error handling section.</p>"},{"location":"getting_started/transitions/#input-data","title":"Input Data","text":"<p>To make the above example more useful the flow needs input data. Input data in Direktiv will never be empty. If the flow is called with no data it will be executed with an empty JSON object <code>{}</code>. If the payload is in JSON format it will be base64 encoded and provided with the attribute <code>input</code>. </p> <pre><code>{\n\"input\": \"T1hSisBaSE64Data==\"\n}\n</code></pre> <p>The above flow can be called with a simple JSON providing a value for age. </p> <pre><code>{ \"age\": 18\n}\n</code></pre> <p>The curl command to call the flow via the API is the following. Please adjust the flow and server name if required.</p> <pre><code>curl -X POST http://localhost:8080/api/namespaces/demo/tree/MYWORKFLOWNAME?op=wait \\\n--data-binary @- &lt;&lt; EOF\n{ \n    \"age\": 18\n}\nEOF\n</code></pre> <p>The response is always the last state data of a flow. Because the final states include a <code>transform</code> the response of the flow would be the transformed data.</p> <pre><code>{\n\"message\": \"request accepted\"\n}\n</code></pre>"},{"location":"getting_started/validating/","title":"Validating Input","text":"<p>In some cases it is important to validate the state of the flow. This can be done as the first state in the flow to protect the flow from rogue data or within the flow to check the state data before proceeding. Direktiv is using JSON schema to validate the state data.</p> Check Attribute<pre><code>states:\n- id: data\ntype: noop\ntransform: name: Michael\ntransition: check\n- id: check\ntype: validate\nschema:\ntype: object\nrequired: - name\nproperties:\nname:\ntype: string\n</code></pre> <p>The above example will succedd because the attribute <code>name</code> is set and it is a string, in this case <code>Michael</code>. If the the value would be an integer the flow would fail.</p> Failed Attribute<pre><code>states:\n- id: start\ntype: validate\nschema:\ntype: object\nrequired: - name\nproperties:\nname:\ntype: string\n</code></pre> <p>JSON schema is used to validate JSON structures and not contents. It can not validate if the value of <code>name</code> has a certain content. If that is a requirement Direktiv's switch statement has to be used. </p>"},{"location":"getting_started/validating/#first-state","title":"First State","text":"<p>Direktiv can generate a form if the validate state is the first state in the flow. </p> Validate Form<pre><code>states:\n- id: start\ntype: validate\nschema:\ntype: object\nrequired: - name\nproperties:\nname:\ntype: string\ntitle: Name\ndescription: Please enter your name\ndefault: My Name\n</code></pre> <p>In this example the <code>default</code> attribute is used and it is shown in the form. Direktiv can not set defaults via API or in a running flow. It is for  form generation only. If defaults are required <code>jq</code> can be used like <code>jq(.name // \"Michael\")</code>. The following validate would ask for the name but set it to <code>Michael</code> if it is empty.</p> Setting Defaults<pre><code>states:\n- id: start\ntype: validate\nschema:\ntype: object\nproperties:\nname:\ntype: string\ntitle: Name\ndescription: Please enter your name\ntransition: next-state\n- id: next-state\ntype: noop\ntransform: 'jq(. + { name: (.name // \"Michael\") })'\n</code></pre>"},{"location":"getting_started/advanced/making-functions/","title":"Making Custom Functions","text":"<p>If a custom function is required in case there are no Direktiv functions available it is easy to create those. Direktiv is pulling the images defined in the <code>functions</code> section and executes the container in the flow. They can be in any repository.</p> Custom Function<pre><code>functions:\n- id: custom\nimage: mycompany/customfunction\ntype: knative-workflow\n</code></pre> <p>The custom container just need to implement a few things. The most important requirement is to listen to port <code>8080</code>. The data in the flow will be posted to the container on that port. </p> Input<pre><code>- id: notify\ntype: action\naction:\nfunction: custom\ninput:\nhello: world\n</code></pre> <p>In the above example Direktiv would post JSON <code>{ \"hello\": \"world\" }</code> to the function. The function can use his date to execute whatever it needs to do. After that the function has to return in JSON formart. Direktiv will fetch the response and add it to the state data in the <code>return</code> attribute. The flow can use that data and proceed. </p>"},{"location":"getting_started/advanced/making-functions/#reporting-errors","title":"Reporting Errors","text":"<p>If something goes wrong a function can report an error to the calling flow instance by adding HTTP headers to the response. If these headers are populated the execution of the function will be considered a failure regardless of what's stored in response data.</p> <p>The headers to report errors are: <code>Direktiv-ErrorCode</code> and <code>Direktiv-ErrorMessage</code>. If an error message is defined without defining an error code the calling flow instance will be marked as \"crashed\" without exposing any helpful information, so it's important to always define both. Errors raised by functions are always 'catchable' by their error codes.</p> Error Headers<pre><code>  \"Direktiv-ErrorCode\": \"myapp.input\",\n\"Direktiv-ErrorMessage\": \"Missing 'customerId' property in JSON input.\"\n</code></pre>"},{"location":"getting_started/advanced/making-functions/#logging","title":"Logging","text":"<p>Logging for functions is a simple HTTP POST or GET request to the address:</p> <p><code>http://localhost:8889/log?aid=$ACTIONID</code></p> <p>If POST is used the body of the request is getting logged for GET requests add a log request parameter. The important parameter is $ACTIONID. Each requests gets an action id header which identifies the flow instance. This parameter has to be passed back to attach the log to the instance. This information is passed in as in the initial request (Direktiv-ActionID).</p>"},{"location":"getting_started/advanced/making-functions/#examples","title":"Examples","text":"<ul> <li>Dotnet</li> <li>Python FastAPI</li> <li>Golang</li> <li>Java</li> <li>Node</li> <li>Python</li> <li>Rust</li> </ul>"},{"location":"getting_started/advanced/metadata/","title":"Metadata","text":"<p>If Direktiv flow are consumed by external applications metadata can be used to request the state of a flow. It is data which can be set by the flow and requested via API. This in particular useful if the flow is executed asynchronously.</p>"},{"location":"getting_started/advanced/metadata/#executing-flow-asynchronously","title":"Executing Flow Asynchronously","text":"<p>A flow can be started with a simple API call. By default this is done asynchronously and can be called e.g. via shell with curl:</p> <p><code>curl -X POST http://&lt;DIREKTIV-ADDRESS&gt;/api/namespaces/&lt;NAMESPACE&gt;/tree/&lt;FLOW-NAME&gt;?op=execute</code></p> <p>This call would return information about the started flow and it looks like the following:</p> Workflow Info<pre><code>{\n\"namespace\": \"asdas\",\n\"instance\": \"24d6b04b-6e3c-47ba-a300-462f02c8fcae\"\n}\n</code></pre> <p>To request the metadata the <code>instance</code> attribute is the value required for subsequent requests to fetch the metadata. </p> <p><code>curl http://10.100.91.85/api/namespaces/&lt;NAMESPACE&gt;/instances/&lt;INSTANCE ID FROM THE PREVIOUS CALL&gt;/metadata | jq -r .data | base64 -d</code></p> <p>The following flow with just <code>delay</code> states can be used to test the result of the metadata call.</p> Metadata Flow Example<pre><code>states:\n- id: step1\ntype: delay\nmetadata:\nstate: waiting at the moment at state one\nduration: PT30S\ntransition: step2\n\n- id: step2 type: delay\nmetadata:\nstate: waiting at the moment at state two\nduration: PT30S\ntransition: step3\n\n- id: step3\ntype: delay\nmetadata:\nstate: waiting at the moment at state three\nduration: PT30S\n</code></pre>"},{"location":"getting_started/advanced/timeout/","title":"Timeouts","text":"<p>Direktiv supports timeouts on different levels. The main reason for having timeouts is to avoid having long-running or orphaned flows. The default timeout for flows and actions is 15 minutes.</p>"},{"location":"getting_started/advanced/timeout/#flow-timeouts","title":"Flow Timeouts","text":"<p>There is a general flow time out setting which controls how Direktiv will try to gracefully stop or interrupt the flow and eventually kill the flow if that is not possible. The time has to be provided in <code>ISO8601</code> format.</p> <pre><code>timeouts:\ninterrupt: PT20M\nkill: PT30M\n\nstates:\n- id: nothing\ntype: noop\nlog: I'm doing nothing\n</code></pre>"},{"location":"getting_started/advanced/timeout/#state-timeouts","title":"State Timeouts","text":"<p>Every state has a timeout attribute as well. This is in particular interesting for functions and the action state. If the timeout is triggered in an action Direktiv sends an interrupt to the action and it is up to the function to handle it.</p> Action Timeouts<pre><code>functions:\n- id: httprequest\nimage: gcr.io/direktiv/functions/http-request:1.0\ntype: knative-workflow\n\nstates:\n- id: timeout-test\ntype: action\n# this flow fails if it exceeds 10 seconds\ntimeout: PT10S\naction:\nfunction: httprequest\ninput:\nmethod: \"GET\"\nurl: \"https://jsonplaceholder.typicode.com/todos/1\"\n</code></pre>"},{"location":"getting_started/advanced/timeout/#events","title":"Events","text":"<p>Another use for timeouts is events. There are three states consuming events: consumeEvent, eventsAnd and eventsXor. If the timeout is reached the flow fails or the error can be caught and handled. </p> Event Wait And Timeout<pre><code>states:\n- id: something\ntype: noop\ntransition: consume\n\n- id: consume\ntype: consumeEvent\n# wait for the event for one minute, otherwise fail\ntimeout: PT1M\nevent:\ntype: com.github.pull.create\ncontext:\nsubject: '123'\n</code></pre>"},{"location":"getting_started/advanced/timeout/#catching-timeouts","title":"Catching Timeouts","text":"<p>Timeouts in actions can be caught and the error thrown is <code>direktiv.cancels.timeout.soft</code>. Based on that error the flow can be re-routed. </p> Catch Timeout<pre><code>states:\n- id: something\ntype: noop\ntransition: consume\n\n- id: consume\ntype: consumeEvent\ntimeout: PT1S\nevent:\ntype: com.github.pull.create\ncontext:\nsubject: '123'\ncatch:\n- error: \"direktiv.cancels.timeout.soft\"\ntransition: handle-error\n\n- id: handle-error\ntype: noop\nlog: error handling\n</code></pre> <p>Timeouts in States</p> <p>Direktiv is not automatically calculating timeouts. If an action has a 30 minute timeout the flow timeout has to be increased as well to cater for long-running actions. </p>"},{"location":"installation/","title":"Installation","text":"<p>Direktiv is using Helm charts for installation. For a basic installation there are only two dependencies. A PostgreSQL database and Knative. Optional dependencies are Linkerd as service mesh and monitoring and tracing tools, e.g. backends for Direktiv's Opentelemetry configuration. The following diagram shows a high-level architecture of Direktiv and the required and optional components.</p> <p> </p> <p>The following sections explain how to install each component in a local cluster:</p> <ul> <li> <p>Kubernetes</p> </li> <li> <p>Linkerd</p> </li> <li> <p>Postgres</p> </li> <li> <p>Direktiv</p> </li> <li> <p>Knative</p> </li> </ul>"},{"location":"installation/#run-docker-image","title":"Run Docker Image","text":"<p>For testing there is a \"all-in-one\" Docker image available. It contains all required components already installed and can be used for testing or development. It has a container registry installed on port 31212 as well which can be used to push local images.</p> Direktiv Docker Container<pre><code>docker run --privileged -p 8080:80 -ti direktiv/direktiv-kube\n</code></pre> <p>The docker image has additional environment variables which can add other functionalities and configurations:</p> <ul> <li>APIKEY: Set an API key for the application</li> <li>HTTPS_PROXY: Sets the HTTPS_PROXY environment variable</li> <li>HTTP_PROXY: Sets the HTTP_PROXY environment variable</li> <li>NO_PROXY: Sets the NO_PROXY environment variable</li> <li>EVENTING: Enables Knative eventing</li> <li>DEBUG: Prints k3s output to stdout</li> </ul> Direktiv Docker Container with API Key and Registry<pre><code>docker run -e APIKEY=123 --privileged -p 8080:80 -p 31212:31212 -ti direktiv/direktiv-kube\n</code></pre>"},{"location":"installation/database/","title":"Database","text":"<p>Direktiv requires a PostgreSQL 13+ database. It acts as datastore as well as pub/sub system between Direktiv's components. It has been tested with Postgres offerings from cloud providers as well as on-premise installations. It is recommended to use a managed Postgres service from cloud providers. If that is not possible Postgres can be installed in Kubernetes as well. </p> <p>To install a Postgres instance in Kubernetes we are using CrunchyData's operator and helm charts. The following section will provide exmaples for different installation scenarions from basic testing setups to more complex high-availability configurations. For inidividual changes please visit the CrunchyData Operator documentation page. </p>"},{"location":"installation/database/#installing-the-operator","title":"Installing the Operator","text":"<p>The operator is provided as Helm chart and the installation is straighforward. Add Direktiv's helm chart repository and run the installation command.</p> Install Postgres Operator<pre><code>helm repo add direktiv https://chart.direktiv.io\nhelm install -n postgres --create-namespace postgres direktiv/pgo\n</code></pre> <p>Backup Ports</p> <p>For the backup to work properly port 2022 needs to be open between the nodes</p>"},{"location":"installation/database/#creating-a-postgres-instance","title":"Creating a Postgres Instance","text":""},{"location":"installation/database/#basic-configuration","title":"Basic Configuration","text":"<p>This basic configuration is good for small instances and testing. It creates weekly backups and keeps the last 4 backups. Direktiv connects directly to the Database without connection pooling.</p> Basic Install<pre><code>kubectl apply -f https://raw.githubusercontent.com/direktiv/direktiv/main/kubernetes/install/db/basic.yaml\n</code></pre> Basic Database Configuration<pre><code>apiVersion: postgres-operator.crunchydata.com/v1beta1\nkind: PostgresCluster\nmetadata:\nname: direktiv\nnamespace: postgres\nspec:\npostgresVersion: 14\ninstances:\n- name: \"direktiv\"\nreplicas: 1\ndataVolumeClaimSpec:\naccessModes:\n- \"ReadWriteOnce\"\nresources:\nrequests:\nstorage: \"1Gi\"\nbackups:\npgbackrest:\nglobal:\n# Keep 4 Backups\nrepo1-retention-full: \"4\"\nrepo1-retention-full-type: count\nrepos:\n- name: repo1\nschedules:\n# Run every Sunday\nfull: \"0 1 * * 0\"\nvolume:\nvolumeClaimSpec:\naccessModes:\n- \"ReadWriteOnce\"\nresources:\nrequests:\nstorage: \"4Gi\"\n</code></pre>"},{"location":"installation/database/#high-availability","title":"High-Availability","text":"<p>High-Availabilty can be achieved by scaling the database replicas. The following example has added daily differential backups and pod anti-affinity to spread the pods across the cluster. If anti-affinity is used the cluster needs to have the same number of nodes and database replicas.</p> Basic Install<pre><code>kubectl apply -f https://raw.githubusercontent.com/direktiv/direktiv/main/kubernetes/install/db/ha.yaml\n</code></pre> High-Availability Configuration<pre><code>apiVersion: postgres-operator.crunchydata.com/v1beta1\nkind: PostgresCluster\nmetadata:\nname: direktiv\nnamespace: postgres\nspec:\npostgresVersion: 14\ninstances:\n- name: \"instance1\"\nreplicas: 3\naffinity:\npodAntiAffinity:\nrequiredDuringSchedulingIgnoredDuringExecution:\n- labelSelector:\nmatchExpressions:\n- key: \"postgres-operator.crunchydata.com/cluster\"\noperator: In\nvalues:\n- direktiv\ntopologyKey: \"kubernetes.io/hostname\"\ndataVolumeClaimSpec:\naccessModes:\n- \"ReadWriteOnce\"\nresources:\nrequests:\nstorage: \"1Gi\"\nbackups:\npgbackrest:\nglobal:\nrepo1-retention-full: \"4\"\nrepo1-retention-full-type: count\nrepos:\n- name: repo1\nschedules:\nfull: \"0 1 * * 0\"\ndifferential: \"0 1 * * 1-6\"\nvolume:\nvolumeClaimSpec:\naccessModes:\n- \"ReadWriteOnce\"\nresources:\nrequests:\nstorage: \"4Gi\"\n</code></pre>"},{"location":"installation/database/#high-availability-with-s3-backup","title":"High-Availability with S3 Backup","text":"<p>CrunchyData's Postgres operator can store backups in AWS, Azure and Google Cloud as well. The following example shows how to use AWS S3 as backup storage. A secret is required for the S3 backend with the appropriate permission. This requires a <code>s3.conf</code> file with the S3 key and secret.</p> s3.conf<pre><code>[global]\nrepo1-s3-key=MYKEY\nrepo1-s3-key-secret=MYSECRET\n</code></pre> <p>After creating the file adding the secret is a simple <code>kubectl</code> command:</p> Create S3 Secret<pre><code>kubectl create secret generic -n postgres direktiv-pgbackrest-secret --from-file=s3.conf\n</code></pre> <p>To test if the values are correct run the following command:</p> Show S3 Secrets<pre><code>kubectl get secret -n postgres direktiv-pgbackrest-secret -o go-template='{{ index .data \"s3.conf\" | base64decode }}'\n</code></pre> <p>High-Availabilty can be achieved by scaling the database replicas. The following example has added daily differential backups and pod anti-affinity to spread the pods across the cluster. If anti-affinity is used the cluster needs to have the same number of nodes and database replicas.</p> S3 Backup Install<pre><code>kubectl apply -f https://raw.githubusercontent.com/direktiv/direktiv/main/kubernetes/install/db/s3.yaml\n</code></pre> S3 Configuration<pre><code>  apiVersion: postgres-operator.crunchydata.com/v1beta1\nkind: PostgresCluster\nmetadata:\nname: direktiv\nnamespace: postgres\nspec:\npostgresVersion: 14\ninstances:\n- name: \"instance1\"\nreplicas: 1\ndataVolumeClaimSpec:\naccessModes:\n- \"ReadWriteOnce\"\nresources:\nrequests:\nstorage: \"1Gi\"\nbackups:\npgbackrest:\nconfiguration:\n- secret:\nname: direktiv-pgbackrest-secret\nglobal:\nrepo1-retention-full: \"4\"\nrepo1-retention-full-type: count\nrepos:\n- name: repo1\ns3:\nbucket: my-bucket\nendpoint: s3.eu-central-1.amazonaws.com:443\nregion: eu-central-1\nschedules:\nfull: \"0 1 * * 0\"\n</code></pre>"},{"location":"installation/database/#connection-pooling","title":"Connection-Pooling","text":"<p>Connection pooling help scaling and maintaining availability between your application and the database. The Postgres Operator provides the option to install <code>pgBouncer</code> as connection pooling mechanism. If it is a multi-node cluster the <code>pgBouncer</code> replicas can be increased and spread acorss the cluster with pod anit-affinity rules. </p> pgBouncer Install<pre><code>kubectl apply -f https://raw.githubusercontent.com/direktiv/direktiv/main/kubernetes/install/db/pgbouncer.yaml\n</code></pre> pgBouncer Configuration<pre><code>apiVersion: postgres-operator.crunchydata.com/v1beta1\nkind: PostgresCluster\nmetadata:\nname: direktiv\nnamespace: postgres\nspec:\npostgresVersion: 14\ninstances:\n- name: \"direktiv\"\nreplicas: 1\ndataVolumeClaimSpec:\naccessModes:\n- \"ReadWriteOnce\"\nresources:\nrequests:\nstorage: \"1Gi\"\nproxy:\npgBouncer:\nreplicas: 2\naffinity:\npodAntiAffinity:\nrequiredDuringSchedulingIgnoredDuringExecution:\n- labelSelector:\nmatchExpressions:\n- key: \"postgres-operator.crunchydata.com/cluster\"\noperator: In\nvalues:\n- direktiv\ntopologyKey: \"kubernetes.io/hostname\"\nbackups:\npgbackrest:\nglobal:\n# Keep 4 Backups\nrepo1-retention-full: \"4\"\nrepo1-retention-full-type: count\nrepos:\n- name: repo1\nschedules:\n# Run every Sunday\nfull: \"0 1 * * 0\"\nvolume:\nvolumeClaimSpec:\naccessModes:\n- \"ReadWriteOnce\"\nresources:\nrequests:\nstorage: \"4Gi\"\n</code></pre>"},{"location":"installation/database/#getting-database-secrets","title":"Getting Database Secrets","text":"<p>Direktiv will need the database connection information during installation with a Helm chart. It is a good start for an installation YAML to have this information. It can be easily done by running a simple script:</p> Database Configuration (No Connection Pooling)<pre><code>echo \"database:\n  host: \\\"$(kubectl get secrets -n postgres direktiv-pguser-direktiv -o 'go-template={{index .data \"host\"}}' | base64 --decode)\\\"\n  port: $(kubectl get secrets -n postgres direktiv-pguser-direktiv -o 'go-template={{index .data \"port\"}}' | base64 --decode)\n  user: \\\"$(kubectl get secrets -n postgres direktiv-pguser-direktiv -o 'go-template={{index .data \"user\"}}' | base64 --decode)\\\"\n  password: \\\"$(kubectl get secrets -n postgres direktiv-pguser-direktiv -o 'go-template={{index .data \"password\"}}' | base64 --decode)\\\"\n  name: \\\"$(kubectl get secrets -n postgres direktiv-pguser-direktiv -o 'go-template={{index .data \"dbname\"}}' | base64 --decode)\\\"\n  sslmode: require\" &gt; direktiv.yaml\n</code></pre> Database Configuration (With Connection Pooling)<pre><code>echo \"database:\n  host: \\\"$(kubectl get secrets -n postgres direktiv-pguser-direktiv -o 'go-template={{index .data \"pgbouncer-host\"}}' | base64 --decode)\\\"\n  port: $(kubectl get secrets -n postgres direktiv-pguser-direktiv -o 'go-template={{index .data \"pgbouncer-port\"}}' | base64 --decode)\n  user: \\\"$(kubectl get secrets -n postgres direktiv-pguser-direktiv -o 'go-template={{index .data \"user\"}}' | base64 --decode)\\\"\n  password: \\\"$(kubectl get secrets -n postgres direktiv-pguser-direktiv -o 'go-template={{index .data \"password\"}}' | base64 --decode)\\\"\n  name: \\\"$(kubectl get secrets -n postgres direktiv-pguser-direktiv -o 'go-template={{index .data \"dbname\"}}' | base64 --decode)\\\"\n  sslmode: require\" &gt; direktiv.yaml\n</code></pre>"},{"location":"installation/database/#restore-from-s3","title":"Restore from S3","text":"<p>It is always recommended to test the backup and restore before using Direktiv in production. To restore from S3 is a straightforward process. The first step is to pick the backup used for the restore process. It can be found under <code>bd/backup</code> in the bucket used for backups in S3. It looks like this: <code>20221023-042407F</code>. There are two differtent scenarios to consider. The first one is a restore for an existing database. This can be a restore of as certain backup or a point-in-time recovery. This can be achieved with a <code>restore</code> attribute in the dtaabase configuration YAML.</p> Restore From S3 (Same Database)<pre><code>...\nbackups:\npgbackrest:\nconfiguration:\n- secret:\nname: direktiv-pgbackrest-secret\nglobal:\nrepo1-retention-full: \"4\"\nrepo1-retention-full-type: count\nrepos:\n- name: repo1\ns3:\nbucket: cd-direktiv-backup\nendpoint: s3.eu-central-1.amazonaws.com:443\nregion: eu-central-1\nschedules:\nfull: \"0 1 * * 0\"\n# Enable Restore\nrestore:\nenabled: true\nrepoName: repo1\noptions:\n- --set=20221023-042407F\n# point-in-time recovery alternative\n# - --type=time\n# - --target=\"2021-06-09 14:15:11-04\"\n</code></pre> <p>The second scenario is if the whole database has been destroyed and it is a restore to a new database instance. In this case a <code>datasource</code> attribute has to be added to define the source for the backup.</p> Restore From S3 (New Database)<pre><code>  apiVersion: postgres-operator.crunchydata.com/v1beta1\nkind: PostgresCluster\nmetadata:\nname: direktiv\nnamespace: postgres\nspec:\ndataSource:\npostgresCluster:\nclusterName: direktiv\nrepoName: repo1\noptions:\n- --set=20221023-042407F\npostgresVersion: 14\ninstances:\n...\n</code></pre> <p>Additional Information</p> <p>For more information visit CrunchyData's documentation about disaster recovery.</p>"},{"location":"installation/database/#restore-from-pvc","title":"Restore from PVC","text":"<p>In case the database is not using S3 backups the backups need to be stored in a safe location in case of loss of the node storing the backups. The data has to be transferred via e.g. scp in using a cron job. A restore of an existing database can be achieved with a simple <code>restore</code> attribute in the database configuration YAML mentioned in the S3 restore section of this documentation. The process is different if the backup node has been destroyed. It is important to not do this restore procedure if a backup is laready running. The backup needs to be rescheduled to execute it without running a backup in parallel.</p>"},{"location":"installation/database/#identify-backup-pvc","title":"Identify Backup PVC","text":"<p>The first step to store the backup is to identify the node where the backup is stored. </p> Identify PV<pre><code>kubectl get pv\n\nNAME                                       CAPACITY   ...     CLAIM         # This is the backup node                           \npvc-80ae5325-8b27-4695-b6df-b362dd946cb7   1Gi        ...     postgres/direktiv-repo1                 \npvc-ce9bb226-1038-49bf-bed6-e6d0188b228c   1Gi        ...     postgres/direktiv-direktiv-wnh4-pgdata   </code></pre> <p>Describing the PV shows the node where the data is stored and the directory of the data. This directory needs to be stored in a safe location for a later restore.</p> Identify PV<pre><code>kubectl describe  pv pvc-80ae5325-8b27-4695-b6df-b362dd946cb7\n\nName:              pvc-80ae5325-8b27-4695-b6df-b362dd946cb7\n...\nClaim:             postgres/direktiv-repo1\n...\nNode Affinity:     Required Terms:  # Node where the data is stored\nTerm 0:        kubernetes.io/hostname in [db2]\nMessage:           \nSource:\n    Type:          HostPath (bare host directory volume)\n# Data directory on the node\nPath:          /var/lib/rancher/k3s/storage/pvc-80ae5325-8b27-4695-b6df-b362dd946cb7_postgres_direktiv-repo1\n    HostPathType:  DirectoryOrCreate\n</code></pre>"},{"location":"installation/database/#copy-data","title":"Copy Data","text":"<p>To restore the database a backup has to be selected. The available backups are in <code>&lt;Backup Directory&gt;/&lt;Old PVC Name&gt;/backup/db</code>. The directory will look like the following:</p> Backup Directory<pre><code>drwxr-x--- 7 root root 4096 Okt 23 08:11 .\ndrwxr-x--- 3 root root 4096 Okt 23 08:11 ..\ndrwxr-x--- 3 root root 4096 Okt 23 08:11 20221023-060801F\ndrwxr-x--- 3 root root 4096 Okt 23 08:11 20221023-060901F\ndrwxr-x--- 3 root root 4096 Okt 23 08:11 20221023-061001F\ndrwxr-x--- 3 root root 4096 Okt 23 08:11 20221023-061101F\ndrwxr-x--- 3 root root 4096 Okt 23 08:11 backup.history\n-rw-r----- 1 root root 2792 Okt 23 08:11 backup.info\n-rw-r----- 1 root root 2792 Okt 23 08:11 backup.info.copy\nlrwxrwxrwx 1 root root   16 Okt 23 08:11 latest -&gt; 20221023-061101F\n</code></pre> <p>The next step is to identify where the new backup folder is located. It is exactly the same procedure as used in the copying process. The <code>archive</code> and <code>backup</code> have to be copied into the new backup directory of the new cluster. </p> Copy  Folders<pre><code>sudo cp -Rf  &lt;Backup Directory&gt;/archive /var/lib/rancher/k3s/storage/&lt;New PV Directory&gt;\nsudo cp -Rf  &lt;Backup Directory&gt;/backup /var/lib/rancher/k3s/storage/&lt;New PV Directory&gt;\n\nsudo chown -R 26:tape  /var/lib/rancher/k3s/storage/&lt;New PV Directory&gt;\n</code></pre> <p>The selected restore needs to be configured in the database configuration YAML and applied with <code>kubectl apply -f mydb.yaml</code>.</p> Restore from PVC<pre><code>apiVersion: postgres-operator.crunchydata.com/v1beta1\nkind: PostgresCluster\nmetadata:\nname: direktiv\nnamespace: postgres\nspec:\ndataSource:\npostgresCluster:\nclusterName: direktiv\nrepoName: repo1\noptions:\n- --set=20221023-075501F\n- --archive-mode=off\npostgresVersion: 14\n</code></pre>"},{"location":"installation/database/#update-password","title":"Update Password","text":"<p>If this is a new installation of the database the password will be overwritten and the command to generate the <code>direktiv.yaml</code> file is incorrect. Therefore it is advised to update the password to the password in the Kubernetes secret and update Direktiv with the new password.</p> Update User Password<pre><code># get the old password\nkubectl get secrets -n postgres direktiv-pguser-direktiv -o 'go-template={{index .data \"password\"}}' | base64 --decode\n\n# execute in pod \nkubectl exec -n postgres --stdin --tty direktiv-direktiv-&lt;POD-ID&gt; -- psql\n\n# update user password\nALTER USER direktiv WITH PASSWORD '&lt;PASSWORD FROM FIRST COMMAND&gt;';\n\n# exit\n\\q\n</code></pre>"},{"location":"installation/database/#helpful-commands","title":"Helpful Commands","text":"<p>Fetch Master Instance<pre><code>kubectl -n postgres get pods \\\n--selector=postgres-operator.crunchydata.com/role=master \\\n-o jsonpath='{.items[*].metadata.labels.postgres-operator\\.crunchydata\\.com/instance}'\n</code></pre> Cluster Information<pre><code>kubectl -n postgres describe postgrescluster direktiv\n</code></pre></p> Use psql in Database Instance<pre><code>kubectl exec -n postgres --stdin --tty direktiv-direktiv-nl9z-0 -- psql\n</code></pre>"},{"location":"installation/direktiv/","title":"Direktiv","text":"<p>Direktiv requires a few components to run. At least the database has to be installed before proceeding with this part of the installation. </p> <ul> <li>Linkerd</li> <li>Database</li> <li>Knative</li> <li>Direktiv</li> </ul> <p>The following is a two-step process. First Knative is installed. Knative is responsible to execute Direktiv's serverless functions. It comes pre-configured to work with Direktiv. </p>"},{"location":"installation/direktiv/#knative","title":"Knative","text":"<p>Knative is an essential part of Direktiv and can be installed with Knative's operator. The following command installs this operator in the default namespace.</p> Install Knative Operator<pre><code>kubectl apply -f https://github.com/knative/operator/releases/download/knative-v1.9.4/operator.yaml\n</code></pre> <p>After the deployment of the operator a new instance of Knative Serving can be created. Direktiv requires a certain configuration for Knative to work. There are two examples of configurations in the (Github repository). The first one is the standard configuration and the other one is an example with proxy settings. </p> Install Knative<pre><code>kubectl create ns knative-serving\nkubectl apply -f https://raw.githubusercontent.com/direktiv/direktiv/main/kubernetes/install/knative/basic.yaml\n</code></pre> <p>Direktiv supports Contour as network component. </p> Install Contour<pre><code>kubectl apply --filename https://github.com/knative/net-contour/releases/download/knative-v1.9.3/contour.yaml\n</code></pre> <p>This installs Contour in two namespaces <code>contour-internal</code> and <code>contour-external</code>. The second namespace is not needed for Direktiv to run and might even block the ingress controller from getting an external IP. This can be deleted with:</p> Delete Contour External<pre><code>kubectl delete namespace contour-external\n</code></pre>"},{"location":"installation/direktiv/#direktiv_1","title":"Direktiv","text":"<p>Firstly, create a <code>direktiv.yaml</code> file which contains all of the database connectivity and secret information created during the database setup:</p> Direktiv Database Configuration<pre><code>database:\n# -- database host\nhost: \"direktiv-ha.postgres.svc\"\n# -- database port\nport: 5432\n# -- database user\nuser: \"direktiv\"\n# -- database password\npassword: \"direktivdirektiv\"\n# -- database name, auto created if it does not exist\nname: \"direktiv\"\n# -- sslmode for database\nsslmode: require\n</code></pre> Database Configuration (No Connection Pooling)<pre><code>echo \"database:\n  host: \\\"$(kubectl get secrets -n postgres direktiv-pguser-direktiv -o 'go-template={{index .data \"host\"}}' | base64 --decode)\\\"\n  port: $(kubectl get secrets -n postgres direktiv-pguser-direktiv -o 'go-template={{index .data \"port\"}}' | base64 --decode)\n  user: \\\"$(kubectl get secrets -n postgres direktiv-pguser-direktiv -o 'go-template={{index .data \"user\"}}' | base64 --decode)\\\"\n  password: \\\"$(kubectl get secrets -n postgres direktiv-pguser-direktiv -o 'go-template={{index .data \"password\"}}' | base64 --decode)\\\"\n  name: \\\"$(kubectl get secrets -n postgres direktiv-pguser-direktiv -o 'go-template={{index .data \"dbname\"}}' | base64 --decode)\\\"\n  sslmode: require\" &gt; direktiv.yaml\n</code></pre> Database Configuration (With Connection Pooling)<pre><code>echo \"database:\n  host: \\\"$(kubectl get secrets -n postgres direktiv-pguser-direktiv -o 'go-template={{index .data \"pgbouncer-host\"}}' | base64 --decode)\\\"\n  port: $(kubectl get secrets -n postgres direktiv-pguser-direktiv -o 'go-template={{index .data \"pgbouncer-port\"}}' | base64 --decode)\n  user: \\\"$(kubectl get secrets -n postgres direktiv-pguser-direktiv -o 'go-template={{index .data \"user\"}}' | base64 --decode)\\\"\n  password: \\\"$(kubectl get secrets -n postgres direktiv-pguser-direktiv -o 'go-template={{index .data \"password\"}}' | base64 --decode)\\\"\n  name: \\\"$(kubectl get secrets -n postgres direktiv-pguser-direktiv -o 'go-template={{index .data \"dbname\"}}' | base64 --decode)\\\"\n  sslmode: require\" &gt; direktiv.yaml\n</code></pre> <p>Using this <code>direktiv.yaml</code> configuration, deploy the direktiv helm chart:</p> <pre><code>helm install -f direktiv.yaml -n direktiv direktiv direktiv/direktiv\n</code></pre> <p>For more configuration options go to Direktiv's helm charts.</p>"},{"location":"installation/kubernetes/","title":"Kubernetes","text":"<p>Direktiv is a cloud-native solution requiring Kubernetes to run. It is working with all Kubernetes offerings of the major cloud providers as well as on-premise Kubernetes installations. The easiest way to install a Kubernetes cluster for Kubernetes is using k3s. The following section explains how to install k3s on-premise. The minimum version is 1.24.</p>"},{"location":"installation/kubernetes/#k3s","title":"k3s","text":"<p>Direktiv supports Kubernetes offerings from all major cloud providers and requires Kubernets 1.24+ to be installed. Direktiv supports Kubernetes setups with a single node, seperate server and agents nodes as well as small setups with nodes acting both as server and agent. The following section describes the installation with k3s.</p>"},{"location":"installation/kubernetes/#single-node-setup","title":"Single Node Setup","text":"<p>A single node setup requires no further configuration and k3s can be used with the default settings. This setup disables Traefik to be replaced with Nginx during the installation. If proxy configuration is required please read the proxy setup section. </p> One Node Setup<pre><code>curl -sfL https://get.k3s.io | sh -s - --disable traefik --write-kubeconfig-mode=644\n</code></pre> <p>k3s Version</p> <p>If an error message occurs during installation, e.g. <code>resource mapping not found for name: \"linkerd-heartbeat\" namespace: \"linkerd\" from \"\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"</code> it is most likely the wrong k3s version. To keep k3S small there is only a subset of Kubernetes APIs available. Please try to update k3s to the latest version or at least 1.24</p>"},{"location":"installation/kubernetes/#multi-node-setup","title":"Multi Node Setup","text":"<p>For production use it is recommended to run Direktiv in a multi-node environment. The k3s documentation page provides a lot of information about configuration and installation options. The following is a quick installation instruction to setup a three node cluster with nodes action as servers and agents. </p>"},{"location":"installation/kubernetes/#server-configuration","title":"Server configuration","text":"<p>In a multi-node environment the nodes have to communicate with each other. Therefore certain ports between those nodes have to be open. The following table shows the ports required to be accessible (incoming) for the nodes to enable this. On some Linux distributions firewall changes have to be applied. Please see k3s installation guide for detailed installation instructions.</p> Protocol Port Source Description TCP 6443 k3s agent nodes Kubernetes API Server UDP 8472 k3s server and agent nodes VXLAN TCP 10250 k3s server and agent nodes Kubelet metrics TCP 2379-2380 k3s server nodes Required for HA with embedded etcd only <p>Firewall changes (Centos/RedHat):</p> Example Firewall Changes Centos/RedHat<pre><code>sudo firewall-cmd --permanent --add-port=6443/tcp\nsudo firewall-cmd --permanent --add-port=10250/tcp\nsudo firewall-cmd --permanent --add-port=8472/udp\nsudo firewall-cmd --permanent --add-port=2379-2380/tcp\nsudo firewall-cmd --reload\n</code></pre> <p>Additional Centos/RedHat Instructions</p> <p>https://rancher.com/docs/k3s/latest/en/advanced/#additional-preparation-for-red-hat-centos-enterprise-linux</p> <p>An additional Kubernetes requirement is to disable swap on the nodes. This change need to be applied permanently to survive reboots. This might be achieved differently on different Linux distributions.</p> Disable Swap<pre><code>sudo swapoff -a\nsudo sed -e '/swap/s/^/#/g' -i /etc/fstab\n</code></pre>"},{"location":"installation/kubernetes/#node-installation","title":"Node Installation","text":"<p>k3s provides a script to install k3s. It is recommended to use it for installation. The configuration can be done via environment variables during installation. For Direktiv the default ingress controller (Traefik) needs to be disabled because Nginx will be used. For installations using the embedded etcd the first server node requires the '--cluster-init' flag.</p> Initial Node<pre><code>curl -sfL https://get.k3s.io | INSTALL_K3S_EXEC=\"server --disable traefik --write-kubeconfig-mode=644 --cluster-init\" sh -\n</code></pre> <p>Loadbalancer</p> <p>To use MetalLB add <code>--disable servicelb</code> to the arguments, e.g. for on-premise installation. It is not needed if the cluster is installed in a cloud environment like AWS, GCP or Azure.</p> <p>To add nodes to the cluster the node token is required, which is saved under /var/lib/rancher/k3s/server/node-token. With this token additional nodes can be added.</p> Additional Nodes<pre><code>curl -sfL https://get.k3s.io | INSTALL_K3S_EXEC=\"server --disable traefik --write-kubeconfig-mode=644\" K3S_TOKEN=\"&lt;TOKEN FROM NODE-TOKEN FILE&gt;\" K3S_URL=https://&lt;cluster ip&gt;:6443 sh -\n</code></pre>"},{"location":"installation/kubernetes/#metallb","title":"MetalLB","text":"<p>In a on-premise environment a Kubernetes bare-metal load-balancer is required. The following example shows the use of MetalLB. k3s load-balancer needs to be disabled with <code>--disable servicelb</code> for this to work.</p> Disable Loadbalancer<pre><code>curl -sfL https://get.k3s.io | INSTALL_K3S_EXEC=\"server --disable servicelb --disable traefik --write-kubeconfig-mode=644\" K3S_TOKEN=\"&lt;TOKEN FROM NODE-TOKEN FILE&gt;\" K3S_URL=https://&lt;cluster ip&gt;:6443 sh -\n</code></pre> <p>To install MetalLB add the Helm repository and configure the avaiable IPs. </p> <pre><code>helm repo add metallb https://metallb.github.io/metallb\nhelm install metallb metallb/metallb\n</code></pre> <p>MetalLB needs an IP pool to serve IP address. During the installation this pool can be configured with fhe following example YAML file:</p> MetalLB IP Pool Configuration<pre><code>apiVersion: metallb.io/v1beta1\nkind: IPAddressPool\nmetadata:\nname: myip\nnamespace: default\nspec:\naddresses:\n- 192.168.0.199/32\n---\napiVersion: metallb.io/v1beta1\nkind: L2Advertisement\nmetadata:\nname: ipadvertise\nnamespace: default\n</code></pre>"},{"location":"installation/kubernetes/#proxy-setup","title":"Proxy Setup","text":"<p>K3s will download container images during installation and runtime. For the downloads of those internet connectivity is required. If the nodes are behind a proxy server the Linux environment variables need to provided to the service, e.g.:</p> Proxy Settings for k3s<pre><code>curl -sfL https://get.k3s.io | INSTALL_K3S_EXEC=\"server --disable traefik --write-kubeconfig-mode=644\" K3S_TOKEN=\"&lt;TOKEN FROM NODE-TOKEN FILE&gt;\" K3S_URL=https://&lt;cluster ip&gt;:6443 HTTP_PROXY=\"http://192.168.1.10:3128\" HTTPS_PROXY=\"http://192.168.1.10:3128\" NO_PROXY=\"localhost,127.0.0.1,svc,.cluster.local,192.168.1.100,192.168.1.101,192.168.1.102,10.0.0.0/8\" sh -\n</code></pre> <p>Alternatively the environment variables HTTP_PROXY, HTTPS_PROXY and NO_PROXY can be set and k3s will automatically add them to the service configuration file.</p>"},{"location":"installation/linkerd/","title":"Linkerd (Optional)","text":"<p>Linkerd is a lightweight service mesh for Kubernetes and can be used in Direktiv as a mechanism to secure communication between the components. Linkerd can enable mTLS between the core Direktiv pods as well as the containers running in a flow. The installation of Linkerd is optional. The easiest way to install Linkerd is via Helm. </p>"},{"location":"installation/linkerd/#creating-certificates","title":"Creating Certificates","text":"<p>The identity component of Linkerd requires setting up a trust anchor certificate, and an issuer certificate with its key. The following script starts a container and generates the certificates needed:</p> Generating Linkerd Certificates<pre><code>certDir=$(exe='step certificate create root.linkerd.cluster.local ca.crt ca.key \\\n--profile root-ca --no-password --insecure \\\n&amp;&amp; step certificate create identity.linkerd.cluster.local issuer.crt issuer.key \\\n--profile intermediate-ca --not-after 87600h --no-password --insecure \\\n--ca ca.crt --ca-key ca.key'; \\\nsudo docker run --mount \"type=bind,src=$(pwd),dst=/home/step\"  -i smallstep/step-cli /bin/bash -c \"$exe\";  \\\necho $(pwd));\n</code></pre> <p>Permissions</p> <p>The directory where the certificates are located is stored in $certDir. If there are permission problems, please try a different directory with write permissions.</p>"},{"location":"installation/linkerd/#install-with-helm","title":"Install with Helm","text":"<p>After creating the certificates the certificate folder should be located at $certDir. The expiry date provided during installation has to be the same as the value for the certificates (in this case: one year). The following script installs Linkerd with the previously generated certificates:</p> Install Linkerd CRDs<pre><code>helm repo add linkerd https://helm.linkerd.io/stable;\n\nhelm install linkerd-crds linkerd/linkerd-crds -n linkerd --create-namespace </code></pre> Install Linkerd<pre><code>helm install linkerd-control-plane \\\n-n linkerd \\\n--set-file identityTrustAnchorsPEM=$certDir/ca.crt \\\n--set-file identity.issuer.tls.crtPEM=$certDir/issuer.crt \\\n--set-file identity.issuer.tls.keyPEM=$certDir/issuer.key \\\nlinkerd/linkerd-control-plane --wait\n</code></pre>"},{"location":"installation/linkerd/#annotate-namespaces","title":"Annotate Namespaces","text":"<p>To use the service mesh (and, in particular, the mTLS communication) between pods within a Direktiv cluster the namespaces need to be annotated for Linkerd to inject its proxy. The default namespace to annotate is <code>direktiv</code>.</p> Annotate Namespace<pre><code>kubectl annotate ns --overwrite=true direktiv linkerd.io/inject=enabled\n</code></pre>"},{"location":"installation/summary/","title":"Quick Install","text":"<p>This is a list of \"copy&amp;paste\" commands which creates a one node Direktiv cluster.</p>"},{"location":"installation/summary/#k3s","title":"K3s","text":"<pre><code>curl -sfL https://get.k3s.io | INSTALL_K3S_VERSION=v1.24.7+k3s1 sh -s - --disable traefik --write-kubeconfig-mode=644\n</code></pre>"},{"location":"installation/summary/#linkerd","title":"Linkerd","text":""},{"location":"installation/summary/#create-certificates","title":"Create certificates","text":"<pre><code>certDir=$(exe='step certificate create root.linkerd.cluster.local ca.crt ca.key \\\n--profile root-ca --no-password --insecure \\\n&amp;&amp; step certificate create identity.linkerd.cluster.local issuer.crt issuer.key \\\n--profile intermediate-ca --not-after 87600h --no-password --insecure \\\n--ca ca.crt --ca-key ca.key'; \\\nsudo docker run --mount \"type=bind,src=$(pwd),dst=/home/step\"  -i smallstep/step-cli /bin/bash -c \"$exe\";  \\\necho $(pwd));\n</code></pre>"},{"location":"installation/summary/#install-linkerd","title":"Install Linkerd","text":"<pre><code>helm repo add linkerd https://helm.linkerd.io/stable;\n\nhelm install linkerd-crds linkerd/linkerd-crds -n linkerd --create-namespace \n\nhelm install linkerd-control-plane \\\n-n linkerd \\\n--set-file identityTrustAnchorsPEM=$certDir/ca.crt \\\n--set-file identity.issuer.tls.crtPEM=$certDir/issuer.crt \\\n--set-file identity.issuer.tls.keyPEM=$certDir/issuer.key \\\nlinkerd/linkerd-control-plane --wait\n</code></pre>"},{"location":"installation/summary/#annotate-the-namespace","title":"Annotate the Namespace","text":"<pre><code>kubectl annotate ns --overwrite=true direktiv linkerd.io/inject=enabled\n</code></pre>"},{"location":"installation/summary/#database","title":"Database","text":"<pre><code>helm repo add direktiv https://chart.direktiv.io\nhelm install -n postgres --create-namespace --set singleNamespace=true postgres direktiv/pgo\n</code></pre> <pre><code>kubectl apply -f https://raw.githubusercontent.com/direktiv/direktiv/main/kubernetes/install/db/basic.yaml\n</code></pre>"},{"location":"installation/summary/#knative","title":"Knative","text":"<pre><code>kubectl apply -f https://github.com/knative/operator/releases/download/knative-v1.9.4/operator.yaml\nkubectl create ns knative-serving\nkubectl apply -f https://raw.githubusercontent.com/direktiv/direktiv/main/kubernetes/install/knative/basic.yaml\nkubectl delete ns contour-external\n</code></pre>"},{"location":"installation/summary/#direktiv","title":"Direktiv","text":"<pre><code>echo \"database:\n  host: \\\"$(kubectl get secrets -n postgres direktiv-pguser-direktiv -o 'go-template={{index .data \"host\"}}' | base64 --decode)\\\"\n  port: $(kubectl get secrets -n postgres direktiv-pguser-direktiv -o 'go-template={{index .data \"port\"}}' | base64 --decode)\n  user: \\\"$(kubectl get secrets -n postgres direktiv-pguser-direktiv -o 'go-template={{index .data \"user\"}}' | base64 --decode)\\\"\n  password: \\\"$(kubectl get secrets -n postgres direktiv-pguser-direktiv -o 'go-template={{index .data \"password\"}}' | base64 --decode)\\\"\n  name: \\\"$(kubectl get secrets -n postgres direktiv-pguser-direktiv -o 'go-template={{index .data \"dbname\"}}' | base64 --decode)\\\"\n  sslmode: require\" &gt; direktiv.yaml\n</code></pre> <pre><code>helm install -f direktiv.yaml direktiv direktiv/direktiv\n</code></pre>"},{"location":"installation/summary/#get-ip-of-direktiv","title":"Get IP of Direktiv","text":"<pre><code>kubectl get services direktiv-ingress-nginx-controller --output jsonpath='{.status.loadBalancer.ingress[0].ip}'\n</code></pre>"},{"location":"spec/TODO/","title":"Spec Documentation TODOs","text":"<ul> <li>YAML Section Inclusions:</li> <li>Logging</li> <li>Metadata </li> <li> <p>Errors</p> </li> <li> <p>Section about secrets.</p> </li> <li>Section about events.</li> <li>Section about errors &amp; error handling.</li> <li>Large section explaining the spec for containers and everything related to actions.</li> <li>Expand variables section. Explain function files and events.</li> </ul>"},{"location":"spec/instance-data/input/","title":"Workflow Input","text":"<p>When a workflow is triggered and spawns a new instance it may do so with some starting value for its instance data. Here's everything you need to know about workflow input. </p>"},{"location":"spec/instance-data/input/#api-subflow","title":"API / Subflow","text":"<p>If a workflow is invoked directly, either through the API or as a subflow to another instance, its input is passed in as-is. </p> <p>So if you call the workflow with the following input:</p> <pre><code>{\n\"msg\": \"Hello, world!\"\n}\n</code></pre> <p>Then the instance data for the workflow will, be the same:</p> <pre><code>{\n\"msg\": \"Hello, world!\"\n}\n</code></pre> <p>That is, unless the input data isn't a valid JSON object. If the input is valid JSON but not an object, as in the following example, it is wrapped within an object automatically under the property <code>.input</code>. </p> <p>So this input:</p> <pre><code>[1, 2, 3]\n</code></pre> <p>Becomes:</p> <pre><code>{\n\"input\": [1, 2, 3]\n}\n</code></pre> <p>If the input data isn't valid JSON at all, it is treated as binary data. Binary data is converted into a base64 encoded string and passed into the instance the same way as above.</p> <p>This input:</p> <pre><code>Hello, world!\n</code></pre> <p>Becomes:</p> <pre><code>{\n\"input\": \"SGVsbG8sIHdvcmxkIQo=\"\n}\n</code></pre> <p>This treatment of binary data allows workflows to handle non-JSON inputs. Common examples include XML and form data. Just use a function to extract the information needed from these other formats and convert them to JSON.</p> <p>One thing to keep in mind that might trip you up: if you provide no input data whatsoever that's not valid JSON. It is valid binary data, which means this input:</p> <pre><code>\n</code></pre> <p>Becomes:</p> <pre><code>{\n\"input\": \"\"\n}\n</code></pre> <p>An empty string is a valid base64 representation of zero bytes.</p>"},{"location":"spec/instance-data/input/#cron","title":"CRON","text":"<p>By their nature, scheduled workflows have empty input. They will always be:</p> <pre><code>{}\n</code></pre> <p>This doesn't mean they have to do exactly the same thing each time, it just means you need to get a little creative. For example, begin your workflow by loading data from variables or by using an action that grabs data from an external source.</p>"},{"location":"spec/instance-data/input/#cloudevents-events","title":"CloudEvents Events","text":"<p>Workflows that are triggered by receiving one or more events will include the received event(s) in their input data. Each received event will appear in the instance data under a property with the same value as their event type, to allow workflows to distinguish between events.</p> <p>For an instance triggered with the following event:</p> <pre><code>{\n\"specversion\" : \"1.0\",\n\"type\" : \"com.github.pull.create\",\n\"source\" : \"https://github.com/cloudevents/spec/pull\",\n\"subject\" : \"123\",\n\"id\" : \"A234-1234-1234\",\n\"time\" : \"2018-04-05T17:31:00Z\",\n\"comexampleextension1\" : \"value\",\n\"comexampleothervalue\" : 5,\n\"datacontenttype\" : \"text/xml\",\n\"data\" : \"&lt;much wow=\\\"xml\\\"/&gt;\"\n}\n</code></pre> <p>The instance input data becomes:</p> <pre><code>{\n\"com.github.pull.create\": {\n\"specversion\" : \"1.0\",\n\"type\" : \"com.github.pull.create\",\n\"source\" : \"https://github.com/cloudevents/spec/pull\",\n\"subject\" : \"123\",\n\"id\" : \"A234-1234-1234\",\n\"time\" : \"2018-04-05T17:31:00Z\",\n\"comexampleextension1\" : \"value\",\n\"comexampleothervalue\" : 5,\n\"datacontenttype\" : \"text/xml\",\n\"data\" : \"&lt;much wow=\\\"xml\\\"/&gt;\"\n}\n}\n</code></pre> <p>If an event's payload is JSON it should be directly addressable, rather than being embedded within a string.</p>"},{"location":"spec/instance-data/input/#large-inputs","title":"Large Inputs","text":"<p>Like instance data, input data has size limits. These size limits are usually the same, but not necessarily. This will vary according to the configuration of each Direktiv installation, and is usually about 128 MiB. </p>"},{"location":"spec/instance-data/instance-data/","title":"Instance Data","text":"<p>Every workflow instance has its own instance data, which is data that is exclusively accessible to the instance, and only changeable by the instance. </p>"},{"location":"spec/instance-data/instance-data/#json-objects","title":"JSON Objects","text":"<p>Instance data is represented in JSON form, and is always a valid JSON object. This detail is important because it means that not everything that is valid JSON can be valid instance data. </p> <p>This is valid instance data:</p> <pre><code>{}\n</code></pre> <p>So is this:</p> <pre><code>{\n\"list\": [1, 2, 3]\n}\n</code></pre> <p>And this:</p> <pre><code>{\n\"a\": 5,\n\"b\": \"6\",\n\"c\": true,\n\"d\": {\n\"list\": [7, \"8\"]\n}\n}\n</code></pre> <p>But this are not valid instance data, even though it is valid JSON:</p> <pre><code>true\n</code></pre> <p>Neither is this:</p> <pre><code>\"Hello, world!\"\n</code></pre> <p>Nor is this:</p> <pre><code>[{\n\"a\": 5\n}]\n</code></pre> <p>Another way of looking at it: it's not valid instance data unless it's valid JSON beginning with <code>{</code> and ending with <code>}</code>.</p>"},{"location":"spec/instance-data/instance-data/#size-limit","title":"Size Limit","text":"<p>The size of instance data is measured in terms of the length (in bytes) of its JSON representation. For technical reasons, there is an enforced upper limit allowed for this maximum size. This limit can vary according to the specific configuration of a Direktiv installation, but the default is 128 MiB.</p>"},{"location":"spec/instance-data/instance-data/#lifecycle","title":"Lifecycle","text":"<p>The starting value for an instance's data is set based on what triggered the workflow to spawn a new instance. See Workflow Input.</p> <p>Afterwards, the instance may manipulate the data in predictable ways according to the instructions in the workflow definition. The main way to change instance data is through Transforms. </p> <p>Other operations can also contribute to the instance data. Actions may return results, error handling may save error information, event listeners save received events, and variable getters can retrieve data saved elsewhere and add it to the instance data.</p> <p>After the final operation of an instance is executed the instance data becomes the instance's output data. See Instance Output. Output data is viewable by the API, and is also returned to the caller if the instance was executed as a subflow to another workflow.</p>"},{"location":"spec/instance-data/output/","title":"Instance Output","text":"<p>Unlike instance data, which is not accessible to anything other than the instance itself, instance output is exposed via API. It is also returned to caller instance if the workflow was invoked as a subflow. </p> <p>When an instance completes it saves its instance data as its output, which indirectly exposes the instance data. Normally this is the desired behaviour, but it can present a security risk if handled incorrectly. </p> <p>Workflows should take steps to trim things they don't mean to return before terminating using transforms.</p>"},{"location":"spec/instance-data/output/#large-outputs","title":"Large Outputs","text":"<p>Like instance data, output data has size limits. These size limits are usually the same, but not necessarily. This will vary according to the configuration of each Direktiv installation, and is usually about 128 MiB. </p>"},{"location":"spec/instance-data/security/","title":"Security","text":"<p>There are a number of security concerns to keep in mind with instance data:</p>"},{"location":"spec/instance-data/security/#input-output-data-is-remembered","title":"Input &amp; Output Data Is Remembered","text":"<p>A copy of the starting value is saved separately so that instances can be replayed. It also helps to debug workflows. It is worth keeping this in mind. Even if your workflow deletes sensitive fields, they are still stored somewhere they could be reused or read later. </p> <p>Likewise, output data is saved. It is returned to parent instances if the instance was executed as a subflow. Both input and output data is requestable via API. For a good way to handle most sensitive data, consider using secrets.</p>"},{"location":"spec/instance-data/security/#input-validation","title":"Input Validation","text":"<p>To protect your workflows from behaving in unexpected ways, including intentional exploits by attackers, it is good practice to validate your input data before acting upon it. That is why we recommend beginning every workflow with a validate state.</p>"},{"location":"spec/instance-data/security/#private","title":".private","text":"<p>As a basic precaution, anything stored under <code>.private</code> is redacted over the APIs that retrieve instance input and output data. This data is still usable by the instance. Could still be returned to a parent instance. It is still stored in the database in plaintext. And there is nothing preventing you from transforming it or passing it somewhere that exposes this information. Use this feature with caution. </p>"},{"location":"spec/instance-data/structured-jx/","title":"Structured JX","text":"<p>Many fields of the workflow definition are described as \"Structured JX\". That's a name we use for fields that support complex and powerful query logic that we'll describe in greater detail here.</p>"},{"location":"spec/instance-data/structured-jx/#jq","title":"JQ","text":"<p>Since instance data is represented as JSON, the most natural way to work with that data is with the powerful JSON query language called jq. </p> <p>Whenever a string appears within a Structured JX field that includes <code>jq(...)</code>, everything between the brackets is evaluated as a jq query against the instance data. Then the entire <code>jq(...)</code> part is replaced by the results of that query. </p> <p>Note: YAML allows for strings without quotation marks, but this should be avoided when using Structured JX. The characters in the queries will commonly be interpreted in unintended ways by the YAML parser.</p> <p>If the <code>jq(...)</code> part constitutes the entirety of the string then the entire string is replaced by whatever data type was returned. If not, the results are marshalled into a JSON string and substituted into the parent string. </p> <p>The one exception to this rule is if the returned data type is a string, in which case it is substituted as-is without marshalling into JSON. This enables you to build strings without filling them with quotation marks.</p>"},{"location":"spec/instance-data/structured-jx/#example-1","title":"Example 1","text":"Instance Data<pre><code>{\n\"a\": [1, 2, 3]\n}\n</code></pre> Structured JX<pre><code>'jq(.a)'\n</code></pre> Evaluated Result<pre><code>[1, 2, 3]\n</code></pre>"},{"location":"spec/instance-data/structured-jx/#example-2","title":"Example 2","text":"Instance Data<pre><code>{\n\"a\": [1, 2, 3]\n}\n</code></pre> Structured JX<pre><code>'a: jq(.a)'\n</code></pre> Evaluated Result<pre><code>\"a: [1, 2, 3]\"\n</code></pre>"},{"location":"spec/instance-data/structured-jx/#example-3","title":"Example 3","text":"Instance Data<pre><code>{\n\"a\": \"hello\"\n}\n</code></pre> Structured JX<pre><code>'a: jq(.a)'\n</code></pre> Evaluated Result<pre><code>\"a: hello\"\n</code></pre>"},{"location":"spec/instance-data/structured-jx/#js","title":"JS","text":"<p>JQ isn't the only option available to interact with the instance data. Javascript is also supported using <code>js(...)</code> in a very similar way. Entire Javascript scripts can be embedded in strings within Structured JX.</p> <p>Note: YAML supports several ways of including large or multi-line strings. But each of these ways is treated a little bit differently by the YAML parser. To preserve newlines, we recommend using the <code>|</code> form. With Javascript this often necessary. </p> <p>When writing scripts this way, the instance data is copied and exposed to the script in an object called <code>data</code>. </p>"},{"location":"spec/instance-data/structured-jx/#example-1_1","title":"Example 1","text":"JQ<pre><code>transform: 'jq({x: 5})'\n</code></pre> Analogous Javascript<pre><code>transform: |\njs(\nitems = new Object()\nitems.x = 5\nreturn items\n)\n</code></pre>"},{"location":"spec/instance-data/structured-jx/#example-2_1","title":"Example 2","text":"JQ<pre><code>transform: 'jq({x: .a})'\n</code></pre> Analogous Javascript<pre><code>transform: |\njs(\nitems = new Object()\nitems.x = data['a']\nreturn items\n)\n</code></pre>"},{"location":"spec/instance-data/structured-jx/#yaml","title":"YAML","text":"<p>So far we've seen how you can use jq or Javascript to produce a value for your Structured JX field, but it's also possible to use neither, or both. </p> <p>The \"Structured\" part of Structured JX is so named because you don't have to provide a single string. You can provide any type of data you like. The entirety of what is provided will be converted from its YAML representation to a JSON representation. And then every field within will be searched recursively for embedded jq/Javascript. </p>"},{"location":"spec/instance-data/structured-jx/#example","title":"Example","text":"Instance Data Before Transform<pre><code>{\n\"a\": [1, 2, 3]\n}\n</code></pre> Transform<pre><code>tranform:\nx: 'jq(.a)'\ny: |\njs(\nvar output = data['a'].map((x) =&gt; {return ++x;})\nreturn output\n)\nz: 5\nlistA: [\"a\", \"b\", \"c\"]\nlistB:\n- d\n- e\n- f\nobj:\ni: 10\nj: 'jq(.a[2])'\n</code></pre> Evaluated Result<pre><code>{\n\"listA\": [\"a\", \"b\", \"c\"],\n\"listB\": [\"d\", \"e\", \"f\"],\n\"obj\": {\n\"i\": 10,\n\"j\": 3\n},\n\"x\": [1, 2, 3],\n\"y\": [2, 3, 4],\n\"z\": 5\n}\n</code></pre>"},{"location":"spec/instance-data/transforms/","title":"Transforms","text":"<p>Whenever an instance finishes executing a state there is an opportunity to perform a Transform. Usually with a field called <code>transform</code>, but sometimes in other forms. The <code>switch</code> state also has a <code>defaultTransform</code>, for example. </p> <p>All transforms use structured jx, giving you powerful options to enrich, sanitize, or modify instance data. All transforms must produce output that remains valid instance data, otherwise an error will be thrown: <code>direktiv.jq.notObject</code>.</p>"},{"location":"spec/instance-data/transforms/#examples","title":"Examples","text":"<p>Here are some common use-case helpful examples of transforms.</p>"},{"location":"spec/instance-data/transforms/#completely-replacing-instance-data","title":"Completely Replacing Instance Data","text":"Instance Data Before Transform<pre><code>{\n\"msg\": \"Hello, world!\n}\n</code></pre> Transform Snippet<pre><code>- id: snippet\ntype: noop\ntransform: x: 5\n</code></pre> Instance Data After Transform<pre><code>{\n\"x\": 5\n}\n</code></pre>"},{"location":"spec/instance-data/transforms/#replacing-a-subset-of-instance-data","title":"Replacing A Subset Of Instance Data","text":"Instance Data Before Transform<pre><code>{\n\"a\": 1,\n\"b\": 2,\n\"c\": 3\n}\n</code></pre> Transform Snippet<pre><code>- id: snippet\ntype: noop\ntransform: 'jq(.a = 5 | .b = 6)'\n</code></pre> Instance Data After Transform<pre><code>{\n\"a\": 5,\n\"b\": 6,\n\"c\": 3\n}\n</code></pre>"},{"location":"spec/instance-data/transforms/#deleteing-a-subset-of-instance-data","title":"Deleteing A Subset of Instance Data","text":"Instance Data Before Transform<pre><code>{\n\"a\": 1,\n\"b\": 2,\n\"c\": 3\n}\n</code></pre> Transform Snippet<pre><code>- id: snippet\ntype: noop\ntransform: 'jq(del(.a) | del(.b))'\n</code></pre> Instance Data After Transform<pre><code>{\n\"c\": 3\n}\n</code></pre>"},{"location":"spec/instance-data/transforms/#adding-a-new-value","title":"Adding A New Value.","text":"Instance Data Before Transform<pre><code>{\n\"a\": 1\n}\n</code></pre> Transform Snippet<pre><code>- id: snippet\ntype: noop\ntransform: 'jq(.b = 2)'\n</code></pre> Instance Data After Transform<pre><code>{\n\"a\": 1,\n\"b\": 2\n}\n</code></pre>"},{"location":"spec/instance-data/transforms/#renaming-a-subset-of-instance-data","title":"Renaming A Subset of Instance Data","text":"Instance Data Before Transform<pre><code>{\n\"a\": 1,\n\"b\": 2,\n\"c\": 3\n}\n</code></pre> Transform Snippet<pre><code>- id: snippet\ntype: noop\ntransform: 'jq(.x = .a | del(.a))'\n</code></pre> Instance Data After Transform<pre><code>{\n\"b\": 2,\n\"c\": 3,\n\"x\": 1\n}\n</code></pre>"},{"location":"spec/variables/system/","title":"System Variables","text":"<p>In addition to the standard scopes, there is a special <code>system</code> scope. This scope is a utility to make miscellaneous information accessible to an instance. The following special variables exist in the system scope:</p> Key Description instance Returns the instance ID of the running instance. uuid Returns a randomly generated UUID. epoch Returns the current time in unix/epoch format."},{"location":"spec/variables/variables/","title":"Variables","text":"<p>Direktiv can store data separately to instance data. An instance can read and change its instance data at will so you might wonder why this separation needs to exist, but it turns out variables solve a number of problems: </p> <ul> <li>Efficiently passing around large datasets or files to actions, especially ones that exceed instance data size limits. </li> <li>Persisting data between instances of a workflow.</li> <li>Sharing data between different workflows.</li> </ul>"},{"location":"spec/variables/variables/#scopes","title":"Scopes","text":"<p>All variables belong to a scope. The scopes are <code>instance</code>, <code>workflow</code>, and <code>namespace</code>. Instance scoped variables are only accessible to the singular instance that created them. Workflow scoped variables can be used and shared between multiple instances of the same workflow. Namespace scoped variables are available to all instances of all workflows on the namespace. All variables are identified by a name, and each name is unique within its scope. </p>"},{"location":"spec/variables/variables/#states","title":"States","text":"<p>Two types of states in the workflow spec interact directly with variables: <code>getter</code> and <code>setter</code>.</p>"},{"location":"spec/variables/variables/#files","title":"Files","text":"<p>Due to size limitations on action inputs and instance data it can sometimes be impossible to pass data to actions without using variables. Actions can interact with variables directly, loading them onto their file-system and sometimes creating/changing variables as well. </p>"},{"location":"spec/workflow-yaml/action/","title":"Action State","text":"<pre><code>- id: a\ntype: action\naction:\nfunction: myfunc\ninput: 'jq(.x)'\n</code></pre>"},{"location":"spec/workflow-yaml/action/#actionstatedefinition","title":"ActionStateDefinition","text":"<p>The <code>action</code> state is the simplest and most common way to call a function or invoke a workflow to act as a subflow. See Actions. </p> Parameter Description Type Required <code>type</code> Identifies which kind of StateDefinition is being used. In this case it must be set to <code>action</code>. string yes <code>id</code> An identifier unique within the workflow to this one state. string yes <code>log</code> If defined, the workflow will generate a log when it commences this state. See StateLogging. Structured JQ no <code>metadata</code> If defined, updates the instance's metadata. See InstanceMetadata. Structured JQ no <code>transform</code> If defined, modifies the instance's data upon completing the state logic. See StateTransforms. Structured JQ no <code>transition</code> Identifies which state to transition to next, referring to the next state's unique <code>id</code>. If undefined, this state terminates the workflow. string no <code>catch</code> Defines behaviour for handling of catchable errors. []ErrorCatchDefinition no <code>timeout</code> ISO8601 duration string to set a non-default timeout. string no <code>async</code> If set to <code>true</code>, the workflow execution will continue without waiting for the action to return. boolean no <code>action</code> Defines the action to perform. ActionDefinition yes"},{"location":"spec/workflow-yaml/actions/","title":"Actions","text":"<pre><code>- id: a\ntype: action\naction:\nfunction: myfunc\ninput: 'jq(.x)'\n</code></pre>"},{"location":"spec/workflow-yaml/actions/#actiondefinition","title":"ActionDefinition","text":"Parameter Description Type Required <code>function</code> Name of the referenced function. See FunctionDefinition. string yes <code>input</code> Selects or generates the data to send as input to the function. Structured JQ no <code>secrets</code> Defines a list of secrets to temporarily add to the instance data under <code>.secrets</code>, before evaluating the <code>input</code>. []string no <code>retries</code> []RetryPolicyDefinition no <code>files</code> Determines a list of files to load onto the function's file-system from variables. Only valid if the referenced function supports it. []FunctionFileDefinition no"},{"location":"spec/workflow-yaml/actions/#retrypolicydefinition","title":"RetryPolicyDefinition","text":"<pre><code>- id: a\ntype: action\naction:\nfunction: myfunc\ninput: 'jq(.x)'\nretries:\ncodes: [\".*\"]\nmax_attempts: 3\ndelay: PT3S\nmultiplier: 1.5\n</code></pre> Parameter Description Type Required codes A list of \"glob\" patterns that will be compared to catchable error codes returned by the function to determine if this retry policy applies. []string yes max_attempts Maximum number of retry attempts. If the function has been retried this many times or more when this policy is invoked the retry will be skipped, and instead the error will be escalated to the state's error handling logic. integer yes delay ISO8601 duration string giving a time delay between retry attempts. string no multiplier Value by which the delay is multiplied after each attempt. float no"},{"location":"spec/workflow-yaml/actions/#functionfiledefinition","title":"FunctionFileDefinition","text":"<pre><code>- id: a\ntype: action\naction:\nfunction: myfunc\ninput: 'jq(.x)'\nfiles:\n- key: VAR_A scope: namespace\nas: a\n</code></pre> <p>Some function types support loading variable directly from storage onto their file-systems. This object defines what variable to load and what to save it as.</p> Parameter Description Type Required <code>key</code> Identifies which variable to load into a file. string yes <code>scope</code> Specifies the scope from which to load the variable. VariableScopeDefinition no <code>as</code> Names the resulting file. If left unspecified, the <code>key</code> will be used instead. string no"},{"location":"spec/workflow-yaml/actions/#variablescopedefinition","title":"VariableScopeDefinition","text":"<p>Every variable exists within a single scope. The scope dictates what can access it and how persistent it is. There are three defined scopes:</p> <ul> <li><code>instance</code></li> <li><code>workflow</code></li> <li><code>namespace</code></li> </ul>"},{"location":"spec/workflow-yaml/consume-event/","title":"ConsumeEvent State","text":"<pre><code>- id: a\ntype: consumeEvent\ntimeout: PT15M\nevent:\ntype: com.github.pull.create\ncontext:\nsubject: '123'\n</code></pre>"},{"location":"spec/workflow-yaml/consume-event/#consumeeventstatedefinition","title":"ConsumeEventStateDefinition","text":"<p>To pause the workflow and wait until a CloudEvents event is received before proceeding, the <code>consumeEvent</code> is the simplest state that can be used. It is one of three states that can do so, along with <code>eventsAnd</code> and <code>eventsXor</code>.</p> Parameter Description Type Required <code>type</code> Identifies which kind of StateDefinition is being used. In this case it must be set to <code>consumeEvent</code>. string yes <code>id</code> An identifier unique within the workflow to this one state. string yes <code>log</code> If defined, the workflow will generate a log when it commences this state. See StateLogging. Structured JQ no <code>metadata</code> If defined, updates the instance's metadata. See InstanceMetadata. Structured JQ no <code>transform</code> If defined, modifies the instance's data upon completing the state logic. See StateTransforms. Structured JQ no <code>transition</code> Identifies which state to transition to next, referring to the next state's unique <code>id</code>. If undefined, this state terminates the workflow. string no <code>catch</code> Defines behaviour for handling of catchable errors. []ErrorCatchDefinition no <code>timeout</code> An ISO8601 duration string. string no <code>event</code> Defines the criteria by which incoming CloudEvents events are evaluated to find a match. ConsumeEventDefinition yes"},{"location":"spec/workflow-yaml/consume-event/#consumeeventdefinition","title":"ConsumeEventDefinition","text":"<p>The StartEventDefinition is a structure shared by various event-consuming states. </p> Parameter Description Type Required <code>type</code> Identifies which CloudEvents events can trigger the workflow by requiring an exact match to the event's own <code>type</code> context value. string yes <code>context</code> Optional key-value pairs to further restrict what events can trigger the workflow. For each pair, incoming CloudEvents context values will be checked for a match. All pairs must find a match for the event to be accepted. The \"keys\" must be strings that match exactly to specific context keys, but the \"values\" can be \"glob\" patterns allowing them to match a range of possible context values. Structured JQ no <p>The received data of an event-triggered workflow is a JSON representation of all the received events stored under keys matching the events' respective type. For example, this CloudEvents event will result in the following data:</p> CloudEvents Event<pre><code>{\n\"specversion\" : \"1.0\",\n\"type\" : \"com.github.pull.create\",\n\"source\" : \"https://github.com/cloudevents/spec/pull\",\n\"subject\" : \"123\",\n\"id\" : \"A234-1234-1234\",\n\"time\" : \"2018-04-05T17:31:00Z\",\n\"comexampleextension1\" : \"value\",\n\"comexampleothervalue\" : 5,\n\"datacontenttype\" : \"text/xml\",\n\"data\" : \"&lt;much wow=\\\"xml\\\"/&gt;\"\n}\n</code></pre> Input Data<pre><code>{\n\"com.github.pull.create\": {\n\"specversion\" : \"1.0\",\n\"type\" : \"com.github.pull.create\",\n\"source\" : \"https://github.com/cloudevents/spec/pull\",\n\"subject\" : \"123\",\n\"id\" : \"A234-1234-1234\",\n\"time\" : \"2018-04-05T17:31:00Z\",\n\"comexampleextension1\" : \"value\",\n\"comexampleothervalue\" : 5,\n\"datacontenttype\" : \"text/xml\",\n\"data\" : \"&lt;much wow=\\\"xml\\\"/&gt;\"\n}\n}\n</code></pre>"},{"location":"spec/workflow-yaml/delay/","title":"Delay State","text":"<pre><code>- id: a\ntype: delay\nduration: PT10S\n</code></pre>"},{"location":"spec/workflow-yaml/delay/#delaystatedefinition","title":"DelayStateDefinition","text":"<p>If the workflow needs to pause for a specific length of time, the delay state is usually the simplest way to do that.</p> Parameter Description Type Required <code>type</code> Identifies which kind of StateDefinition is being used. In this case it must be set to <code>delay</code>. string yes <code>id</code> An identifier unique within the workflow to this one state. string yes <code>log</code> If defined, the workflow will generate a log when it commences this state. See StateLogging. Structured JQ no <code>metadata</code> If defined, updates the instance's metadata. See InstanceMetadata. Structured JQ no <code>transform</code> If defined, modifies the instance's data upon completing the state logic. See StateTransforms. Structured JQ no <code>transition</code> Identifies which state to transition to next, referring to the next state's unique <code>id</code>. If undefined, this state terminates the workflow. string no <code>catch</code> Defines behaviour for handling of catchable errors. []ErrorCatchDefinition no <code>duration</code> An ISO8601 duration string. string yes"},{"location":"spec/workflow-yaml/error/","title":"Error State","text":"<pre><code>- id: a\ntype: error\nerror: badinput\nmessage: 'Missing or invalid value for required input.'\n</code></pre>"},{"location":"spec/workflow-yaml/error/#errorstatedefinition","title":"ErrorStateDefinition","text":"<p>When workflow logic end up in a failure mode, the <code>error</code> state can be used to mark the instance as failed. This allows the instance to report what went wrong to the caller, which may then be handled or reported appropriately.</p> Parameter Description Type Required <code>type</code> Identifies which kind of StateDefinition is being used. In this case it must be set to <code>error</code>. string yes <code>id</code> An identifier unique within the workflow to this one state. string yes <code>log</code> If defined, the workflow will generate a log when it commences this state. See StateLogging. Structured JQ no <code>metadata</code> If defined, updates the instance's metadata. See InstanceMetadata. Structured JQ no <code>transform</code> If defined, modifies the instance's data upon completing the state logic. See StateTransforms. Structured JQ no <code>transition</code> Identifies which state to transition to next, referring to the next state's unique <code>id</code>. If undefined, this state terminates the workflow. string no <code>catch</code> Defines behaviour for handling of catchable errors. []ErrorCatchDefinition no <code>error</code> A short descriptive error code that can be caught by a parent workflow. string yes <code>message</code> Generates a more detailed message or object that can contain instance data, to provide more information for users. Structured JQ yes"},{"location":"spec/workflow-yaml/errors/","title":"Errors","text":"<p>Errors can happen for many reasons. Direktiv allows you to catch and handle these errors using a common field 'catch'. This field takes an array of ErrorCatchDefinition objects, each specifying one or more errors that apply and where to transition to next in order to handle them. When an error is thrown, the list of error catchers is evaluated in order until a match is found. If no match is found, the instance fails. </p> <pre><code>states:\n- id: a\ntype: consumeEvent\ntimeout: PT5S\nevent:\ntype: com.github.pull.create\ncatch: - error: \"direktiv.cancels.timeout.soft\"\ntransition: handle-error\n- id: handle-error\ntype: noop\nlog: handling error\n</code></pre>"},{"location":"spec/workflow-yaml/errors/#errorcatchdefinition","title":"ErrorCatchDefinition","text":"Parameter Description Type Required error Specified what error code(s) this catcher applies to. This should be a \"glob\" pattern that will be compared to catchable error codes to determine if this retry policy applies. string yes transition Identifies which state to transition to next, referring to the next state's unique <code>id</code>. If undefined, this state terminates the workflow. string no"},{"location":"spec/workflow-yaml/events-and/","title":"EventsAnd State","text":"<pre><code>- id: a\ntype: eventsAnd\ntimeout: PT15M\nevents:\n- type: com.github.pull.create\ncontext:\nsubject: '123'\n- type: com.github.pull.delete\ncontext:\nsubject: '123'\n</code></pre>"},{"location":"spec/workflow-yaml/events-and/#eventsandstatedefinition","title":"EventsAndStateDefinition","text":"<p>To pause the workflow and wait until multiple CloudEvents events are received before proceeding, the <code>eventsAnd</code> is used. Every listed event must be received for the state to complete. If there are multiple events of the same type a index number will be added to the duplicate cloudevent types.</p> Parameter Description Type Required <code>type</code> Identifies which kind of StateDefinition is being used. In this case it must be set to <code>eventsAnd</code>. string yes <code>id</code> An identifier unique within the workflow to this one state. string yes <code>log</code> If defined, the workflow will generate a log when it commences this state. See StateLogging. Structured JQ no <code>metadata</code> If defined, updates the instance's metadata. See InstanceMetadata. Structured JQ no <code>transform</code> If defined, modifies the instance's data upon completing the state logic. See StateTransforms. Structured JQ no <code>transition</code> Identifies which state to transition to next, referring to the next state's unique <code>id</code>. If undefined, this state terminates the workflow. string no <code>catch</code> Defines behaviour for handling of catchable errors. []ErrorCatchDefinition no <code>timeout</code> An ISO8601 duration string. string no <code>events</code> Defines the criteria by which incoming CloudEvents events are evaluated to find a match. ConsumeEventDefinition yes"},{"location":"spec/workflow-yaml/events-xor/","title":"EventsXor State","text":"<pre><code>- id: a\ntype: eventsXor\ntimeout: PT15M\nevents:\n- event:\ntype: com.github.pull.create\ncontext:\nsubject: '123'\n- event:\ntype: com.github.pull.delete\ncontext:\nsubject: '123'\n</code></pre>"},{"location":"spec/workflow-yaml/events-xor/#eventsxorstatedefinition","title":"EventsXorStateDefinition","text":"<p>To pause the workflow and wait until one of multiple CloudEvents events is received before proceeding, the <code>eventsXor</code> state might be used. Any event match received will cause this state to complete.</p> Parameter Description Type Required <code>type</code> Identifies which kind of StateDefinition is being used. In this case it must be set to <code>eventsXor</code>. string yes <code>id</code> An identifier unique within the workflow to this one state. string yes <code>log</code> If defined, the workflow will generate a log when it commences this state. See StateLogging. Structured JQ no <code>metadata</code> If defined, updates the instance's metadata. See InstanceMetadata. Structured JQ no <code>transform</code> If defined, modifies the instance's data upon completing the state logic. See StateTransforms. Structured JQ no <code>transition</code> Identifies which state to transition to next, referring to the next state's unique <code>id</code>. If undefined, this state terminates the workflow. string no <code>catch</code> Defines behaviour for handling of catchable errors. []ErrorCatchDefinition no <code>timeout</code> An ISO8601 duration string. string no <code>events</code> Defines the criteria by which incoming CloudEvents events are evaluated to find a match. ConsumeEventDefinition yes"},{"location":"spec/workflow-yaml/foreach/","title":"Foreach State","text":"<pre><code>- id: data\ntype: noop\ntransform:\nnames:\n- hello\n- world\ntransition: a\n- id: a\ntype: foreach\narray: 'jq([.names[] | {name: .}])'\naction:\nfunction: echo\ninput: 'jq(.name)'\n</code></pre>"},{"location":"spec/workflow-yaml/foreach/#foreachstatedefinition","title":"ForeachStateDefinition","text":"<p>The <code>foreach</code> state is a convenient way to divide some data and then perform an action on each element in parallel. </p> Parameter Description Type Required <code>type</code> Identifies which kind of StateDefinition is being used. In this case it must be set to <code>foreach</code>. string yes <code>id</code> An identifier unique within the workflow to this one state. string yes <code>log</code> If defined, the workflow will generate a log when it commences this state. See StateLogging. Structured JQ no <code>metadata</code> If defined, updates the instance's metadata. See InstanceMetadata. Structured JQ no <code>transform</code> If defined, modifies the instance's data upon completing the state logic. See StateTransforms. Structured JQ no <code>transition</code> Identifies which state to transition to next, referring to the next state's unique <code>id</code>. If undefined, this state terminates the workflow. string no <code>catch</code> Defines behaviour for handling of catchable errors. []ErrorCatchDefinition no <code>timeout</code> ISO8601 duration string to set a non-default timeout. string no <code>array</code> Selects or generates an array, from which each element will be separately acted upon. The <code>action.input</code> will be evaluated against each element in this array, rather than the usual instance data. Structured JQ yes <code>action</code> Defines the action to perform. ActionDefinition yes"},{"location":"spec/workflow-yaml/functions/","title":"Functions","text":""},{"location":"spec/workflow-yaml/functions/#functiondefinition","title":"FunctionDefinition","text":"<p>Functions refer to anything executable by Direktiv as a unit of logic within a subflow that isn't otherwise part of basic state functionality. Usually this means either a purpose-built container or another workflow executed as a subflow. In some cases functions can be extensively configured, and they are often reused repeatedly within a workflow. To manage the size of Direktiv workflow definitions functions are predefined as much as possible and referenced when called.</p> <p>These are the currently available function types:</p> <ul> <li>Functions</li> <li>FunctionDefinition<ul> <li>NamespacedKnativeFunctionDefinition</li> <li>WorkflowKnativeFunctionDefinition</li> <li>ContainerSizeDefinition</li> <li>SubflowFunctionDefinition</li> </ul> </li> </ul> <p>The following example demonstrate how to define and reference a function within a workflow:</p> Workflow<pre><code>description: |\nA basic demonstration of functions.\nfunctions:\n- type: knative-workflow\nid: request\nimage: direktiv/request:latest\nsize: small\nstates:\n- id: getter\ntype: action\naction:\nfunction: request\ninput:\nmethod: \"GET\"\nurl: \"https://jsonplaceholder.typicode.com/todos/1\"\n</code></pre> Input<pre><code>{}\n</code></pre> Output<pre><code>{\n\"return\": {\n\"userId\": 1,\n\"id\": 1,\n\"title\": \"delectus aut autem\",\n\"completed\": false\n}\n}\n</code></pre>"},{"location":"spec/workflow-yaml/functions/#namespacedknativefunctiondefinition","title":"NamespacedKnativeFunctionDefinition","text":"<p>A <code>knative-namespace</code> refers to a function that is implemented according to the requirements for a direktiv knative service. Specifically, in this case referring to a service configured to be available on the namespace.</p> <p>This function type supports <code>files</code>.</p> Parameter Description Type Required <code>type</code> Identifies which kind of FunctionDefinition is being used. In this case it must be set to <code>knative-namespace</code>. string yes <code>id</code> A unique identifier for the function within the workflow definition. string yes <code>service</code> URI to a function on the namespace. string yes"},{"location":"spec/workflow-yaml/functions/#workflowknativefunctiondefinition","title":"WorkflowKnativeFunctionDefinition","text":"<p>A <code>knative-workflow</code> refers to a function that is implemented according to the requirements for a direktiv knative service. Specifically, in this case referring to a service that Direktiv can create on-demand for the exclusive use by this workflow.</p> <p>This function type supports <code>files</code>.</p> Parameter Description Type Required <code>type</code> Identifies which kind of FunctionDefinition is being used. In this case it must be set to <code>knative-workflow</code>. string yes <code>id</code> A unique identifier for the function within the workflow definition. string yes <code>image</code> URI to a <code>knative-workflow</code> compliant container. string yes <code>size</code> Specifies the container size. ContainerSizeDefinition no <code>cmd</code> Custom command to execute within the container. string no"},{"location":"spec/workflow-yaml/functions/#containersizedefinition","title":"ContainerSizeDefinition","text":"<p>When functions use containers you may be able to specify what size the container should be. This is done using one of three keywords, each representing a different size preset defined in Direktiv's configuration files:</p> <ul> <li><code>small</code></li> <li><code>medium</code></li> <li><code>large</code></li> </ul>"},{"location":"spec/workflow-yaml/functions/#subflowfunctiondefinition","title":"SubflowFunctionDefinition","text":"<p>A <code>subflow</code> refers to a function that is actually another workflow. The other workflow is called with some input and its output is returned to this workflow.</p> <p>This function type does not support <code>files</code>.</p> Parameter Description Type Required <code>type</code> Identifies which kind of FunctionDefinition is being used. In this case it must be set to <code>subflow</code>. string yes <code>id</code> A unique identifier for the function within the workflow definition. string yes <code>workflow</code> URI to a workflow within the same namespace. string yes"},{"location":"spec/workflow-yaml/generate-event/","title":"GenerateEvent State","text":"<pre><code>- id: a\ntype: generateEvent\nevent:\ntype: myeventtype\nsource: myeventsource\ndata: hello: world\ndatacontenttype: application/json\n</code></pre>"},{"location":"spec/workflow-yaml/generate-event/#generateeventstatedefinition","title":"GenerateEventStateDefinition","text":"Parameter Description Type Required <code>type</code> Identifies which kind of StateDefinition is being used. In this case it must be set to <code>generateEvent</code>. string yes <code>id</code> An identifier unique within the workflow to this one state. string yes <code>log</code> If defined, the workflow will generate a log when it commences this state. See StateLogging. Structured JQ no <code>metadata</code> If defined, updates the instance's metadata. See InstanceMetadata. Structured JQ no <code>transform</code> If defined, modifies the instance's data upon completing the state logic. See StateTransforms. Structured JQ no <code>transition</code> Identifies which state to transition to next, referring to the next state's unique <code>id</code>. If undefined, this state terminates the workflow. string no <code>catch</code> Defines behaviour for handling of catchable errors. []ErrorCatchDefinition no <code>delay</code> ISO8601 duration string defining how long to hold the event before broadcasting it. string no <code>event</code> Defines the event to generate. GenerateEventDefinition yes"},{"location":"spec/workflow-yaml/generate-event/#generateeventdefinition","title":"GenerateEventDefinition","text":"Parameter Description Type Required <code>type</code> Sets the CloudEvents event type. string yes <code>source</code> Sets the CloudEvents event source. string yes <code>data</code> Defines the content of the payload for the CloudEvents event. Structured JQ no <code>datacontenttype</code> An RFC2046 string specifying the payload content type. string no <code>context</code> If defined, must evaluate to an object of key-value pairs. These will be used to define CloudEvents event context data. Structured JQ no"},{"location":"spec/workflow-yaml/getter/","title":"Getter State","text":"<pre><code>- id: a\ntype: setter\nvariables:\n- key: x scope: workflow\nmimeType: application/json\nvalue: Hello World\ntransition: b\n- id: b\ntype: getter\nvariables:\n- key: x scope: workflow\n</code></pre>"},{"location":"spec/workflow-yaml/getter/#getterstatedefinition","title":"GetterStateDefinition","text":"<p>To load variables, use the <code>getter</code> state. See Variables.</p> Parameter Description Type Required <code>type</code> Identifies which kind of StateDefinition is being used. In this case it must be set to <code>getter</code>. string yes <code>id</code> An identifier unique within the workflow to this one state. string yes <code>log</code> If defined, the workflow will generate a log when it commences this state. See StateLogging. Structured JQ no <code>metadata</code> If defined, updates the instance's metadata. See InstanceMetadata. Structured JQ no <code>transform</code> If defined, modifies the instance's data upon completing the state logic. See StateTransforms. Structured JQ no <code>transition</code> Identifies which state to transition to next, referring to the next state's unique <code>id</code>. If undefined, this state terminates the workflow. string no <code>catch</code> Defines behaviour for handling of catchable errors. []ErrorCatchDefinition no <code>variables</code> Defines variables to load. []VariableGetterDefinition yes"},{"location":"spec/workflow-yaml/getter/#variablegetterdefinition","title":"VariableGetterDefinition","text":"Parameter Description Type Required <code>key</code> Variable name. Structured JQ yes <code>scope</code> Selects the scope to which the variable belongs. If undefined, defaults to <code>instance</code>. See Variables. yes no <code>as</code> Names the resulting data. If left unspecified, the <code>key</code> will be used instead. string no"},{"location":"spec/workflow-yaml/logging/","title":"Logging","text":"<p>All states can write to instance logs via a common field <code>log</code>. This field uses structured jx to support querying instance data and inserting it into the logs. </p> <pre><code>- id: a\ntype: noop\nlog: 'Hello, world!'\n</code></pre>"},{"location":"spec/workflow-yaml/metadata/","title":"Instance Metadata","text":"<p>Instance metadata is a way to monitor an instance. An instance can update its metadata at any time, replacing it with whatever information it needs to expose via the API.</p> <p>All states can write to instance metadata via a common field <code>metadata</code>. This field uses structured jx to support querying instance data and inserting it into the metadata. </p> <pre><code>states:\n- id: a\ntype: delay\nduration: PT1M\nmetadata: workflow-data: jq(.)\n</code></pre>"},{"location":"spec/workflow-yaml/noop/","title":"Noop State","text":"<pre><code>- id: a\ntype: noop\n</code></pre>"},{"location":"spec/workflow-yaml/noop/#noopstatedefinition","title":"NoopStateDefinition","text":"<p>Often workflows need to do something that can be achieved using logic built into most state types. For example, to log something, or to transform the instance data by running a <code>jq</code> command. In many cases this can be done by an existing state within the workflow, but sometimes it's necessary to split it out into a separate state. The <code>noop</code> state exists for this purpose.</p> Parameter Description Type Required <code>type</code> Identifies which kind of StateDefinition is being used. In this case it must be set to <code>noop</code>. string yes <code>id</code> An identifier unique within the workflow to this one state. string yes <code>log</code> If defined, the workflow will generate a log when it commences this state. See StateLogging. Structured JQ no <code>metadata</code> If defined, updates the instance's metadata. See InstanceMetadata. Structured JQ no <code>transform</code> If defined, modifies the instance's data upon completing the state logic. See StateTransforms. Structured JQ no <code>transition</code> Identifies which state to transition to next, referring to the next state's unique <code>id</code>. If undefined, this state terminates the workflow. string no <code>catch</code> Defines behaviour for handling of catchable errors. []ErrorCatchDefinition no"},{"location":"spec/workflow-yaml/parallel/","title":"Parallel State","text":"<pre><code>- id: a\ntype: parallel\nmode: and\nactions:\n- function: myfunc\ninput: 'jq(.x)'\n- function: myfunc\ninput: 'jq(.y)'\n</code></pre>"},{"location":"spec/workflow-yaml/parallel/#parallelstatedefinition","title":"ParallelStateDefinition","text":"<p>The <code>parallel</code> state is an alternative to the <code>action</code> state when a workflow can perform multiple threads of logic simultaneously. The values in <code>return</code> is an array of the returns of the individual actions. In mode <code>or</code> the first response is set in the array and the other actions are set to <code>null</code>.</p> Parameter Description Type Required <code>type</code> Identifies which kind of StateDefinition is being used. In this case it must be set to <code>parallel</code>. string yes <code>id</code> An identifier unique within the workflow to this one state. string yes <code>log</code> If defined, the workflow will generate a log when it commences this state. See StateLogging. Structured JQ no <code>metadata</code> If defined, updates the instance's metadata. See InstanceMetadata. Structured JQ no <code>transform</code> If defined, modifies the instance's data upon completing the state logic. See StateTransforms. Structured JQ no <code>transition</code> Identifies which state to transition to next, referring to the next state's unique <code>id</code>. If undefined, this state terminates the workflow. string no <code>catch</code> Defines behaviour for handling of catchable errors. []ErrorCatchDefinition no <code>timeout</code> ISO8601 duration string to set a non-default timeout. string no <code>mode</code> If defined, must be either <code>and</code> or <code>or</code>. The default is <code>and</code>. This setting determines whether the state is considered successfully completed only if all threads have returned without error (<code>and</code>) or as soon as any single thread returns without error (<code>or</code>). string no <code>actions</code> Defines the action to perform. []ActionDefinition yes"},{"location":"spec/workflow-yaml/setter/","title":"Setter State","text":"<pre><code>- id: a\ntype: setter\nvariables:\n- key: x scope: workflow\nmimeType: text/plain\nvalue: 'jq(.x)'\n</code></pre>"},{"location":"spec/workflow-yaml/setter/#setterstatedefinition","title":"SetterStateDefinition","text":"<p>To create or change variables, use the <code>setter</code> state. See Variables.</p> Parameter Description Type Required <code>type</code> Identifies which kind of StateDefinition is being used. In this case it must be set to <code>setter</code>. string yes <code>id</code> An identifier unique within the workflow to this one state. string yes <code>log</code> If defined, the workflow will generate a log when it commences this state. See StateLogging. Structured JQ no <code>metadata</code> If defined, updates the instance's metadata. See InstanceMetadata. Structured JQ no <code>transform</code> If defined, modifies the instance's data upon completing the state logic. See StateTransforms. Structured JQ no <code>transition</code> Identifies which state to transition to next, referring to the next state's unique <code>id</code>. If undefined, this state terminates the workflow. string no <code>catch</code> Defines behaviour for handling of catchable errors. []ErrorCatchDefinition no <code>variables</code> Defines variables to push. []VariableSetterDefinition yes"},{"location":"spec/workflow-yaml/setter/#variablesetterdefinition","title":"VariableSetterDefinition","text":"Parameter Description Type Required <code>key</code> Variable name. Structured JQ yes <code>scope</code> Selects the scope to which the variable belongs. If undefined, defaults to <code>instance</code>. See Variables. yes no <code>mimeType</code> Store a MIME type with the variable. If left undefined, it will default to <code>application/json</code>. Two specific MIME types cause this state to behave differently: <code>text/plain</code> and <code>application/octet-stream</code>. If the <code>value</code> evaluates to a JSON string the MIME type is <code>text/plain</code>, that string will be stored in plaintext (without JSON quotes and escapes). If if the <code>value</code> is a JSON string containing base64 encoded data and the MIME type is <code>application/octet-stream</code>, the base64 data will be decoded and stored as binary data. Structured JQ no <code>value</code> Select or generate the data to store. Structured JQ yes"},{"location":"spec/workflow-yaml/starts/","title":"Starts","text":""},{"location":"spec/workflow-yaml/starts/#startdefinition","title":"StartDefinition","text":"<p>A <code>StartDefinition</code> may be defined using one of the following, depending on the desired behaviour:</p> <ul> <li>Starts</li> <li>StartDefinition<ul> <li>DefaultStartDefinition</li> <li>ScheduledStartDefinition</li> <li>EventStartDefinition</li> <li>EventsXorStartDefinition</li> <li>EventsAndStartDefinition</li> <li>StartEventDefinition</li> </ul> </li> </ul> <p>If omitted from the workflow definition the DefaultStartDefinition will be used, which means the workflow will only be executed when called.</p>"},{"location":"spec/workflow-yaml/starts/#defaultstartdefinition","title":"DefaultStartDefinition","text":"<p>The default start definition is used for workflows that should only execute when called. This means subflows, workflows triggered by scripts, and workflows triggered manually by humans.</p> Parameter Description Type Required <code>type</code> Identifies which kind of StartDefinition is being used. In this case it must be set to <code>default</code>. string yes <code>state</code> References a defined state's <code>id</code>. This state will be used as the entrypoint into the workflow. If left undefined, it defaults to the first state defined in the <code>states</code> list. string no"},{"location":"spec/workflow-yaml/starts/#scheduledstartdefinition","title":"ScheduledStartDefinition","text":"<p>The scheduled start definition is used for workflows that should execute at regularly defined times. </p> <p>Scheduled workflow can be manually triggered for convenience and testing. They never have input data, so accurate testing should use <code>{}</code> as input. </p> Parameter Description Type Required <code>type</code> Identifies which kind of StartDefinition is being used. In this case it must be set to <code>scheduled</code>. string yes <code>state</code> References a defined state's <code>id</code>. This state will be used as the entrypoint into the workflow. If left undefined, it defaults to the first state defined in the <code>states</code> list. string no <code>cron</code> Defines the time(s) when the workflow should execute using a CRON expression. string yes <p>Example (snippet) <pre><code>start:\ntype: scheduled\ncron: '* * * * *' # Trigger a new instance every minute.\n</code></pre></p>"},{"location":"spec/workflow-yaml/starts/#eventstartdefinition","title":"EventStartDefinition","text":"<p>The event start definition is used for workflows that should be executed whenever a relevant CloudEvents event is received. </p> <p>See StartEventDefinition for an explanation of the input data of event-triggered workflows.</p> Parameter Description Type Required <code>type</code> Identifies which kind of StartDefinition is being used. In this case it must be set to <code>event</code>. string yes <code>state</code> References a defined state's <code>id</code>. This state will be used as the entrypoint into the workflow. If left undefined, it defaults to the first state defined in the <code>states</code> list. string no <code>event</code> Defines what events can trigger the workflow. StartEventDefinition yes"},{"location":"spec/workflow-yaml/starts/#eventsxorstartdefinition","title":"EventsXorStartDefinition","text":"<p>The event \"xor\" start definition is used for workflows that should be executed whenever one of multiple possible CloudEvents events is received. </p> <p>See StartEventDefinition for an explanation of the input data of event-triggered workflows.</p> Parameter Description Type Required <code>type</code> Identifies which kind of StartDefinition is being used. In this case it must be set to <code>eventsXor</code>. string yes <code>state</code> References a defined state's <code>id</code>. This state will be used as the entrypoint into the workflow. If left undefined, it defaults to the first state defined in the <code>states</code> list. string no <code>events</code> Defines what events can trigger the workflow. []StartEventDefinition yes"},{"location":"spec/workflow-yaml/starts/#eventsandstartdefinition","title":"EventsAndStartDefinition","text":"<p>The event \"and\" start definition is used for workflows that should be executed when multiple matching CloudEvents events are received. </p> <p>See StartEventDefinition for an explanation of the input data of event-triggered workflows.</p> Parameter Description Type Required <code>type</code> Identifies which kind of StartDefinition is being used. In this case it must be set to <code>eventsAnd</code>. string yes <code>state</code> References a defined state's <code>id</code>. This state will be used as the entrypoint into the workflow. If left undefined, it defaults to the first state defined in the <code>states</code> list. string no <code>lifespan</code> An ISO8601 duration string. Sets the maximum duration an event can be stored before being discarded while waiting for other events. string no <code>events</code> Defines what events can trigger the workflow. []StartEventDefinition yes"},{"location":"spec/workflow-yaml/starts/#starteventdefinition","title":"StartEventDefinition","text":"<p>The StartEventDefinition is a structure shared by various start definitions involving events. </p> Parameter Description Type Required <code>type</code> Identifies which CloudEvents events can trigger the workflow by requiring an exact match to the event's own <code>type</code> context value. string yes <code>context</code> Optional key-value pairs to further restrict what events can trigger the workflow. For each pair, incoming CloudEvents context values will be checked for a match. All pairs must find a match for the event to be accepted. The \"keys\" are strings that match exactly to specific context keys, but the \"values\" can be \"glob\" patterns allowing them to match a range of possible context values. object no <p>The input data of an event-triggered workflow is a JSON representation of all the received events stored under keys matching the events' respective type. For example, this CloudEvents event will result in the following input data in a workflow triggered by a single event:</p> CloudEvents Event<pre><code>{\n\"specversion\" : \"1.0\",\n\"type\" : \"com.github.pull.create\",\n\"source\" : \"https://github.com/cloudevents/spec/pull\",\n\"subject\" : \"123\",\n\"id\" : \"A234-1234-1234\",\n\"time\" : \"2018-04-05T17:31:00Z\",\n\"comexampleextension1\" : \"value\",\n\"comexampleothervalue\" : 5,\n\"datacontenttype\" : \"text/xml\",\n\"data\" : \"&lt;much wow=\\\"xml\\\"/&gt;\"\n}\n</code></pre> Input Data<pre><code>{\n\"com.github.pull.create\": {\n\"specversion\" : \"1.0\",\n\"type\" : \"com.github.pull.create\",\n\"source\" : \"https://github.com/cloudevents/spec/pull\",\n\"subject\" : \"123\",\n\"id\" : \"A234-1234-1234\",\n\"time\" : \"2018-04-05T17:31:00Z\",\n\"comexampleextension1\" : \"value\",\n\"comexampleothervalue\" : 5,\n\"datacontenttype\" : \"text/xml\",\n\"data\" : \"&lt;much wow=\\\"xml\\\"/&gt;\"\n}\n}\n</code></pre>"},{"location":"spec/workflow-yaml/states/","title":"States","text":""},{"location":"spec/workflow-yaml/states/#statedefinition","title":"StateDefinition","text":"<p>A <code>StateDefinition</code> may be defined using one of the following, depending on the desired behaviour:</p> <ul> <li><code>action</code></li> <li><code>consumeEvent</code></li> <li><code>delay</code></li> <li><code>error</code></li> <li><code>eventsAnd</code></li> <li><code>eventsXor</code></li> <li><code>foreach</code></li> <li><code>generateEvent</code></li> <li><code>getter</code></li> <li><code>noop</code></li> <li><code>parallel</code></li> <li><code>setter</code></li> <li><code>switch</code></li> <li><code>validate</code></li> </ul>"},{"location":"spec/workflow-yaml/switch/","title":"Switch State","text":"<pre><code>- id: a\ntype: switch\ndefaultTransform: 'jq(del(.x))'\ndefaultTransition: b\nconditions:\n- condition: 'jq(.y == true)'\ntransform: 'jq(.x)'\ntransition: c\n- condition: 'jq(.z == true)'\ntransform: 'jq(.x)'\ntransition: d\n</code></pre>"},{"location":"spec/workflow-yaml/switch/#switchstatedefinition","title":"SwitchStateDefinition","text":"<p>To change the behaviour of a workflow based on the instance data, use a <code>switch</code> state. This state does nothing except choose between any number of different possible state transitions.</p> Parameter Description Type Required <code>type</code> Identifies which kind of StateDefinition is being used. In this case it must be set to <code>switch</code>. string yes <code>id</code> An identifier unique within the workflow to this one state. string yes <code>log</code> If defined, the workflow will generate a log when it commences this state. See StateLogging. Structured JQ no <code>metadata</code> If defined, updates the instance's metadata. See InstanceMetadata. Structured JQ no <code>defaultTransform</code> If defined, modifies the instance's data upon completing the state logic. But only if none of the <code>conditions</code> are met. See StateTransforms. Structured JQ no <code>defaultTransition</code> Identifies which state to transition to next, referring to the next state's unique <code>id</code>. If undefined, this state terminates the workflow. But only if none of the <code>conditions</code> are met. string no <code>catch</code> Defines behaviour for handling of catchable errors. []ErrorCatchDefinition no <code>conditions</code> List of conditions, which are evaluated in-order until a match is found. []SwitchConditionDefinition yes"},{"location":"spec/workflow-yaml/switch/#switchconditiondefinition","title":"SwitchConditionDefinition","text":"Parameter Description Type Required <code>condition</code> Selects or generates the data used to determine if condition is met. The condition is considered met if the result is anything other than <code>null</code>, <code>false</code>, <code>{}</code>, <code>[]</code>, <code>\"\"</code>, or <code>0</code>. Structured JQ yes <code>transform</code> If defined, modifies the instance's data upon completing the state logic. See StateTransforms. Structured JQ no <code>transition</code> Identifies which state to transition to next, referring to the next state's unique <code>id</code>. If undefined, matching this condition terminates the workflow. string no"},{"location":"spec/workflow-yaml/timeouts/","title":"Timeouts","text":""},{"location":"spec/workflow-yaml/timeouts/#timeoutsdefinition","title":"TimeoutsDefinition","text":"<p>In addition to any timeouts applied on a state-by-state basis, every workflow has two global timeouts that begin ticking from the moment the workflow starts. This is where you can configure these timeouts differently to their defaults.</p> Parameter Description Type Required <code>interrupt</code> An ISO8601 duration string. Sets the time to wait before throwing a catchable <code>direktiv.cancels.timeout.soft</code> error. Consider this a soft timeout. string no <code>kill</code> An ISO8601 duration string. Sets the time to wait before throwing an uncatchable <code>direktiv.cancels.timeout.hard</code> error. This is a hard timeout. string no Workflow Timeout<pre><code>timeouts:\ninterrupt: PT60M\nkill: PT30M\nfunctions:\n- type: knative-workflow\nid: request\nimage: direktiv/request:latest\nsize: small\nstates:\n- id: getter\ntype: action\naction:\nfunction: request\ninput:\nmethod: \"GET\"\nurl: \"https://jsonplaceholder.typicode.com/todos/1\"\n</code></pre>"},{"location":"spec/workflow-yaml/validate/","title":"Validate State","text":"<pre><code>- id: a\ntype: validate\nschema:\ntitle: Files\ntype: object\nproperties:\nfirstname:\ntype: string\ndescription: Your first name\ntitle: First Name\n</code></pre>"},{"location":"spec/workflow-yaml/validate/#validatestatedefinition","title":"ValidateStateDefinition","text":"<p>Since workflows receive external input it may be necessary to check that instance data is valid. The <code>validate</code> state exists for this purpose. If this state is the first state in the flow the UI will generate a input form based on the specification.</p> Parameter Description Type Required <code>type</code> Identifies which kind of StateDefinition is being used. In this case it must be set to <code>validate</code>. string yes <code>id</code> An identifier unique within the workflow to this one state. string yes <code>log</code> If defined, the workflow will generate a log when it commences this state. See StateLogging. Structured JQ no <code>metadata</code> If defined, updates the instance's metadata. See InstanceMetadata. Structured JQ no <code>transform</code> If defined, modifies the instance's data upon completing the state logic. See StateTransforms. Structured JQ no <code>transition</code> Identifies which state to transition to next, referring to the next state's unique <code>id</code>. If undefined, this state terminates the workflow. string no <code>catch</code> Defines behaviour for handling of catchable errors. []ErrorCatchDefinition no <code>subject</code> Selects or generates the data that will be compared to the <code>schema</code>. If undefined, it will be default to <code>'jq(.)'</code>. Structured JQ no <code>schema</code> A YAMLified representation of a JSON Schema that defines whether the <code>subject</code> is considered valid. object yes"},{"location":"spec/workflow-yaml/workflow/","title":"Workflow Definition","text":""},{"location":"spec/workflow-yaml/workflow/#direktiv-workflow-definition","title":"Direktiv Workflow Definition","text":"<p>This document describes the rules for Direktiv workflow definition files. These files are written in YAML and dictate the behaviour of a workflow running on Direktiv. </p> Workflow<pre><code>description: |\nA simple \"Hello, world\" demonstration.\nstates:\n- id: hello\ntype: noop\ntransform: 'jq({ msg: \"Hello, world!\" })'\n</code></pre> Input<pre><code>{}\n</code></pre> Output<pre><code>{\n\"msg\": \"Hello, world!\"\n}\n</code></pre> <p>Workflows have inputs and outputs, usually in JSON. Where examples appear in this document they will often be accompanied by inputs and outputs as seen above.</p>"},{"location":"spec/workflow-yaml/workflow/#workflowdefinition","title":"WorkflowDefinition","text":"<p>This is the top-level structure of a Direktiv workflow definition. All workflows must have one.</p> Parameter Description Type Required <code>url</code> Link to further information. string no <code>description</code> Short description of the workflow. string no <code>functions</code> List of function definitions for use by function-based <code>states</code>. []FunctionDefinition no <code>start</code> Configuration for how the workflow should start. StartDefinition no <code>states</code> List of all possible workflow states. []StateDefinition yes <code>timeouts</code> Configuration of workflow-level timeouts. TimeoutsDefinition no"}]}